{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kvergopoulos/miniconda3/envs/ffcv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Â These two lines ensure that we always import the latest version of a package, in case it has been modified.\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import detectors\n",
    "from torchvision import transforms\n",
    "from utils import vis as vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from data_utils.data_stats import *\n",
    "from models.networks import get_model\n",
    "from data_utils.dataloader import get_loader\n",
    "from data_utils.dataset_to_beton import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define important parameters\n",
    "\n",
    "dataset         = 'cifar10'               # One of cifar10, cifar100, stl10, imagenet or imagenet21\n",
    "num_classes     = CLASS_DICT[dataset]\n",
    "data_path       = '/scratch/ffcv'\n",
    "model_path      = '/tmp/zooming_in_on_mlps/'\n",
    "eval_batch_size = 32\n",
    "crop_resolution = 32\n",
    "data_resolution = 32 \n",
    "checkpoint      = None\n",
    "device          = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_type      = 'mlp'                   \n",
    "checkpoint      = 'in21k_cifar10'       \n",
    "architecture    = 'B_12-Wi_1024'        \n",
    "crop_resolution = 64   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models_full(model_type, \n",
    "                    architecture, \n",
    "                    resolution  = crop_resolution, \n",
    "                    num_classes = CLASS_DICT[dataset], \n",
    "                    checkpoint  = checkpoint, \n",
    "                    model_path   = model_path):\n",
    "    if model_type == 'mlp':\n",
    "        model = get_model(architecture=architecture, resolution = resolution, \n",
    "                          num_classes=num_classes,checkpoint= checkpoint)\n",
    "        model = torch.nn.Sequential(vis.Reshape(64), model)\n",
    "    elif model_type == 'cnn':\n",
    "        model = timm.create_model(architecture, pretrained=True)\n",
    "    elif model_type == 'vit':\n",
    "        model = torch.load(os.path.join(model_path, architecture))\n",
    "        model = torch.nn.Sequential(vis.Reshape(224), model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n",
      "Loading /scratch/ffcv/cifar10/val_32.beton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kvergopoulos/miniconda3/envs/ffcv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probability for target class 0.4835677742958069\n",
      "all probabilities tensor([0.0396, 0.1941, 0.0328, 0.0406, 0.0474, 0.0417, 0.0387, 0.0432, 0.4836,\n",
      "        0.0382], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.6053304672241211\n",
      "all probabilities tensor([0.0388, 0.0725, 0.0367, 0.0436, 0.0441, 0.0413, 0.0390, 0.0424, 0.6053,\n",
      "        0.0361], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.6257598996162415\n",
      "all probabilities tensor([0.0376, 0.0604, 0.0361, 0.0429, 0.0424, 0.0401, 0.0383, 0.0413, 0.6258,\n",
      "        0.0350], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.6375758051872253\n",
      "all probabilities tensor([0.0367, 0.0553, 0.0353, 0.0422, 0.0412, 0.0393, 0.0376, 0.0406, 0.6376,\n",
      "        0.0342], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.6462640166282654\n",
      "all probabilities tensor([0.0359, 0.0522, 0.0346, 0.0415, 0.0403, 0.0386, 0.0371, 0.0399, 0.6463,\n",
      "        0.0336], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.653386116027832\n",
      "all probabilities tensor([0.0352, 0.0501, 0.0339, 0.0408, 0.0394, 0.0380, 0.0366, 0.0394, 0.6534,\n",
      "        0.0331], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.659578263759613\n",
      "all probabilities tensor([0.0346, 0.0485, 0.0332, 0.0402, 0.0387, 0.0375, 0.0362, 0.0389, 0.6596,\n",
      "        0.0326], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.6651481986045837\n",
      "all probabilities tensor([0.0341, 0.0472, 0.0326, 0.0396, 0.0380, 0.0369, 0.0358, 0.0384, 0.6651,\n",
      "        0.0322], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.67026686668396\n",
      "all probabilities tensor([0.0336, 0.0461, 0.0320, 0.0390, 0.0374, 0.0365, 0.0354, 0.0379, 0.6703,\n",
      "        0.0318], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.6750370264053345\n",
      "all probabilities tensor([0.0331, 0.0451, 0.0315, 0.0384, 0.0368, 0.0360, 0.0351, 0.0375, 0.6750,\n",
      "        0.0314], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.679528534412384\n",
      "all probabilities tensor([0.0327, 0.0442, 0.0310, 0.0379, 0.0363, 0.0356, 0.0347, 0.0371, 0.6795,\n",
      "        0.0310], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.6837860941886902\n",
      "all probabilities tensor([0.0322, 0.0434, 0.0304, 0.0374, 0.0358, 0.0352, 0.0344, 0.0367, 0.6838,\n",
      "        0.0307], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.6878427267074585\n",
      "all probabilities tensor([0.0318, 0.0426, 0.0300, 0.0369, 0.0353, 0.0348, 0.0340, 0.0363, 0.6878,\n",
      "        0.0303], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.6917222142219543\n",
      "all probabilities tensor([0.0314, 0.0419, 0.0295, 0.0364, 0.0348, 0.0345, 0.0337, 0.0360, 0.6917,\n",
      "        0.0300], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.6954424977302551\n",
      "all probabilities tensor([0.0310, 0.0412, 0.0291, 0.0359, 0.0344, 0.0341, 0.0334, 0.0356, 0.6954,\n",
      "        0.0297], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.6990219950675964\n",
      "all probabilities tensor([0.0307, 0.0406, 0.0287, 0.0355, 0.0340, 0.0338, 0.0331, 0.0353, 0.6990,\n",
      "        0.0294], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7024713754653931\n",
      "all probabilities tensor([0.0303, 0.0400, 0.0282, 0.0351, 0.0336, 0.0334, 0.0328, 0.0350, 0.7025,\n",
      "        0.0291], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7058009505271912\n",
      "all probabilities tensor([0.0300, 0.0394, 0.0279, 0.0346, 0.0332, 0.0331, 0.0326, 0.0346, 0.7058,\n",
      "        0.0288], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7090197801589966\n",
      "all probabilities tensor([0.0297, 0.0388, 0.0275, 0.0342, 0.0328, 0.0328, 0.0323, 0.0343, 0.7090,\n",
      "        0.0286], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7121361494064331\n",
      "all probabilities tensor([0.0293, 0.0383, 0.0271, 0.0338, 0.0324, 0.0325, 0.0320, 0.0340, 0.7121,\n",
      "        0.0283], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.715154767036438\n",
      "all probabilities tensor([0.0290, 0.0377, 0.0268, 0.0335, 0.0321, 0.0322, 0.0317, 0.0337, 0.7152,\n",
      "        0.0281], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7180829048156738\n",
      "all probabilities tensor([0.0287, 0.0372, 0.0264, 0.0331, 0.0317, 0.0319, 0.0315, 0.0335, 0.7181,\n",
      "        0.0278], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7209238409996033\n",
      "all probabilities tensor([0.0285, 0.0367, 0.0261, 0.0327, 0.0314, 0.0316, 0.0312, 0.0332, 0.7209,\n",
      "        0.0276], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.723679780960083\n",
      "all probabilities tensor([0.0282, 0.0363, 0.0258, 0.0324, 0.0311, 0.0314, 0.0310, 0.0329, 0.7237,\n",
      "        0.0273], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.72635817527771\n",
      "all probabilities tensor([0.0279, 0.0358, 0.0255, 0.0320, 0.0308, 0.0311, 0.0307, 0.0326, 0.7264,\n",
      "        0.0271], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7289637923240662\n",
      "all probabilities tensor([0.0276, 0.0354, 0.0252, 0.0317, 0.0305, 0.0309, 0.0305, 0.0324, 0.7290,\n",
      "        0.0269], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.731498122215271\n",
      "all probabilities tensor([0.0274, 0.0349, 0.0249, 0.0314, 0.0302, 0.0306, 0.0303, 0.0321, 0.7315,\n",
      "        0.0266], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7339667081832886\n",
      "all probabilities tensor([0.0271, 0.0345, 0.0246, 0.0311, 0.0299, 0.0304, 0.0301, 0.0319, 0.7340,\n",
      "        0.0264], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.736372709274292\n",
      "all probabilities tensor([0.0269, 0.0341, 0.0244, 0.0308, 0.0297, 0.0301, 0.0298, 0.0316, 0.7364,\n",
      "        0.0262], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.738717257976532\n",
      "all probabilities tensor([0.0267, 0.0337, 0.0241, 0.0305, 0.0294, 0.0299, 0.0296, 0.0314, 0.7387,\n",
      "        0.0260], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7410041689872742\n",
      "all probabilities tensor([0.0264, 0.0334, 0.0239, 0.0302, 0.0291, 0.0296, 0.0294, 0.0312, 0.7410,\n",
      "        0.0258], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7432355880737305\n",
      "all probabilities tensor([0.0262, 0.0330, 0.0236, 0.0299, 0.0289, 0.0294, 0.0292, 0.0309, 0.7432,\n",
      "        0.0256], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7454149127006531\n",
      "all probabilities tensor([0.0260, 0.0326, 0.0234, 0.0296, 0.0287, 0.0292, 0.0290, 0.0307, 0.7454,\n",
      "        0.0254], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7475416660308838\n",
      "all probabilities tensor([0.0258, 0.0323, 0.0232, 0.0293, 0.0284, 0.0290, 0.0288, 0.0305, 0.7475,\n",
      "        0.0252], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7496204376220703\n",
      "all probabilities tensor([0.0256, 0.0319, 0.0229, 0.0291, 0.0282, 0.0288, 0.0286, 0.0303, 0.7496,\n",
      "        0.0250], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.75165194272995\n",
      "all probabilities tensor([0.0254, 0.0316, 0.0227, 0.0288, 0.0280, 0.0286, 0.0284, 0.0301, 0.7517,\n",
      "        0.0249], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7536389827728271\n",
      "all probabilities tensor([0.0252, 0.0313, 0.0225, 0.0286, 0.0277, 0.0284, 0.0282, 0.0299, 0.7536,\n",
      "        0.0247], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7555832862854004\n",
      "all probabilities tensor([0.0250, 0.0310, 0.0223, 0.0283, 0.0275, 0.0282, 0.0280, 0.0297, 0.7556,\n",
      "        0.0245], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7574853301048279\n",
      "all probabilities tensor([0.0248, 0.0307, 0.0221, 0.0281, 0.0273, 0.0280, 0.0278, 0.0295, 0.7575,\n",
      "        0.0243], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7593491673469543\n",
      "all probabilities tensor([0.0246, 0.0304, 0.0219, 0.0278, 0.0271, 0.0278, 0.0276, 0.0293, 0.7593,\n",
      "        0.0242], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7611744403839111\n",
      "all probabilities tensor([0.0244, 0.0301, 0.0217, 0.0276, 0.0269, 0.0276, 0.0275, 0.0291, 0.7612,\n",
      "        0.0240], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7629620432853699\n",
      "all probabilities tensor([0.0242, 0.0298, 0.0215, 0.0274, 0.0267, 0.0274, 0.0273, 0.0289, 0.7630,\n",
      "        0.0238], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7647153735160828\n",
      "all probabilities tensor([0.0240, 0.0295, 0.0213, 0.0271, 0.0265, 0.0272, 0.0271, 0.0287, 0.7647,\n",
      "        0.0237], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7664334774017334\n",
      "all probabilities tensor([0.0239, 0.0293, 0.0212, 0.0269, 0.0264, 0.0270, 0.0269, 0.0285, 0.7664,\n",
      "        0.0235], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7681149840354919\n",
      "all probabilities tensor([0.0237, 0.0290, 0.0210, 0.0267, 0.0262, 0.0268, 0.0268, 0.0284, 0.7681,\n",
      "        0.0233], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.76976478099823\n",
      "all probabilities tensor([0.0235, 0.0288, 0.0208, 0.0265, 0.0260, 0.0267, 0.0266, 0.0282, 0.7698,\n",
      "        0.0232], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7713841795921326\n",
      "all probabilities tensor([0.0234, 0.0285, 0.0207, 0.0263, 0.0258, 0.0265, 0.0264, 0.0280, 0.7714,\n",
      "        0.0230], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7729744911193848\n",
      "all probabilities tensor([0.0232, 0.0283, 0.0205, 0.0261, 0.0257, 0.0263, 0.0263, 0.0278, 0.7730,\n",
      "        0.0229], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7745363116264343\n",
      "all probabilities tensor([0.0230, 0.0280, 0.0203, 0.0259, 0.0255, 0.0262, 0.0261, 0.0277, 0.7745,\n",
      "        0.0227], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7760704755783081\n",
      "all probabilities tensor([0.0229, 0.0278, 0.0202, 0.0257, 0.0253, 0.0260, 0.0260, 0.0275, 0.7761,\n",
      "        0.0226], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7775784134864807\n",
      "all probabilities tensor([0.0227, 0.0276, 0.0200, 0.0255, 0.0252, 0.0258, 0.0258, 0.0273, 0.7776,\n",
      "        0.0225], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7790593504905701\n",
      "all probabilities tensor([0.0226, 0.0274, 0.0199, 0.0253, 0.0250, 0.0257, 0.0257, 0.0272, 0.7791,\n",
      "        0.0223], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.780514657497406\n",
      "all probabilities tensor([0.0224, 0.0271, 0.0197, 0.0251, 0.0249, 0.0255, 0.0255, 0.0270, 0.7805,\n",
      "        0.0222], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7819467782974243\n",
      "all probabilities tensor([0.0223, 0.0269, 0.0196, 0.0249, 0.0247, 0.0253, 0.0254, 0.0269, 0.7819,\n",
      "        0.0220], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7833553552627563\n",
      "all probabilities tensor([0.0221, 0.0267, 0.0195, 0.0247, 0.0246, 0.0252, 0.0252, 0.0267, 0.7834,\n",
      "        0.0219], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7847419381141663\n",
      "all probabilities tensor([0.0220, 0.0265, 0.0193, 0.0246, 0.0244, 0.0250, 0.0251, 0.0266, 0.7847,\n",
      "        0.0218], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7861058712005615\n",
      "all probabilities tensor([0.0218, 0.0263, 0.0192, 0.0244, 0.0243, 0.0249, 0.0249, 0.0264, 0.7861,\n",
      "        0.0216], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7874488234519958\n",
      "all probabilities tensor([0.0217, 0.0261, 0.0191, 0.0242, 0.0241, 0.0247, 0.0248, 0.0263, 0.7874,\n",
      "        0.0215], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7887712717056274\n",
      "all probabilities tensor([0.0216, 0.0259, 0.0189, 0.0241, 0.0240, 0.0246, 0.0247, 0.0261, 0.7888,\n",
      "        0.0214], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7900739908218384\n",
      "all probabilities tensor([0.0214, 0.0257, 0.0188, 0.0239, 0.0239, 0.0244, 0.0245, 0.0260, 0.7901,\n",
      "        0.0213], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7913565635681152\n",
      "all probabilities tensor([0.0213, 0.0256, 0.0187, 0.0237, 0.0237, 0.0243, 0.0244, 0.0259, 0.7914,\n",
      "        0.0211], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7926206588745117\n",
      "all probabilities tensor([0.0212, 0.0254, 0.0186, 0.0236, 0.0236, 0.0242, 0.0243, 0.0257, 0.7926,\n",
      "        0.0210], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7938656806945801\n",
      "all probabilities tensor([0.0210, 0.0252, 0.0184, 0.0234, 0.0235, 0.0240, 0.0241, 0.0256, 0.7939,\n",
      "        0.0209], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7950912117958069\n",
      "all probabilities tensor([0.0209, 0.0250, 0.0183, 0.0232, 0.0233, 0.0239, 0.0240, 0.0254, 0.7951,\n",
      "        0.0208], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7962992191314697\n",
      "all probabilities tensor([0.0208, 0.0248, 0.0182, 0.0231, 0.0232, 0.0237, 0.0239, 0.0253, 0.7963,\n",
      "        0.0206], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.797490119934082\n",
      "all probabilities tensor([0.0206, 0.0247, 0.0181, 0.0229, 0.0231, 0.0236, 0.0237, 0.0252, 0.7975,\n",
      "        0.0205], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7986655831336975\n",
      "all probabilities tensor([0.0205, 0.0245, 0.0180, 0.0228, 0.0230, 0.0235, 0.0236, 0.0251, 0.7987,\n",
      "        0.0204], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.7998247146606445\n",
      "all probabilities tensor([0.0204, 0.0244, 0.0179, 0.0226, 0.0228, 0.0233, 0.0235, 0.0249, 0.7998,\n",
      "        0.0203], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8009688854217529\n",
      "all probabilities tensor([0.0203, 0.0242, 0.0178, 0.0225, 0.0227, 0.0232, 0.0234, 0.0248, 0.8010,\n",
      "        0.0202], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8020976185798645\n",
      "all probabilities tensor([0.0202, 0.0240, 0.0176, 0.0224, 0.0226, 0.0231, 0.0233, 0.0247, 0.8021,\n",
      "        0.0201], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8032116293907166\n",
      "all probabilities tensor([0.0200, 0.0239, 0.0175, 0.0222, 0.0225, 0.0230, 0.0231, 0.0246, 0.8032,\n",
      "        0.0200], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8043115139007568\n",
      "all probabilities tensor([0.0199, 0.0237, 0.0174, 0.0221, 0.0224, 0.0228, 0.0230, 0.0244, 0.8043,\n",
      "        0.0198], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.805397093296051\n",
      "all probabilities tensor([0.0198, 0.0236, 0.0173, 0.0219, 0.0223, 0.0227, 0.0229, 0.0243, 0.8054,\n",
      "        0.0197], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8064693808555603\n",
      "all probabilities tensor([0.0197, 0.0234, 0.0172, 0.0218, 0.0222, 0.0226, 0.0228, 0.0242, 0.8065,\n",
      "        0.0196], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8075280785560608\n",
      "all probabilities tensor([0.0196, 0.0233, 0.0171, 0.0217, 0.0220, 0.0225, 0.0227, 0.0241, 0.8075,\n",
      "        0.0195], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8085731267929077\n",
      "all probabilities tensor([0.0195, 0.0231, 0.0170, 0.0215, 0.0219, 0.0223, 0.0226, 0.0240, 0.8086,\n",
      "        0.0194], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8096062541007996\n",
      "all probabilities tensor([0.0193, 0.0230, 0.0170, 0.0214, 0.0218, 0.0222, 0.0225, 0.0238, 0.8096,\n",
      "        0.0193], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8106272220611572\n",
      "all probabilities tensor([0.0192, 0.0229, 0.0169, 0.0213, 0.0217, 0.0221, 0.0223, 0.0237, 0.8106,\n",
      "        0.0192], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8116352558135986\n",
      "all probabilities tensor([0.0191, 0.0227, 0.0168, 0.0212, 0.0216, 0.0220, 0.0222, 0.0236, 0.8116,\n",
      "        0.0191], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8126319646835327\n",
      "all probabilities tensor([0.0190, 0.0226, 0.0167, 0.0210, 0.0215, 0.0219, 0.0221, 0.0235, 0.8126,\n",
      "        0.0190], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8136171102523804\n",
      "all probabilities tensor([0.0189, 0.0224, 0.0166, 0.0209, 0.0214, 0.0218, 0.0220, 0.0234, 0.8136,\n",
      "        0.0189], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.814590334892273\n",
      "all probabilities tensor([0.0188, 0.0223, 0.0165, 0.0208, 0.0213, 0.0216, 0.0219, 0.0233, 0.8146,\n",
      "        0.0188], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8155524730682373\n",
      "all probabilities tensor([0.0187, 0.0222, 0.0164, 0.0207, 0.0212, 0.0215, 0.0218, 0.0232, 0.8156,\n",
      "        0.0187], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8165038824081421\n",
      "all probabilities tensor([0.0186, 0.0221, 0.0163, 0.0206, 0.0211, 0.0214, 0.0217, 0.0231, 0.8165,\n",
      "        0.0186], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8174448013305664\n",
      "all probabilities tensor([0.0185, 0.0219, 0.0162, 0.0204, 0.0210, 0.0213, 0.0216, 0.0230, 0.8174,\n",
      "        0.0185], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8183746933937073\n",
      "all probabilities tensor([0.0184, 0.0218, 0.0162, 0.0203, 0.0209, 0.0212, 0.0215, 0.0229, 0.8184,\n",
      "        0.0184], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8192951083183289\n",
      "all probabilities tensor([0.0183, 0.0217, 0.0161, 0.0202, 0.0209, 0.0211, 0.0214, 0.0228, 0.8193,\n",
      "        0.0183], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8202051520347595\n",
      "all probabilities tensor([0.0182, 0.0216, 0.0160, 0.0201, 0.0208, 0.0210, 0.0213, 0.0227, 0.8202,\n",
      "        0.0182], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8211055994033813\n",
      "all probabilities tensor([0.0181, 0.0214, 0.0159, 0.0200, 0.0207, 0.0209, 0.0212, 0.0226, 0.8211,\n",
      "        0.0181], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8219965696334839\n",
      "all probabilities tensor([0.0180, 0.0213, 0.0158, 0.0199, 0.0206, 0.0208, 0.0211, 0.0225, 0.8220,\n",
      "        0.0180], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8228779435157776\n",
      "all probabilities tensor([0.0179, 0.0212, 0.0158, 0.0198, 0.0205, 0.0207, 0.0210, 0.0224, 0.8229,\n",
      "        0.0180], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.823749840259552\n",
      "all probabilities tensor([0.0178, 0.0211, 0.0157, 0.0197, 0.0204, 0.0206, 0.0209, 0.0223, 0.8237,\n",
      "        0.0179], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.824612557888031\n",
      "all probabilities tensor([0.0177, 0.0210, 0.0156, 0.0196, 0.0203, 0.0205, 0.0208, 0.0222, 0.8246,\n",
      "        0.0178], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8254671096801758\n",
      "all probabilities tensor([0.0176, 0.0209, 0.0155, 0.0195, 0.0202, 0.0204, 0.0207, 0.0221, 0.8255,\n",
      "        0.0177], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8263117074966431\n",
      "all probabilities tensor([0.0175, 0.0207, 0.0154, 0.0194, 0.0201, 0.0203, 0.0206, 0.0220, 0.8263,\n",
      "        0.0176], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8271486163139343\n",
      "all probabilities tensor([0.0174, 0.0206, 0.0154, 0.0193, 0.0201, 0.0202, 0.0205, 0.0219, 0.8271,\n",
      "        0.0175], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8279758095741272\n",
      "all probabilities tensor([0.0173, 0.0205, 0.0153, 0.0192, 0.0200, 0.0201, 0.0205, 0.0218, 0.8280,\n",
      "        0.0174], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8287955522537231\n",
      "all probabilities tensor([0.0172, 0.0204, 0.0152, 0.0191, 0.0199, 0.0200, 0.0204, 0.0217, 0.8288,\n",
      "        0.0173], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8296068906784058\n",
      "all probabilities tensor([0.0171, 0.0203, 0.0152, 0.0190, 0.0198, 0.0199, 0.0203, 0.0216, 0.8296,\n",
      "        0.0173], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.830410361289978\n",
      "all probabilities tensor([0.0170, 0.0202, 0.0151, 0.0189, 0.0197, 0.0198, 0.0202, 0.0215, 0.8304,\n",
      "        0.0172], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8312067985534668\n",
      "all probabilities tensor([0.0170, 0.0201, 0.0150, 0.0188, 0.0197, 0.0197, 0.0201, 0.0214, 0.8312,\n",
      "        0.0171], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8319949507713318\n",
      "all probabilities tensor([0.0169, 0.0200, 0.0150, 0.0187, 0.0196, 0.0196, 0.0200, 0.0213, 0.8320,\n",
      "        0.0170], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8327759504318237\n",
      "all probabilities tensor([0.0168, 0.0199, 0.0149, 0.0186, 0.0195, 0.0195, 0.0199, 0.0213, 0.8328,\n",
      "        0.0169], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8335497379302979\n",
      "all probabilities tensor([0.0167, 0.0198, 0.0148, 0.0185, 0.0194, 0.0194, 0.0198, 0.0212, 0.8335,\n",
      "        0.0168], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8343159556388855\n",
      "all probabilities tensor([0.0166, 0.0197, 0.0147, 0.0184, 0.0193, 0.0193, 0.0198, 0.0211, 0.8343,\n",
      "        0.0168], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8350746631622314\n",
      "all probabilities tensor([0.0165, 0.0196, 0.0147, 0.0183, 0.0193, 0.0192, 0.0197, 0.0210, 0.8351,\n",
      "        0.0167], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8358270525932312\n",
      "all probabilities tensor([0.0164, 0.0195, 0.0146, 0.0182, 0.0192, 0.0191, 0.0196, 0.0209, 0.8358,\n",
      "        0.0166], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8365715146064758\n",
      "all probabilities tensor([0.0163, 0.0194, 0.0146, 0.0181, 0.0191, 0.0190, 0.0195, 0.0208, 0.8366,\n",
      "        0.0165], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8373106122016907\n",
      "all probabilities tensor([0.0163, 0.0193, 0.0145, 0.0180, 0.0191, 0.0189, 0.0194, 0.0207, 0.8373,\n",
      "        0.0164], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8380422592163086\n",
      "all probabilities tensor([0.0162, 0.0192, 0.0144, 0.0180, 0.0190, 0.0189, 0.0193, 0.0207, 0.8380,\n",
      "        0.0164], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8387678861618042\n",
      "all probabilities tensor([0.0161, 0.0191, 0.0144, 0.0179, 0.0189, 0.0188, 0.0193, 0.0206, 0.8388,\n",
      "        0.0163], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8394868969917297\n",
      "all probabilities tensor([0.0160, 0.0190, 0.0143, 0.0178, 0.0188, 0.0187, 0.0192, 0.0205, 0.8395,\n",
      "        0.0162], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8401997685432434\n",
      "all probabilities tensor([0.0159, 0.0189, 0.0142, 0.0177, 0.0188, 0.0186, 0.0191, 0.0204, 0.8402,\n",
      "        0.0161], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8409063220024109\n",
      "all probabilities tensor([0.0159, 0.0188, 0.0142, 0.0176, 0.0187, 0.0185, 0.0190, 0.0203, 0.8409,\n",
      "        0.0160], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8416067361831665\n",
      "all probabilities tensor([0.0158, 0.0187, 0.0141, 0.0175, 0.0186, 0.0184, 0.0189, 0.0203, 0.8416,\n",
      "        0.0160], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8423016667366028\n",
      "all probabilities tensor([0.0157, 0.0187, 0.0141, 0.0174, 0.0186, 0.0183, 0.0189, 0.0202, 0.8423,\n",
      "        0.0159], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8429902791976929\n",
      "all probabilities tensor([0.0156, 0.0186, 0.0140, 0.0174, 0.0185, 0.0183, 0.0188, 0.0201, 0.8430,\n",
      "        0.0158], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8436732888221741\n",
      "all probabilities tensor([0.0155, 0.0185, 0.0140, 0.0173, 0.0184, 0.0182, 0.0187, 0.0200, 0.8437,\n",
      "        0.0157], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8443498611450195\n",
      "all probabilities tensor([0.0155, 0.0184, 0.0139, 0.0172, 0.0184, 0.0181, 0.0186, 0.0200, 0.8443,\n",
      "        0.0157], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.845021665096283\n",
      "all probabilities tensor([0.0154, 0.0183, 0.0138, 0.0171, 0.0183, 0.0180, 0.0186, 0.0199, 0.8450,\n",
      "        0.0156], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8456878662109375\n",
      "all probabilities tensor([0.0153, 0.0182, 0.0138, 0.0171, 0.0182, 0.0179, 0.0185, 0.0198, 0.8457,\n",
      "        0.0155], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8463486433029175\n",
      "all probabilities tensor([0.0152, 0.0181, 0.0137, 0.0170, 0.0182, 0.0178, 0.0184, 0.0197, 0.8463,\n",
      "        0.0155], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8470032811164856\n",
      "all probabilities tensor([0.0151, 0.0180, 0.0137, 0.0169, 0.0181, 0.0178, 0.0183, 0.0197, 0.8470,\n",
      "        0.0154], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8476527333259583\n",
      "all probabilities tensor([0.0151, 0.0180, 0.0136, 0.0168, 0.0180, 0.0177, 0.0183, 0.0196, 0.8477,\n",
      "        0.0153], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8482969999313354\n",
      "all probabilities tensor([0.0150, 0.0179, 0.0136, 0.0167, 0.0180, 0.0176, 0.0182, 0.0195, 0.8483,\n",
      "        0.0152], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.848936140537262\n",
      "all probabilities tensor([0.0149, 0.0178, 0.0135, 0.0167, 0.0179, 0.0175, 0.0181, 0.0194, 0.8489,\n",
      "        0.0152], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8495702147483826\n",
      "all probabilities tensor([0.0148, 0.0177, 0.0135, 0.0166, 0.0179, 0.0174, 0.0180, 0.0194, 0.8496,\n",
      "        0.0151], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8501990437507629\n",
      "all probabilities tensor([0.0148, 0.0176, 0.0134, 0.0165, 0.0178, 0.0174, 0.0180, 0.0193, 0.8502,\n",
      "        0.0150], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8508230447769165\n",
      "all probabilities tensor([0.0147, 0.0176, 0.0134, 0.0165, 0.0177, 0.0173, 0.0179, 0.0192, 0.8508,\n",
      "        0.0150], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8514427542686462\n",
      "all probabilities tensor([0.0146, 0.0175, 0.0133, 0.0164, 0.0177, 0.0172, 0.0178, 0.0192, 0.8514,\n",
      "        0.0149], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8520572185516357\n",
      "all probabilities tensor([0.0146, 0.0174, 0.0132, 0.0163, 0.0176, 0.0171, 0.0178, 0.0191, 0.8521,\n",
      "        0.0148], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8526670932769775\n",
      "all probabilities tensor([0.0145, 0.0173, 0.0132, 0.0162, 0.0176, 0.0171, 0.0177, 0.0190, 0.8527,\n",
      "        0.0148], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8532721400260925\n",
      "all probabilities tensor([0.0144, 0.0172, 0.0131, 0.0162, 0.0175, 0.0170, 0.0176, 0.0189, 0.8533,\n",
      "        0.0147], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8538724780082703\n",
      "all probabilities tensor([0.0143, 0.0172, 0.0131, 0.0161, 0.0174, 0.0169, 0.0176, 0.0189, 0.8539,\n",
      "        0.0146], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8544685244560242\n",
      "all probabilities tensor([0.0143, 0.0171, 0.0131, 0.0160, 0.0174, 0.0168, 0.0175, 0.0188, 0.8545,\n",
      "        0.0146], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8550602793693542\n",
      "all probabilities tensor([0.0142, 0.0170, 0.0130, 0.0160, 0.0173, 0.0168, 0.0174, 0.0187, 0.8551,\n",
      "        0.0145], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8556470274925232\n",
      "all probabilities tensor([0.0141, 0.0169, 0.0130, 0.0159, 0.0173, 0.0167, 0.0174, 0.0187, 0.8556,\n",
      "        0.0144], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8562294244766235\n",
      "all probabilities tensor([0.0141, 0.0169, 0.0129, 0.0158, 0.0172, 0.0166, 0.0173, 0.0186, 0.8562,\n",
      "        0.0144], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8568077683448792\n",
      "all probabilities tensor([0.0140, 0.0168, 0.0129, 0.0158, 0.0172, 0.0165, 0.0172, 0.0185, 0.8568,\n",
      "        0.0143], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8573816418647766\n",
      "all probabilities tensor([0.0139, 0.0167, 0.0128, 0.0157, 0.0171, 0.0165, 0.0172, 0.0185, 0.8574,\n",
      "        0.0142], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8579517006874084\n",
      "all probabilities tensor([0.0139, 0.0166, 0.0128, 0.0156, 0.0170, 0.0164, 0.0171, 0.0184, 0.8580,\n",
      "        0.0142], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8585173487663269\n",
      "all probabilities tensor([0.0138, 0.0166, 0.0127, 0.0156, 0.0170, 0.0163, 0.0170, 0.0183, 0.8585,\n",
      "        0.0141], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8590788841247559\n",
      "all probabilities tensor([0.0137, 0.0165, 0.0127, 0.0155, 0.0169, 0.0163, 0.0170, 0.0183, 0.8591,\n",
      "        0.0141], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.859636127948761\n",
      "all probabilities tensor([0.0137, 0.0164, 0.0126, 0.0154, 0.0169, 0.0162, 0.0169, 0.0182, 0.8596,\n",
      "        0.0140], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8601894378662109\n",
      "all probabilities tensor([0.0136, 0.0164, 0.0126, 0.0154, 0.0168, 0.0161, 0.0168, 0.0182, 0.8602,\n",
      "        0.0139], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8607388734817505\n",
      "all probabilities tensor([0.0135, 0.0163, 0.0125, 0.0153, 0.0168, 0.0161, 0.0168, 0.0181, 0.8607,\n",
      "        0.0139], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8612841367721558\n",
      "all probabilities tensor([0.0135, 0.0162, 0.0125, 0.0153, 0.0167, 0.0160, 0.0167, 0.0180, 0.8613,\n",
      "        0.0138], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8618261218070984\n",
      "all probabilities tensor([0.0134, 0.0161, 0.0124, 0.0152, 0.0167, 0.0159, 0.0166, 0.0180, 0.8618,\n",
      "        0.0138], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8623634576797485\n",
      "all probabilities tensor([0.0133, 0.0161, 0.0124, 0.0151, 0.0166, 0.0159, 0.0166, 0.0179, 0.8624,\n",
      "        0.0137], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8628975749015808\n",
      "all probabilities tensor([0.0133, 0.0160, 0.0124, 0.0151, 0.0166, 0.0158, 0.0165, 0.0179, 0.8629,\n",
      "        0.0136], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8634278178215027\n",
      "all probabilities tensor([0.0132, 0.0159, 0.0123, 0.0150, 0.0165, 0.0157, 0.0165, 0.0178, 0.8634,\n",
      "        0.0136], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8639541864395142\n",
      "all probabilities tensor([0.0132, 0.0159, 0.0123, 0.0150, 0.0165, 0.0157, 0.0164, 0.0177, 0.8640,\n",
      "        0.0135], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8644766211509705\n",
      "all probabilities tensor([0.0131, 0.0158, 0.0122, 0.0149, 0.0164, 0.0156, 0.0163, 0.0177, 0.8645,\n",
      "        0.0135], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8649957776069641\n",
      "all probabilities tensor([0.0130, 0.0157, 0.0122, 0.0148, 0.0164, 0.0155, 0.0163, 0.0176, 0.8650,\n",
      "        0.0134], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8655112981796265\n",
      "all probabilities tensor([0.0130, 0.0157, 0.0121, 0.0148, 0.0163, 0.0155, 0.0162, 0.0176, 0.8655,\n",
      "        0.0133], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8660229444503784\n",
      "all probabilities tensor([0.0129, 0.0156, 0.0121, 0.0147, 0.0163, 0.0154, 0.0162, 0.0175, 0.8660,\n",
      "        0.0133], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8665310144424438\n",
      "all probabilities tensor([0.0129, 0.0155, 0.0121, 0.0147, 0.0162, 0.0153, 0.0161, 0.0174, 0.8665,\n",
      "        0.0132], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8670359253883362\n",
      "all probabilities tensor([0.0128, 0.0155, 0.0120, 0.0146, 0.0162, 0.0153, 0.0160, 0.0174, 0.8670,\n",
      "        0.0132], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8675370812416077\n",
      "all probabilities tensor([0.0127, 0.0154, 0.0120, 0.0146, 0.0161, 0.0152, 0.0160, 0.0173, 0.8675,\n",
      "        0.0131], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8680347800254822\n",
      "all probabilities tensor([0.0127, 0.0154, 0.0119, 0.0145, 0.0161, 0.0151, 0.0159, 0.0173, 0.8680,\n",
      "        0.0131], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8685296177864075\n",
      "all probabilities tensor([0.0126, 0.0153, 0.0119, 0.0144, 0.0160, 0.0151, 0.0159, 0.0172, 0.8685,\n",
      "        0.0130], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8690200448036194\n",
      "all probabilities tensor([0.0126, 0.0152, 0.0119, 0.0144, 0.0160, 0.0150, 0.0158, 0.0172, 0.8690,\n",
      "        0.0129], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8695072531700134\n",
      "all probabilities tensor([0.0125, 0.0152, 0.0118, 0.0143, 0.0159, 0.0150, 0.0158, 0.0171, 0.8695,\n",
      "        0.0129], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8699912428855896\n",
      "all probabilities tensor([0.0125, 0.0151, 0.0118, 0.0143, 0.0159, 0.0149, 0.0157, 0.0170, 0.8700,\n",
      "        0.0128], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8704718947410583\n",
      "all probabilities tensor([0.0124, 0.0150, 0.0117, 0.0142, 0.0159, 0.0148, 0.0157, 0.0170, 0.8705,\n",
      "        0.0128], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8709489703178406\n",
      "all probabilities tensor([0.0123, 0.0150, 0.0117, 0.0142, 0.0158, 0.0148, 0.0156, 0.0169, 0.8709,\n",
      "        0.0127], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.871423065662384\n",
      "all probabilities tensor([0.0123, 0.0149, 0.0117, 0.0141, 0.0158, 0.0147, 0.0155, 0.0169, 0.8714,\n",
      "        0.0127], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8718940019607544\n",
      "all probabilities tensor([0.0122, 0.0149, 0.0116, 0.0141, 0.0157, 0.0147, 0.0155, 0.0168, 0.8719,\n",
      "        0.0126], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8723613023757935\n",
      "all probabilities tensor([0.0122, 0.0148, 0.0116, 0.0140, 0.0157, 0.0146, 0.0154, 0.0168, 0.8724,\n",
      "        0.0126], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.872825562953949\n",
      "all probabilities tensor([0.0121, 0.0147, 0.0116, 0.0140, 0.0156, 0.0145, 0.0154, 0.0167, 0.8728,\n",
      "        0.0125], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8732872009277344\n",
      "all probabilities tensor([0.0121, 0.0147, 0.0115, 0.0139, 0.0156, 0.0145, 0.0153, 0.0167, 0.8733,\n",
      "        0.0125], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8737447261810303\n",
      "all probabilities tensor([0.0120, 0.0146, 0.0115, 0.0139, 0.0155, 0.0144, 0.0153, 0.0166, 0.8737,\n",
      "        0.0124], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8742002844810486\n",
      "all probabilities tensor([0.0120, 0.0146, 0.0114, 0.0138, 0.0155, 0.0144, 0.0152, 0.0166, 0.8742,\n",
      "        0.0124], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8746525645256042\n",
      "all probabilities tensor([0.0119, 0.0145, 0.0114, 0.0138, 0.0155, 0.0143, 0.0152, 0.0165, 0.8747,\n",
      "        0.0123], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8751010298728943\n",
      "all probabilities tensor([0.0119, 0.0145, 0.0114, 0.0137, 0.0154, 0.0143, 0.0151, 0.0165, 0.8751,\n",
      "        0.0123], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8755471110343933\n",
      "all probabilities tensor([0.0118, 0.0144, 0.0113, 0.0137, 0.0154, 0.0142, 0.0151, 0.0164, 0.8755,\n",
      "        0.0122], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8759897947311401\n",
      "all probabilities tensor([0.0118, 0.0143, 0.0113, 0.0136, 0.0153, 0.0141, 0.0150, 0.0164, 0.8760,\n",
      "        0.0122], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8764296770095825\n",
      "all probabilities tensor([0.0117, 0.0143, 0.0113, 0.0136, 0.0153, 0.0141, 0.0150, 0.0163, 0.8764,\n",
      "        0.0121], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8768667578697205\n",
      "all probabilities tensor([0.0117, 0.0142, 0.0112, 0.0135, 0.0153, 0.0140, 0.0149, 0.0163, 0.8769,\n",
      "        0.0121], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8773002624511719\n",
      "all probabilities tensor([0.0116, 0.0142, 0.0112, 0.0135, 0.0152, 0.0140, 0.0149, 0.0162, 0.8773,\n",
      "        0.0120], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8777315020561218\n",
      "all probabilities tensor([0.0116, 0.0141, 0.0112, 0.0134, 0.0152, 0.0139, 0.0148, 0.0162, 0.8777,\n",
      "        0.0120], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8781594634056091\n",
      "all probabilities tensor([0.0115, 0.0141, 0.0111, 0.0134, 0.0151, 0.0139, 0.0148, 0.0161, 0.8782,\n",
      "        0.0119], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8785846829414368\n",
      "all probabilities tensor([0.0115, 0.0140, 0.0111, 0.0133, 0.0151, 0.0138, 0.0147, 0.0161, 0.8786,\n",
      "        0.0119], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8790072798728943\n",
      "all probabilities tensor([0.0114, 0.0140, 0.0111, 0.0133, 0.0150, 0.0138, 0.0147, 0.0160, 0.8790,\n",
      "        0.0118], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8794261813163757\n",
      "all probabilities tensor([0.0114, 0.0139, 0.0110, 0.0132, 0.0150, 0.0137, 0.0146, 0.0160, 0.8794,\n",
      "        0.0118], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8798434734344482\n",
      "all probabilities tensor([0.0113, 0.0138, 0.0110, 0.0132, 0.0150, 0.0137, 0.0146, 0.0159, 0.8798,\n",
      "        0.0117], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8802570104598999\n",
      "all probabilities tensor([0.0113, 0.0138, 0.0110, 0.0131, 0.0149, 0.0136, 0.0145, 0.0159, 0.8803,\n",
      "        0.0117], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8806684017181396\n",
      "all probabilities tensor([0.0112, 0.0137, 0.0109, 0.0131, 0.0149, 0.0135, 0.0145, 0.0158, 0.8807,\n",
      "        0.0116], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8810765147209167\n",
      "all probabilities tensor([0.0112, 0.0137, 0.0109, 0.0130, 0.0149, 0.0135, 0.0144, 0.0158, 0.8811,\n",
      "        0.0116], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8814818859100342\n",
      "all probabilities tensor([0.0111, 0.0136, 0.0109, 0.0130, 0.0148, 0.0134, 0.0144, 0.0157, 0.8815,\n",
      "        0.0115], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8818838596343994\n",
      "all probabilities tensor([0.0111, 0.0136, 0.0108, 0.0130, 0.0148, 0.0134, 0.0143, 0.0157, 0.8819,\n",
      "        0.0115], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8822834491729736\n",
      "all probabilities tensor([0.0110, 0.0135, 0.0108, 0.0129, 0.0147, 0.0133, 0.0143, 0.0156, 0.8823,\n",
      "        0.0114], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8826798796653748\n",
      "all probabilities tensor([0.0110, 0.0135, 0.0108, 0.0129, 0.0147, 0.0133, 0.0142, 0.0156, 0.8827,\n",
      "        0.0114], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8830729722976685\n",
      "all probabilities tensor([0.0109, 0.0134, 0.0107, 0.0128, 0.0147, 0.0132, 0.0142, 0.0155, 0.8831,\n",
      "        0.0114], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8834637999534607\n",
      "all probabilities tensor([0.0109, 0.0134, 0.0107, 0.0128, 0.0146, 0.0132, 0.0141, 0.0155, 0.8835,\n",
      "        0.0113], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8838514089584351\n",
      "all probabilities tensor([0.0109, 0.0133, 0.0107, 0.0127, 0.0146, 0.0131, 0.0141, 0.0155, 0.8839,\n",
      "        0.0113], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8842369318008423\n",
      "all probabilities tensor([0.0108, 0.0133, 0.0107, 0.0127, 0.0146, 0.0131, 0.0141, 0.0154, 0.8842,\n",
      "        0.0112], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.884619414806366\n",
      "all probabilities tensor([0.0108, 0.0132, 0.0106, 0.0126, 0.0145, 0.0130, 0.0140, 0.0154, 0.8846,\n",
      "        0.0112], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8849993348121643\n",
      "all probabilities tensor([0.0107, 0.0132, 0.0106, 0.0126, 0.0145, 0.0130, 0.0140, 0.0153, 0.8850,\n",
      "        0.0111], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8853771686553955\n",
      "all probabilities tensor([0.0107, 0.0131, 0.0106, 0.0126, 0.0144, 0.0129, 0.0139, 0.0153, 0.8854,\n",
      "        0.0111], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8857519030570984\n",
      "all probabilities tensor([0.0106, 0.0131, 0.0105, 0.0125, 0.0144, 0.0129, 0.0139, 0.0152, 0.8858,\n",
      "        0.0110], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8861241936683655\n",
      "all probabilities tensor([0.0106, 0.0130, 0.0105, 0.0125, 0.0144, 0.0129, 0.0138, 0.0152, 0.8861,\n",
      "        0.0110], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8864941596984863\n",
      "all probabilities tensor([0.0106, 0.0130, 0.0105, 0.0124, 0.0143, 0.0128, 0.0138, 0.0151, 0.8865,\n",
      "        0.0110], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8868614435195923\n",
      "all probabilities tensor([0.0105, 0.0129, 0.0104, 0.0124, 0.0143, 0.0128, 0.0137, 0.0151, 0.8869,\n",
      "        0.0109], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8872263431549072\n",
      "all probabilities tensor([0.0105, 0.0129, 0.0104, 0.0124, 0.0143, 0.0127, 0.0137, 0.0151, 0.8872,\n",
      "        0.0109], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8875884413719177\n",
      "all probabilities tensor([0.0104, 0.0129, 0.0104, 0.0123, 0.0142, 0.0127, 0.0137, 0.0150, 0.8876,\n",
      "        0.0108], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8879481554031372\n",
      "all probabilities tensor([0.0104, 0.0128, 0.0104, 0.0123, 0.0142, 0.0126, 0.0136, 0.0150, 0.8879,\n",
      "        0.0108], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8883056640625\n",
      "all probabilities tensor([0.0104, 0.0128, 0.0103, 0.0122, 0.0142, 0.0126, 0.0136, 0.0149, 0.8883,\n",
      "        0.0108], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8886606097221375\n",
      "all probabilities tensor([0.0103, 0.0127, 0.0103, 0.0122, 0.0141, 0.0125, 0.0135, 0.0149, 0.8887,\n",
      "        0.0107], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8890125751495361\n",
      "all probabilities tensor([0.0103, 0.0127, 0.0103, 0.0122, 0.0141, 0.0125, 0.0135, 0.0149, 0.8890,\n",
      "        0.0107], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8893628120422363\n",
      "all probabilities tensor([0.0102, 0.0126, 0.0102, 0.0121, 0.0141, 0.0124, 0.0134, 0.0148, 0.8894,\n",
      "        0.0106], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8897098302841187\n",
      "all probabilities tensor([0.0102, 0.0126, 0.0102, 0.0121, 0.0140, 0.0124, 0.0134, 0.0148, 0.8897,\n",
      "        0.0106], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8900548219680786\n",
      "all probabilities tensor([0.0102, 0.0125, 0.0102, 0.0120, 0.0140, 0.0123, 0.0134, 0.0147, 0.8901,\n",
      "        0.0106], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.890396773815155\n",
      "all probabilities tensor([0.0101, 0.0125, 0.0102, 0.0120, 0.0140, 0.0123, 0.0133, 0.0147, 0.8904,\n",
      "        0.0105], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8907374143600464\n",
      "all probabilities tensor([0.0101, 0.0125, 0.0101, 0.0120, 0.0139, 0.0123, 0.0133, 0.0146, 0.8907,\n",
      "        0.0105], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8910743594169617\n",
      "all probabilities tensor([0.0101, 0.0124, 0.0101, 0.0119, 0.0139, 0.0122, 0.0132, 0.0146, 0.8911,\n",
      "        0.0104], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8914097547531128\n",
      "all probabilities tensor([0.0100, 0.0124, 0.0101, 0.0119, 0.0139, 0.0122, 0.0132, 0.0146, 0.8914,\n",
      "        0.0104], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8917425870895386\n",
      "all probabilities tensor([0.0100, 0.0123, 0.0101, 0.0118, 0.0138, 0.0121, 0.0132, 0.0145, 0.8917,\n",
      "        0.0104], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8920734524726868\n",
      "all probabilities tensor([0.0100, 0.0123, 0.0100, 0.0118, 0.0138, 0.0121, 0.0131, 0.0145, 0.8921,\n",
      "        0.0103], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8924017548561096\n",
      "all probabilities tensor([0.0099, 0.0122, 0.0100, 0.0118, 0.0138, 0.0120, 0.0131, 0.0145, 0.8924,\n",
      "        0.0103], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8927279114723206\n",
      "all probabilities tensor([0.0099, 0.0122, 0.0100, 0.0117, 0.0138, 0.0120, 0.0131, 0.0144, 0.8927,\n",
      "        0.0102], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.89305180311203\n",
      "all probabilities tensor([0.0098, 0.0122, 0.0100, 0.0117, 0.0137, 0.0120, 0.0130, 0.0144, 0.8931,\n",
      "        0.0102], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8933734893798828\n",
      "all probabilities tensor([0.0098, 0.0121, 0.0099, 0.0117, 0.0137, 0.0119, 0.0130, 0.0143, 0.8934,\n",
      "        0.0102], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8936928510665894\n",
      "all probabilities tensor([0.0098, 0.0121, 0.0099, 0.0116, 0.0137, 0.0119, 0.0129, 0.0143, 0.8937,\n",
      "        0.0101], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8940101265907288\n",
      "all probabilities tensor([0.0097, 0.0120, 0.0099, 0.0116, 0.0136, 0.0118, 0.0129, 0.0143, 0.8940,\n",
      "        0.0101], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8943246006965637\n",
      "all probabilities tensor([0.0097, 0.0120, 0.0099, 0.0116, 0.0136, 0.0118, 0.0129, 0.0142, 0.8943,\n",
      "        0.0101], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.894638180732727\n",
      "all probabilities tensor([0.0097, 0.0120, 0.0098, 0.0115, 0.0136, 0.0118, 0.0128, 0.0142, 0.8946,\n",
      "        0.0100], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8949483633041382\n",
      "all probabilities tensor([0.0096, 0.0119, 0.0098, 0.0115, 0.0135, 0.0117, 0.0128, 0.0142, 0.8949,\n",
      "        0.0100], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.895256757736206\n",
      "all probabilities tensor([0.0096, 0.0119, 0.0098, 0.0114, 0.0135, 0.0117, 0.0128, 0.0141, 0.8953,\n",
      "        0.0100], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8955628275871277\n",
      "all probabilities tensor([0.0096, 0.0118, 0.0098, 0.0114, 0.0135, 0.0116, 0.0127, 0.0141, 0.8956,\n",
      "        0.0099], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8958670496940613\n",
      "all probabilities tensor([0.0095, 0.0118, 0.0097, 0.0114, 0.0135, 0.0116, 0.0127, 0.0140, 0.8959,\n",
      "        0.0099], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8961690068244934\n",
      "all probabilities tensor([0.0095, 0.0118, 0.0097, 0.0113, 0.0134, 0.0116, 0.0126, 0.0140, 0.8962,\n",
      "        0.0099], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8964690566062927\n",
      "all probabilities tensor([0.0095, 0.0117, 0.0097, 0.0113, 0.0134, 0.0115, 0.0126, 0.0140, 0.8965,\n",
      "        0.0098], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8967665433883667\n",
      "all probabilities tensor([0.0095, 0.0117, 0.0097, 0.0113, 0.0134, 0.0115, 0.0126, 0.0139, 0.8968,\n",
      "        0.0098], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8970624804496765\n",
      "all probabilities tensor([0.0094, 0.0116, 0.0096, 0.0112, 0.0133, 0.0115, 0.0125, 0.0139, 0.8971,\n",
      "        0.0098], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8973556160926819\n",
      "all probabilities tensor([0.0094, 0.0116, 0.0096, 0.0112, 0.0133, 0.0114, 0.0125, 0.0139, 0.8974,\n",
      "        0.0097], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8976472616195679\n",
      "all probabilities tensor([0.0094, 0.0116, 0.0096, 0.0112, 0.0133, 0.0114, 0.0125, 0.0138, 0.8976,\n",
      "        0.0097], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8979367017745972\n",
      "all probabilities tensor([0.0093, 0.0115, 0.0096, 0.0111, 0.0133, 0.0113, 0.0124, 0.0138, 0.8979,\n",
      "        0.0097], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8982245326042175\n",
      "all probabilities tensor([0.0093, 0.0115, 0.0096, 0.0111, 0.0132, 0.0113, 0.0124, 0.0138, 0.8982,\n",
      "        0.0096], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8985099196434021\n",
      "all probabilities tensor([0.0093, 0.0115, 0.0095, 0.0111, 0.0132, 0.0113, 0.0124, 0.0137, 0.8985,\n",
      "        0.0096], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8987932205200195\n",
      "all probabilities tensor([0.0092, 0.0114, 0.0095, 0.0110, 0.0132, 0.0112, 0.0123, 0.0137, 0.8988,\n",
      "        0.0096], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8990746140480042\n",
      "all probabilities tensor([0.0092, 0.0114, 0.0095, 0.0110, 0.0131, 0.0112, 0.0123, 0.0137, 0.8991,\n",
      "        0.0095], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8993540406227112\n",
      "all probabilities tensor([0.0092, 0.0113, 0.0095, 0.0110, 0.0131, 0.0112, 0.0123, 0.0136, 0.8994,\n",
      "        0.0095], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8996314406394958\n",
      "all probabilities tensor([0.0092, 0.0113, 0.0094, 0.0109, 0.0131, 0.0111, 0.0122, 0.0136, 0.8996,\n",
      "        0.0095], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.8999071717262268\n",
      "all probabilities tensor([0.0091, 0.0113, 0.0094, 0.0109, 0.0131, 0.0111, 0.0122, 0.0136, 0.8999,\n",
      "        0.0094], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.9001805782318115\n",
      "all probabilities tensor([0.0091, 0.0112, 0.0094, 0.0109, 0.0130, 0.0110, 0.0122, 0.0135, 0.9002,\n",
      "        0.0094], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.9004522562026978\n",
      "all probabilities tensor([0.0091, 0.0112, 0.0094, 0.0109, 0.0130, 0.0110, 0.0121, 0.0135, 0.9005,\n",
      "        0.0094], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.9007218480110168\n",
      "all probabilities tensor([0.0091, 0.0112, 0.0094, 0.0108, 0.0130, 0.0110, 0.0121, 0.0135, 0.9007,\n",
      "        0.0093], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.900989830493927\n",
      "all probabilities tensor([0.0090, 0.0111, 0.0093, 0.0108, 0.0130, 0.0109, 0.0121, 0.0134, 0.9010,\n",
      "        0.0093], grad_fn=<SoftmaxBackward0>)\n",
      "probability for target class 0.9012560844421387\n",
      "all probabilities tensor([0.0090, 0.0111, 0.0093, 0.0108, 0.0129, 0.0109, 0.0120, 0.0134, 0.9013,\n",
      "        0.0093], grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_type      = 'mlp'                   \n",
    "checkpoint      = 'in21k_cifar10'       \n",
    "architecture    = 'B_12-Wi_1024'        \n",
    "crop_resolution = 32 \n",
    "\n",
    "# load the models\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = get_models_full(model_type, architecture)\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "loader = get_loader(\n",
    "        dataset,\n",
    "        bs=eval_batch_size,\n",
    "        mode=\"test\",\n",
    "        augment=False,\n",
    "        dev=device,\n",
    "        mixup=0.0,\n",
    "        data_path=data_path,\n",
    "        data_resolution=data_resolution,\n",
    "        crop_resolution=crop_resolution,\n",
    "    )\n",
    "\n",
    "# for activation maximization. Start from total random noise or use\n",
    "# an initial image instead\n",
    "use_init_image = True\n",
    "\n",
    "# generate image using activation maximization\n",
    "dataiter    = iter(loader)\n",
    "ims, labels = next(dataiter)\n",
    "img         = ims[1].unsqueeze(0)\n",
    "label       = labels[1]\n",
    "\n",
    "if use_init_image == False:\n",
    "    img   = None\n",
    "    label = 0\n",
    "else:\n",
    "    label = label.item()\n",
    "\n",
    "init_image1, synthetic_image1 = vis.generate_image(model        = model, \n",
    "                                     target_class = label,\n",
    "                                     epochs       = 250, \n",
    "                                     min_prob     = 0.9, \n",
    "                                     lr           = .01, \n",
    "                                     weight_decay = 5e-2, \n",
    "                                     step_size    = 100, \n",
    "                                     gamma        = 0.9,\n",
    "                                     noise_size   = crop_resolution,\n",
    "                                     model_type   = model_type,\n",
    "                                     img          = img,\n",
    "                                     dataset      = dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /scratch/ffcv/cifar10/val_32.beton\n",
      "probability for target class 0.9999675750732422\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_type      = 'cnn'               \n",
    "architecture    = 'resnet18_' + dataset                      \n",
    "crop_resolution = 32 \n",
    "\n",
    "# load the model\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = get_models_full(model_type, architecture)\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "# initialize loader\n",
    "loader = get_loader(\n",
    "        dataset,\n",
    "        bs=eval_batch_size,\n",
    "        mode=\"test\",\n",
    "        augment=False,\n",
    "        dev=device,\n",
    "        mixup=0.0,\n",
    "        data_path=data_path,\n",
    "        data_resolution=data_resolution,\n",
    "        crop_resolution=crop_resolution,\n",
    "    )\n",
    "\n",
    "# for activation maximization. Start from total random noise or use\n",
    "# an initial image instead\n",
    "use_init_image = True\n",
    "\n",
    "# generate image using activation maximization\n",
    "dataiter    = iter(loader)\n",
    "ims, labels = next(dataiter)\n",
    "img         = ims[1].unsqueeze(0)\n",
    "label       = labels[1]\n",
    "\n",
    "if use_init_image == False:\n",
    "    img   = None\n",
    "    label = 0\n",
    "else:\n",
    "    label = label.item()\n",
    "\n",
    "init_image2, synthetic_image2 = vis.generate_image(model        = model, \n",
    "                                     target_class = label,\n",
    "                                     epochs       = 250, \n",
    "                                     min_prob     = 0.9, \n",
    "                                     lr           = .01, \n",
    "                                     weight_decay = 5e-2, \n",
    "                                     step_size    = 100, \n",
    "                                     gamma        = 0.9,\n",
    "                                     noise_size   = crop_resolution,\n",
    "                                     model_type   = model_type,\n",
    "                                     img          = img,\n",
    "                                     dataset      = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /scratch/ffcv/cifar10/val_32.beton\n",
      "probability for target class 0.7589551210403442\n",
      "probability for target class 0.902209460735321\n",
      "probability for target class 0.9396027326583862\n",
      "probability for target class 0.9532944560050964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kvergopoulos/miniconda3/envs/ffcv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_type      = 'vit'                  \n",
    "architecture    = 'vit_small_patch16_224_' + dataset + '_v7.pth'        \n",
    "crop_resolution = 224 \n",
    "\n",
    "# load the model\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = get_models_full(model_type, architecture)\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "# initialize loader\n",
    "loader = get_loader(\n",
    "        dataset,\n",
    "        bs=eval_batch_size,\n",
    "        mode=\"test\",\n",
    "        augment=False,\n",
    "        dev=device,\n",
    "        mixup=0.0,\n",
    "        data_path=data_path,\n",
    "        data_resolution=data_resolution,\n",
    "        crop_resolution=crop_resolution,\n",
    "    )\n",
    "\n",
    "# for activation maximization. Start from total random noise or use\n",
    "# an initial image instead\n",
    "use_init_image = True\n",
    "\n",
    "# generate image using activation maximization\n",
    "dataiter    = iter(loader)\n",
    "ims, labels = next(dataiter)\n",
    "img         = ims[1].unsqueeze(0)\n",
    "label       = labels[1]\n",
    "\n",
    "if use_init_image == False:\n",
    "    img   = None\n",
    "    label = 0\n",
    "else:\n",
    "    label = label.item()\n",
    "\n",
    "init_image3, synthetic_image3 = vis.generate_image(model        = model, \n",
    "                                     target_class = label,\n",
    "                                     epochs       = 150, \n",
    "                                     min_prob     = 0.9, \n",
    "                                     lr           = .01, \n",
    "                                     weight_decay = 5e-2, \n",
    "                                     step_size    = 100, \n",
    "                                     gamma        = 0.9,\n",
    "                                     noise_size   = crop_resolution,\n",
    "                                     model_type   = model_type,\n",
    "                                     img          = img,\n",
    "                                     dataset      = dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm original image mlp 0.705284059047699\n",
      "norm original image mlp 0.0\n",
      "norm original image mlp 0.08486096560955048\n"
     ]
    }
   ],
   "source": [
    "print(f'norm original image mlp {torch.norm(init_image1 - synthetic_image1)}')\n",
    "print(f'norm original image cnn {torch.norm(init_image2 - synthetic_image2)}')\n",
    "print(f'norm original image vit {torch.norm(init_image3 - synthetic_image3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n",
      "Loading /scratch/ffcv/cifar10/val_32.beton\n"
     ]
    }
   ],
   "source": [
    "#model_type      = 'vit'                  \n",
    "#architecture    = 'vit_small_patch16_224_' + dataset + '_v7.pth'        \n",
    "#crop_resolution = 32 \n",
    "\n",
    "#model_type      = 'cnn'               \n",
    "#architecture    = 'resnet18_' + dataset                      \n",
    "#crop_resolution = 32 \n",
    "\n",
    "model_type      = 'mlp'                   \n",
    "checkpoint      = 'in21k_cifar10'       \n",
    "architecture    = 'B_12-Wi_1024'        \n",
    "crop_resolution = 32 \n",
    "\n",
    "# load the model\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = get_models_full(model_type, architecture)\n",
    "model.to(device)\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "\n",
    "# initialize loader\n",
    "loader = get_loader(\n",
    "        dataset,\n",
    "        bs=eval_batch_size,\n",
    "        mode=\"test\",\n",
    "        augment=False,\n",
    "        dev=device,\n",
    "        mixup=0.0,\n",
    "        data_path=data_path,\n",
    "        data_resolution=data_resolution,\n",
    "        crop_resolution=crop_resolution,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if model_type == 'cnn':\n",
    "    modules = ['conv1', 'layer1.0.conv1']\n",
    "    \n",
    "if model_type == 'vit':\n",
    "    modules = ['1.blocks.0.mlp.fc1', '1.blocks.1.mlp.fc1']\n",
    "\n",
    "if model_type == 'mlp':\n",
    "    modules = ['1.blocks.0.block.0', '1.blocks.2.block.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter    = iter(loader)\n",
    "ims, labels = next(dataiter)\n",
    "img         = ims[1].unsqueeze(0)\n",
    "label       = labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=1024, out_features=4096, bias=True)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kvergopoulos/miniconda3/envs/ffcv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0055639720521867275\n",
      "0.0034382829908281565\n",
      "0.0033695208840072155\n",
      "0.0033074934035539627\n",
      "0.0032501069363206625\n",
      "0.0031960688065737486\n",
      "0.0031445161439478397\n",
      "0.0030949003994464874\n",
      "0.0030468327458947897\n",
      "0.003000053111463785\n",
      "0.0029544320423156023\n",
      "0.002909927163273096\n",
      "0.002866314025595784\n",
      "0.0028235716745257378\n",
      "0.0027816379442811012\n",
      "0.0027406122535467148\n",
      "0.002700402867048979\n",
      "0.002660934114828706\n",
      "0.002622270490974188\n",
      "0.0025843472685664892\n",
      "0.0025471036788076162\n",
      "0.0025105313397943974\n",
      "0.002474620472639799\n",
      "0.002439410425722599\n",
      "0.0024049035273492336\n",
      "0.002371030393987894\n",
      "0.0023378413170576096\n",
      "0.0023053584154695272\n",
      "0.0022735740058124065\n",
      "0.002242427784949541\n",
      "0.002211854327470064\n",
      "0.0021818990353494883\n",
      "0.002152499742805958\n",
      "0.0021236443426460028\n",
      "0.002095339121297002\n",
      "0.0020675675477832556\n",
      "0.0020403119269758463\n",
      "0.002013561548665166\n",
      "0.0019873410928994417\n",
      "0.0019616277422755957\n",
      "0.0019363904139027\n",
      "0.0019339034333825111\n",
      "0.0019314208766445518\n",
      "0.0019289421616122127\n",
      "0.0019264690345153213\n",
      "0.0019240000983700156\n",
      "0.001921535935252905\n",
      "0.0019190764287486672\n",
      "0.001916620647534728\n",
      "0.001914170105010271\n",
      "0.0019117242190986872\n",
      "0.00190928322263062\n",
      "0.0019068459514528513\n",
      "0.0019044129876419902\n",
      "0.001901987474411726\n",
      "0.001899569178931415\n",
      "0.001897155772894621\n",
      "0.0018947466742247343\n",
      "0.0018923424649983644\n",
      "0.0018899423303082585\n",
      "0.0018875462701544166\n",
      "0.0018851544009521604\n",
      "0.00188276800327003\n",
      "0.0018803855637088418\n",
      "0.0018780077807605267\n",
      "0.0018756338395178318\n",
      "0.0018732647877186537\n",
      "0.0018709010910242796\n",
      "0.0018685399554669857\n",
      "0.0018661832436919212\n",
      "0.0018638318870216608\n",
      "0.0018614860018715262\n",
      "0.0018591454718261957\n",
      "0.0018568086670711637\n",
      "0.0018544759368523955\n",
      "0.0018521485617384315\n",
      "0.0018498257268220186\n",
      "0.0018475104589015245\n",
      "0.001845200196839869\n",
      "0.0018428950570523739\n",
      "0.0018405941082164645\n",
      "0.0018403639551252127\n",
      "0.0018401347333565354\n",
      "0.0018399044638499618\n",
      "0.0018396747764199972\n",
      "0.0018394453218206763\n",
      "0.0018392151687294245\n",
      "0.0018389865290373564\n",
      "0.0018387569580227137\n",
      "0.0018385269213467836\n",
      "0.0018382976995781064\n",
      "0.0018380682449787855\n",
      "0.0018378382083028555\n",
      "0.0018376094521954656\n",
      "0.0018373803468421102\n",
      "0.0018371507758274674\n",
      "0.0018369226017966866\n",
      "0.0018366931471973658\n",
      "0.0018364640418440104\n",
      "0.0018362351693212986\n",
      "0.0018360060639679432\n",
      "0.001835777424275875\n",
      "0.0018355482025071979\n",
      "0.0018353188643231988\n",
      "0.001835089991800487\n",
      "0.001834861934185028\n",
      "0.0018346329452469945\n",
      "0.001834403839893639\n",
      "0.0018341755494475365\n",
      "0.0018339470261707902\n",
      "0.0018337182700634003\n",
      "0.0018334895139560103\n",
      "0.0018332615727558732\n",
      "0.001833032933063805\n",
      "0.0018328044097870588\n",
      "0.0018325758865103126\n",
      "0.0018323477124795318\n",
      "0.001832119538448751\n",
      "0.0018318910151720047\n",
      "0.0018316626083105803\n",
      "0.0018314351327717304\n",
      "0.001831412548199296\n",
      "0.0018313891487196088\n",
      "0.0018313664477318525\n",
      "0.001831343863159418\n",
      "0.0018313211621716619\n",
      "0.0018312979955226183\n",
      "0.0018312750617042184\n",
      "0.001831252477131784\n",
      "0.0018312296597287059\n",
      "0.0018312069587409496\n",
      "0.0018311841413378716\n",
      "0.0018311607418581843\n",
      "0.0018311376916244626\n",
      "0.0018311148742213845\n",
      "0.0018310921732336283\n",
      "0.0018310697050765157\n",
      "0.001831046654842794\n",
      "0.0018310240702703595\n",
      "0.0018310011364519596\n",
      "0.0018309787847101688\n",
      "0.0018309559673070908\n",
      "0.001830932917073369\n",
      "0.0018309102160856128\n",
      "0.0018308875150978565\n",
      "0.0018308637663722038\n",
      "0.001830841414630413\n",
      "0.001830818597227335\n",
      "0.0018307955469936132\n",
      "0.0018307731952518225\n",
      "Linear(in_features=1024, out_features=4096, bias=True)\n",
      "0.02162271924316883\n",
      "0.004663290921598673\n",
      "0.004252454731613398\n",
      "0.003947064746171236\n",
      "0.003716355189681053\n",
      "0.0035382702481001616\n",
      "0.0033978275023400784\n",
      "0.0032842785585671663\n",
      "0.0031904703937470913\n",
      "0.003110793884843588\n",
      "0.003041396616026759\n",
      "0.002979925600811839\n",
      "0.0029242250602692366\n",
      "0.0028730507474392653\n",
      "0.0028253751806914806\n",
      "0.002780582057312131\n",
      "0.002738232258707285\n",
      "0.0026980021502822638\n",
      "0.00265955226495862\n",
      "0.0026226243935525417\n",
      "0.002587168477475643\n",
      "0.002552918391302228\n",
      "0.0025197751820087433\n",
      "0.002487712539732456\n",
      "0.002456645481288433\n",
      "0.00242648646235466\n",
      "0.002397197298705578\n",
      "0.002368754707276821\n",
      "0.0023411004804074764\n",
      "0.002314196666702628\n",
      "0.002287996467202902\n",
      "0.0022624689154326916\n",
      "0.002237604930996895\n",
      "0.002213370054960251\n",
      "0.0021897307597100735\n",
      "0.0021666642278432846\n",
      "0.002144154394045472\n",
      "0.0021222420036792755\n",
      "0.002100883750244975\n",
      "0.0020800745114684105\n",
      "0.002059787977486849\n",
      "0.0020577942486852407\n",
      "0.0020558075048029423\n",
      "0.002053823322057724\n",
      "0.0020518454257398844\n",
      "0.002049872186034918\n",
      "0.0020479026716202497\n",
      "0.0020459366496652365\n",
      "0.0020439752843230963\n",
      "0.0020420183427631855\n",
      "0.0020400667563080788\n",
      "0.002038119826465845\n",
      "0.002036175923421979\n",
      "0.0020342357456684113\n",
      "0.002032302087172866\n",
      "0.002030370756983757\n",
      "0.0020284426864236593\n",
      "0.0020265213679522276\n",
      "0.002024604706093669\n",
      "0.0020226892083883286\n",
      "0.002020779997110367\n",
      "0.0020188752096146345\n",
      "0.002016973914578557\n",
      "0.0020150779746472836\n",
      "0.0020131857600063086\n",
      "0.0020112995989620686\n",
      "0.0020094166975468397\n",
      "0.002007538452744484\n",
      "0.0020056632347404957\n",
      "0.002003792906180024\n",
      "0.0020019267685711384\n",
      "0.002000063192099333\n",
      "0.001998205902054906\n",
      "0.001996350474655628\n",
      "0.00199449947103858\n",
      "0.001992652425542474\n",
      "0.001990809105336666\n",
      "0.0019889704417437315\n",
      "0.001987135037779808\n",
      "0.0019853031262755394\n",
      "0.001983475172892213\n",
      "0.0019832924008369446\n",
      "0.0019831100944429636\n",
      "0.0019829284865409136\n",
      "0.001982745248824358\n",
      "0.0019825631752610207\n",
      "0.001982380636036396\n",
      "0.0019821987953037024\n",
      "0.001982017420232296\n",
      "0.0019818346481770277\n",
      "0.001981652807444334\n",
      "0.001981470501050353\n",
      "0.001981288893148303\n",
      "0.0019811068195849657\n",
      "0.0019809254445135593\n",
      "0.001980742672458291\n",
      "0.0019805608317255974\n",
      "0.00198037875816226\n",
      "0.001980196451768279\n",
      "0.0019800150766968727\n",
      "0.001979833235964179\n",
      "0.0019796513952314854\n",
      "0.0019794690888375044\n",
      "0.001979287713766098\n",
      "0.001979105407372117\n",
      "0.0019789249636232853\n",
      "0.0019787426572293043\n",
      "0.0019785617478191853\n",
      "0.001978380372747779\n",
      "0.0019781996961683035\n",
      "0.001978017156943679\n",
      "0.00197783624753356\n",
      "0.0019776546396315098\n",
      "0.0019774732645601034\n",
      "0.001977292587980628\n",
      "0.0019771107472479343\n",
      "0.001976929372176528\n",
      "0.0019767482299357653\n",
      "0.001976567320525646\n",
      "0.001976386643946171\n",
      "0.001976204803213477\n",
      "0.001976186875253916\n",
      "0.001976169180124998\n",
      "0.001976151019334793\n",
      "0.0019761326257139444\n",
      "0.001976114697754383\n",
      "0.0019760960713028908\n",
      "0.0019760779105126858\n",
      "0.0019760606810450554\n",
      "0.0019760415889322758\n",
      "0.0019760236609727144\n",
      "0.0019760059658437967\n",
      "0.0019759880378842354\n",
      "0.0019759703427553177\n",
      "0.0019759517163038254\n",
      "0.001975933788344264\n",
      "0.0019759165588766336\n",
      "0.0019758979324251413\n",
      "0.0019758795388042927\n",
      "0.001975861145183444\n",
      "0.001975842984393239\n",
      "0.0019758245907723904\n",
      "0.0019758071284741163\n",
      "0.001975789200514555\n",
      "0.0019757712725549936\n",
      "0.0019757531117647886\n",
      "0.001975735416635871\n",
      "0.001975717255845666\n",
      "0.0019756993278861046\n",
      "0.0019756813999265432\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1600x1600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vis.feature_inversion(model         = model, \n",
    "                      modules_names = modules, \n",
    "                      img           = img,\n",
    "                      noise_size    = crop_resolution,\n",
    "                      epochs        = 150, \n",
    "                      lr            = 1000,\n",
    "                      step_size     = 100,\n",
    "                      gamma         = 0.6,\n",
    "                      mu            = 1e-1,\n",
    "                      device        = device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
