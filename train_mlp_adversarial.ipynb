{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import timm\n",
    "import detectors\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from ffcv.fields import BytesField, IntField, RGBImageField\n",
    "from ffcv.writer import DatasetWriter\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "from data_utils.data_stats import *\n",
    "from data_utils.dataloader import get_loader\n",
    "from data_utils.dataset_to_beton import get_dataset\n",
    "from models.networks import get_model\n",
    "from utils.metrics import topk_acc, real_acc, AverageMeter\n",
    "\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create adversarial examples for trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_and_model(dataset, model, data_path='/scratch/ffcv/', partition = 'test', augment = True):\n",
    "    \"\"\"\n",
    "    This function retrieves the data, model and feature extractor (if needed) based on the provided information.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (str): The name of the dataset to retrieve (can be cifar10, cifar100 or imagenet).\n",
    "    model (str): The name of the model to retrieve (can be mlp, cnn or vit; only mlp is supported for dataset imagenet).\n",
    "    data_path (str): The path to the data.\n",
    "\n",
    "    Returns (as a tuple):\n",
    "    data_loader (DataLoader): The retrieved data loader.\n",
    "    model (Model): The retrieved model.\n",
    "\n",
    "    Raises:\n",
    "    AssertionError: If the dataset or model is not supported.\n",
    "    \"\"\"\n",
    "\n",
    "    assert dataset in ('cifar10', 'cifar100', 'imagenet'), f'dataset {dataset} is currently not supported by this function'\n",
    "    assert model in ('mlp', 'cnn', 'vit'), f'model {model} is currently not supported by this function'\n",
    "\n",
    "    num_classes = CLASS_DICT[dataset]\n",
    "    eval_batch_size = 100\n",
    "\n",
    "    if dataset == 'imagenet':\n",
    "        data_resolution = 64\n",
    "        assert model == 'mlp', f'imagenet dataset is only supported by mlp model'\n",
    "    else:\n",
    "        data_resolution = 32\n",
    "\n",
    "    crop_resolution = data_resolution\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if device == 'cuda':\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "    if model == 'mlp':\n",
    "        architecture = 'B_12-Wi_1024'\n",
    "        checkpoint = 'in21k_' + dataset\n",
    "        model = get_model(architecture=architecture, resolution=64, num_classes=num_classes, checkpoint=checkpoint)\n",
    "\n",
    "    if model == 'cnn':\n",
    "        architecture = 'resnet18_' + dataset\n",
    "        model = timm.create_model(architecture, pretrained=True)\n",
    "\n",
    "    if model == 'vit':\n",
    "        architecture = 'vit_small_patch16_224_' + dataset + '_v7.pth'\n",
    "        model = torch.load(architecture)\n",
    "\n",
    "    data_loader = get_loader(\n",
    "        dataset,\n",
    "        bs=eval_batch_size,\n",
    "        mode=partition,\n",
    "        augment=augment,\n",
    "        dev=device,\n",
    "        mixup=0.0,\n",
    "        data_path=data_path,\n",
    "        data_resolution=data_resolution,\n",
    "        crop_resolution=crop_resolution,\n",
    "    )\n",
    "    model.cuda()\n",
    "    return data_loader, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(torch.nn.Module): \n",
    "    def __init__(self, shape=224): \n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = shape \n",
    "        \n",
    "    def forward(self, x): \n",
    "        shape = self.shape\n",
    "        x = transforms.functional.resize(x, size=(shape, shape))\n",
    "        \n",
    "        #if shape == 64, its an mlp\n",
    "        if shape == 64:\n",
    "            #x = torch.reshape(x, shape=(-1,))\n",
    "            x = torch.reshape(x, shape=(x.shape[0],-1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor, mean, std):\n",
    "    \"\"\"\n",
    "    Denormalize a tensor.\n",
    "\n",
    "    Parameters:\n",
    "    tensor (torch.Tensor): The tensor to denormalize.\n",
    "    mean (float or sequence): The mean used for normalization.\n",
    "    std (float or sequence): The standard deviation used for normalization.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The denormalized tensor.\n",
    "    \"\"\"\n",
    "    return tensor*std[1]+mean[1]\n",
    "\n",
    "def normalize(tensor, mean, std):\n",
    "    \"\"\"\n",
    "    Normalize a tensor.\n",
    "\n",
    "    Parameters:\n",
    "    tensor (torch.Tensor): The tensor to normalize.\n",
    "    mean (float or sequence): The mean used for normalization.\n",
    "    std (float or sequence): The standard deviation used for normalization.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The normalized tensor.\n",
    "    \"\"\"\n",
    "    return (tensor-mean[1])/std[1]\n",
    "\n",
    "def pgd(model, dataset, x_batch, label, eps, k, eps_step):\n",
    "    \"\"\"\n",
    "    Performs the Projected Gradient Descent (PGD) for adversarial attacks.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model to attack.\n",
    "    dataset (str): The name of the dataset used (can be cifar10, cifar100 or imagenet).\n",
    "    x_batch (torch.Tensor): The input tensor.\n",
    "    label (torch.Tensor): The true labels for the input tensor.\n",
    "    eps (float): The maximum perturbation for PGD.\n",
    "    k (int): The number of steps for PGD.\n",
    "    eps_step (float): The step size for each iteration.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The adversarially perturbed input tensor.\n",
    "    \"\"\"   \n",
    "    mean, std = MEAN_DICT[dataset]/255, STD_DICT[dataset]/255\n",
    "\n",
    "    x = x_batch.clone().detach_()\n",
    "    x = denormalize(x, mean, std)\n",
    "    x_adv = x + eps * (2*torch.rand_like(x) - 1)\n",
    "    x_adv.clamp_(min=0., max=1.)\n",
    "    \n",
    "    for _ in range(int(k)):\n",
    "        x_adv = normalize(x_adv, mean, std).detach_()\n",
    "        x_adv.requires_grad_()\n",
    "        model.zero_grad()\n",
    "        loss = torch.nn.CrossEntropyLoss()(model(x_adv), label)\n",
    "        loss.backward()\n",
    "        perturbation = eps_step * x_adv.grad.sign()\n",
    "\n",
    "        x_adv = denormalize(x_adv, mean, std)\n",
    "        x_adv = x + (x_adv + perturbation - x).clamp_(min=-eps, max=eps)\n",
    "        x_adv.clamp_(min=0, max=1)\n",
    "\n",
    "\n",
    "    return normalize(x_adv.detach(), mean, std)\n",
    "\n",
    "def fgsm_untargeted(model, dataset, x_batch, label, eps):\n",
    "    \"\"\"\n",
    "    Performs the Fast Gradient Sign Method (FGSM) for untargeted adversarial attacks.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model to attack.\n",
    "    dataset (str): The name of the dataset used (can be cifar10, cifar100 or imagenet).\n",
    "    x_batch (torch.Tensor): The input tensor.\n",
    "    label (torch.Tensor): The true labels for the input tensor.\n",
    "    eps (float): The step size for the FGSM attack.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The adversarially perturbed input tensor.\n",
    "    \"\"\"\n",
    "    mean, std = MEAN_DICT[dataset]/255, STD_DICT[dataset]/255\n",
    "\n",
    "    x = x_batch.clone().detach_()\n",
    "    x.requires_grad_()\n",
    "    model.zero_grad()\n",
    "    loss = torch.nn.CrossEntropyLoss()(model(x), label)\n",
    "    loss.backward()\n",
    "    perturbation = eps * x.grad.sign()\n",
    "\n",
    "    out = denormalize(x, mean, std) + perturbation\n",
    "    out = out.clamp_(min=0, max=1)\n",
    "        \n",
    "    return normalize(out, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_adversarial(model, dataset, loader, eps, mode, is_mlp = False, is_vit = False, modelname = 'MLP', datasetname = 'cifar10'):\n",
    "    model.eval()\n",
    "    total_adv_acc, total_adv_top5 = AverageMeter(), AverageMeter()\n",
    "    batchnumber = 0\n",
    "    if is_mlp:\n",
    "        model = torch.nn.Sequential(Reshape(64), model)\n",
    "    if is_vit:\n",
    "        model = torch.nn.Sequential(Reshape(224), model)\n",
    "        return\n",
    "    for ims, targs in tqdm(loader, desc=\"Evaluation\"):            \n",
    "        if mode ==\"fgsm\":\n",
    "            adv_ims = fgsm_untargeted(model, dataset, ims, targs, eps)\n",
    "            path = './adv_examples_train/' + modelname + '/' + datasetname + '/' + mode + '/' + str(eps) + 'Batch' + str(batchnumber)\n",
    "            batchnumber += 1\n",
    "            torch.save(adv_ims, path)\n",
    "        if mode == \"pgd\":\n",
    "            adv_ims = pgd(model, dataset, ims, targs, eps=eps, k=5, eps_step=eps/2)\n",
    "            path = './adv_examples_train/' + modelname + '/' + datasetname + '/' + mode + '/' + str(eps) + 'Batch' + str(batchnumber)\n",
    "            batchnumber += 1\n",
    "            torch.save(adv_ims, path)\n",
    "        adv_preds = model(adv_ims)\n",
    "        adv_acc, adv_top5 = topk_acc(adv_preds, targs, k=5, avg=True)\n",
    "        total_adv_acc.update(adv_acc, ims.shape[0])\n",
    "        total_adv_top5.update(adv_top5, ims.shape[0])\n",
    "\n",
    "    return (\n",
    "        total_adv_acc.get_avg(percentage=True),\n",
    "        total_adv_top5.get_avg(percentage=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now starting: fgsm on mlp with cifar100\n",
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n",
      "Loading ./beton/cifar100\\ffcv\\train\\train_32.beton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/1 [00:00<?, ?it/s]c:\\Users\\merci\\miniconda3\\envs\\ffcv\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "Evaluation: 100%|██████████| 500/500 [00:17<00:00, 28.62it/s]\n",
      "Evaluating: 100%|██████████| 1/1 [00:17<00:00, 17.47s/it]\n"
     ]
    }
   ],
   "source": [
    "#USE BATCH SIZE 100\n",
    "\n",
    "#Make adversarial examples for IMAGENET maybe.... Or others, like cifar testset\n",
    "\n",
    "eps_range = 0.025\n",
    "steps = 12\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "for modelname in ['mlp']:\n",
    "    is_mlp = modelname == 'mlp'\n",
    "    is_vit = modelname == 'vit'\n",
    "    for datasetname in ['cifar100']:\n",
    "        for methodname in ['fgsm']:\n",
    "            adv_acc = []\n",
    "            adv_top5 = []\n",
    "            print('Now starting: ' + methodname +' on ' + modelname + ' with ' + datasetname)\n",
    "            data_loader, model = get_data_and_model(dataset=datasetname, model=modelname, data_path='./beton/', partition='train')\n",
    "            #all_eps = np.arange(0,0.26,0.0125)\n",
    "            all_eps = [0.05]\n",
    "            for eps in tqdm(all_eps, desc=\"Evaluating\"):\n",
    "                test_adv_acc, test_adv_top5 = test_adversarial(model, datasetname, data_loader, eps, methodname, is_vit = is_vit, is_mlp= is_mlp, modelname= modelname, datasetname= datasetname)\n",
    "                adv_acc.append(test_adv_acc)\n",
    "                adv_top5.append(test_adv_top5)\n",
    "\n",
    "            #name = methodname + '_' + modelname + '_' + datasetname + '_zoomedin_'\n",
    "            #np.save('accuracy_' + name, adv_acc)\n",
    "            #np.save('top5_' + name, adv_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, opt, scheduler, loss_fn, epoch, train_loader, mode, args):\n",
    "    start = time.time()\n",
    "    model.train()\n",
    "\n",
    "    total_acc, total_top5 = AverageMeter(), AverageMeter()\n",
    "    total_loss = AverageMeter()\n",
    "\n",
    "    for step, (ims, targs) in enumerate(tqdm(train_loader, desc=\"Training epoch: \" + str(epoch))):\n",
    "        #ims = torch.reshape(ims, (ims.shape[0], -1))\n",
    "\n",
    "        #load adversarial examples\n",
    "        path ='./adv_examples_train/' + modelname + '/' + datasetname + '/' + mode + '/' + str(eps) + 'Batch' + str(step)\n",
    "        ims_adversarial = torch.load(path).cuda()\n",
    "        #ims_adversarial = torch.reshape(ims_adversarial, (ims.shape[0], -1))\n",
    "\n",
    "        ims = ims.cuda()\n",
    "        #concat the two tensors so we can backprop in one go\n",
    "        ims = torch.concat((ims,ims_adversarial), 0)\n",
    "        targs = torch.concat((targs,targs), 0)\n",
    "        preds = model(ims).cuda()\n",
    "\n",
    "        loss = loss_fn(preds, targs)\n",
    "        targs_perm = None\n",
    "\n",
    "        acc, top5 = topk_acc(preds, targs, targs_perm, k=5, avg=True)\n",
    "        total_acc.update(acc, ims.shape[0])\n",
    "        total_top5.update(top5, ims.shape[0])\n",
    "      \n",
    "        loss.backward()\n",
    "        \n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "\n",
    "        total_loss.update(loss.item(), ims.shape[0])\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    scheduler.step()\n",
    "# Define a test function that evaluates test accuracy\n",
    "@torch.no_grad()\n",
    "def test(model, loader):\n",
    "\n",
    "    model.eval()\n",
    "    total_acc, total_top5 = AverageMeter(), AverageMeter()\n",
    "\n",
    "    for ims, targs in tqdm(loader, desc=\"Evaluation\"):\n",
    "        \n",
    "        ims = ims.cuda()\n",
    "        \n",
    "        preds = model(ims).cuda()\n",
    "        targs = targs.to(\"cuda\")\n",
    "        acc = real_acc(preds, targs, k=5, avg=True)\n",
    "        top5 = 0\n",
    "\n",
    "        total_acc.update(acc, ims.shape[0])\n",
    "        total_top5.update(top5, ims.shape[0])\n",
    "\n",
    "\n",
    "    return (\n",
    "        total_acc.get_avg(percentage=True),\n",
    "        total_top5.get_avg(percentage=True),\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n",
      "Loading ./beton/imagenet\\ffcv\\train\\train_64.beton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epoch: 0: 100%|██████████| 12811/12811 [10:40<00:00, 19.99it/s]\n"
     ]
    }
   ],
   "source": [
    "#train the network on the adversarial examples.\n",
    "modelname = 'mlp'\n",
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "#hani afach n random gnoh wells eh ned viel epochs sind\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 10,0.05)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "datasetname = 'imagenet'\n",
    "epochs = 10\n",
    "data_loader, model = get_data_and_model(dataset=datasetname, model=modelname, data_path='./beton/', partition='train')\n",
    "model = torch.nn.Sequential(Reshape(64), model)\n",
    "mode = 'fgsm'\n",
    "for x in range(epochs): \n",
    "    train(model, optimizer, scheduler, loss_function, x, data_loader, mode, args = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n",
      "Loading ./beton/imagenet\\ffcv\\val\\val_64.beton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 500/500 [00:05<00:00, 87.73it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy         44.1060\n",
      "Top 5 Test Accuracy           0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_loader, m = get_data_and_model(dataset=datasetname, model=modelname, data_path='./beton/', partition='test', augment = False)\n",
    "test_acc, test_top5 = test(model, data_loader)\n",
    "\n",
    "# Print all the stats\n",
    "print(\"Test Accuracy        \", \"{:.4f}\".format(test_acc))\n",
    "print(\"Top 5 Test Accuracy          \", \"{:.4f}\".format(test_top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "name = 'adversarialTrained_' + str(epochs) +'_epochs_' + modelname +'on_' + datasetname\n",
    "torch.save(model, name +'.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
