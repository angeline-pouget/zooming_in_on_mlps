{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Fall 2023 Course Project - Zooming in on MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import timm\n",
    "import detectors\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from ffcv.fields import BytesField, IntField, RGBImageField\n",
    "from ffcv.writer import DatasetWriter\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "from data_utils.data_stats import *\n",
    "from data_utils.dataloader import get_loader\n",
    "from data_utils.dataset_to_beton import get_dataset\n",
    "from models.networks import get_model\n",
    "from utils.metrics import topk_acc, real_acc, AverageMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching data loader and model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_and_model(dataset, model, data_path='/scratch/ffcv/'):\n",
    "    \"\"\"\n",
    "    This function retrieves the data, model and feature extractor (if needed) based on the provided information.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (str): The name of the dataset to retrieve (can be cifar10, cifar100 or imagenet).\n",
    "    model (str): The name of the model to retrieve (can be mlp, cnn or vit; only mlp is supported for dataset imagenet).\n",
    "    data_path (str): The path to the data.\n",
    "\n",
    "    Returns (as a tuple):\n",
    "    data_loader (DataLoader): The retrieved data loader.\n",
    "    model (Model): The retrieved model.\n",
    "\n",
    "    Raises:\n",
    "    AssertionError: If the dataset or model is not supported.\n",
    "    \"\"\"\n",
    "\n",
    "    assert dataset in ('cifar10', 'cifar100', 'imagenet'), f'dataset {dataset} is currently not supported by this function'\n",
    "    assert model in ('mlp', 'cnn', 'vit'), f'model {model} is currently not supported by this function'\n",
    "\n",
    "    num_classes = CLASS_DICT[dataset]\n",
    "    eval_batch_size = 1024\n",
    "\n",
    "    if dataset == 'imagenet':\n",
    "        data_resolution = 64\n",
    "        assert model == 'mlp', f'imagenet dataset is only supported by mlp model'\n",
    "    else:\n",
    "        data_resolution = 32\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if device == 'cuda':\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "    if model == 'mlp':\n",
    "        crop_resolution = 64\n",
    "        architecture = 'B_12-Wi_1024'\n",
    "        checkpoint = 'in21k_' + dataset\n",
    "\n",
    "        model = get_model(architecture=architecture, resolution=crop_resolution, num_classes=num_classes, checkpoint=checkpoint)\n",
    "\n",
    "    if model == 'cnn':\n",
    "        crop_resolution = 32\n",
    "        architecture = 'resnet18_' + dataset\n",
    "\n",
    "        model = timm.create_model(architecture, pretrained=True)\n",
    "\n",
    "    if model == 'vit':\n",
    "        crop_resolution = 32\n",
    "\n",
    "        if dataset == 'cifar10':\n",
    "            architecture = 'vit_small_patch16_224_cifar10_v4.pth'\n",
    "            model = torch.load(architecture)\n",
    "\n",
    "        elif dataset == 'cifar100':\n",
    "            architecture = 'vit_small_patch16_224_cifar100_v3.pth'\n",
    "            model = torch.load(architecture)\n",
    "\n",
    "    data_loader = get_loader(\n",
    "        dataset,\n",
    "        bs=eval_batch_size,\n",
    "        mode=\"test\",\n",
    "        augment=False,\n",
    "        dev=device,\n",
    "        mixup=0.0,\n",
    "        data_path=data_path,\n",
    "        data_resolution=data_resolution,\n",
    "        crop_resolution=crop_resolution,\n",
    "    )\n",
    "\n",
    "    return data_loader, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating baseline model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a test function that evaluates test accuracy\n",
    "@torch.no_grad()\n",
    "def test(model, loader, is_mlp = False):\n",
    "    model.eval()\n",
    "    total_acc, total_top5 = AverageMeter(), AverageMeter()\n",
    "\n",
    "    for ims, targs in tqdm(loader, desc=\"Evaluation\"):\n",
    "        if is_mlp:\n",
    "            ims = torch.reshape(ims, (ims.shape[0], -1))\n",
    "        \n",
    "        preds = model(ims)    \n",
    "        acc, top5 = topk_acc(preds, targs, k=5, avg=True)\n",
    "        \n",
    "        total_acc.update(acc, ims.shape[0])\n",
    "        total_top5.update(top5, ims.shape[0])\n",
    "\n",
    "    return (\n",
    "        total_acc.get_avg(percentage=True),\n",
    "        total_top5.get_avg(percentage=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n",
      "Loading /scratch/ffcv/cifar10/val_32.beton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 10/10 [01:06<00:00,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy         94.3900\n",
      "Top 5 Test Accuracy           99.6600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_loader, model = get_data_and_model(dataset='cifar10', model='mlp', data_path='/scratch/ffcv/')\n",
    "test_acc, test_top5 = test(model, data_loader, True)\n",
    "\n",
    "# Print all the stats\n",
    "print(\"Test Accuracy        \", \"{:.4f}\".format(test_acc))\n",
    "print(\"Top 5 Test Accuracy          \", \"{:.4f}\".format(test_top5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate adversarial accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor, mean, std):\n",
    "    \"\"\"\n",
    "    Denormalize a tensor.\n",
    "\n",
    "    Parameters:\n",
    "    tensor (torch.Tensor): The tensor to denormalize.\n",
    "    mean (float or sequence): The mean used for normalization.\n",
    "    std (float or sequence): The standard deviation used for normalization.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The denormalized tensor.\n",
    "    \"\"\"\n",
    "    return tensor*std[1]+mean[1]\n",
    "\n",
    "def normalize(tensor, mean, std):\n",
    "    \"\"\"\n",
    "    Normalize a tensor.\n",
    "\n",
    "    Parameters:\n",
    "    tensor (torch.Tensor): The tensor to normalize.\n",
    "    mean (float or sequence): The mean used for normalization.\n",
    "    std (float or sequence): The standard deviation used for normalization.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The normalized tensor.\n",
    "    \"\"\"\n",
    "    return (tensor-mean[1])/std[1]\n",
    "\n",
    "def pgd(model, dataset, x_batch, label, eps, k, eps_step):\n",
    "    \"\"\"\n",
    "    Performs the Projected Gradient Descent (PGD) for adversarial attacks.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model to attack.\n",
    "    dataset (str): The name of the dataset used (can be cifar10, cifar100 or imagenet).\n",
    "    x_batch (torch.Tensor): The input tensor.\n",
    "    label (torch.Tensor): The true labels for the input tensor.\n",
    "    eps (float): The maximum perturbation for PGD.\n",
    "    k (int): The number of steps for PGD.\n",
    "    eps_step (float): The step size for each iteration.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The adversarially perturbed input tensor.\n",
    "    \"\"\"   \n",
    "    mean, std = MEAN_DICT[dataset]/255, STD_DICT[dataset]/255\n",
    "\n",
    "    x = x_batch.clone().detach_()\n",
    "    x = denormalize(x, mean, std)\n",
    "    x_adv = x + eps * (2*torch.rand_like(x) - 1)\n",
    "    x_adv.clamp_(min=0., max=1.)\n",
    "    \n",
    "    for _ in range(int(k)):\n",
    "        x_adv = normalize(x_adv, mean, std).detach_()\n",
    "        x_adv.requires_grad_()\n",
    "        model.zero_grad()\n",
    "        loss = torch.nn.CrossEntropyLoss()(model(x_adv), label)\n",
    "        loss.backward()\n",
    "        perturbation = eps_step * x_adv.grad.sign()\n",
    "\n",
    "        x_adv = denormalize(x_adv, mean, std)\n",
    "        x_adv = x + (x_adv + perturbation - x).clamp_(min=-eps, max=eps)\n",
    "        x_adv.clamp_(min=0, max=1)\n",
    "\n",
    "    return normalize(x_adv.detach(), mean, std)\n",
    "\n",
    "def fgsm_untargeted(model, dataset, x_batch, label, eps):\n",
    "    \"\"\"\n",
    "    Performs the Fast Gradient Sign Method (FGSM) for untargeted adversarial attacks.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model to attack.\n",
    "    dataset (str): The name of the dataset used (can be cifar10, cifar100 or imagenet).\n",
    "    x_batch (torch.Tensor): The input tensor.\n",
    "    label (torch.Tensor): The true labels for the input tensor.\n",
    "    eps (float): The step size for the FGSM attack.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The adversarially perturbed input tensor.\n",
    "    \"\"\"\n",
    "    mean, std = MEAN_DICT[dataset]/255, STD_DICT[dataset]/255\n",
    "\n",
    "    x = x_batch.clone().detach_()\n",
    "    x.requires_grad_()\n",
    "    model.zero_grad()\n",
    "    loss = torch.nn.CrossEntropyLoss()(model(x), label)\n",
    "    loss.backward()\n",
    "    perturbation = eps * x.grad.sign()\n",
    "\n",
    "    out = denormalize(x, mean, std) + perturbation\n",
    "    out = out.clamp_(min=0, max=1)\n",
    "        \n",
    "    return normalize(out, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_adversarial(model, dataset, loader, eps, mode, is_mlp = False):\n",
    "    model.eval()\n",
    "    total_adv_acc, total_adv_top5 = AverageMeter(), AverageMeter()\n",
    "\n",
    "    for ims, targs in tqdm(loader, desc=\"Evaluation\"):\n",
    "        if is_mlp:\n",
    "            ims = torch.reshape(ims, (ims.shape[0], -1))\n",
    "        targs = targs\n",
    "        if mode ==\"fgsm\":\n",
    "            adv_ims = fgsm_untargeted(model, dataset, ims, targs, eps)\n",
    "        if mode == \"pgd\":\n",
    "            adv_ims = pgd(model, dataset, ims, targs, eps=eps, k=5, eps_step=eps/2)\n",
    "\n",
    "        adv_preds = model(adv_ims)\n",
    "   \n",
    "        adv_acc, adv_top5 = topk_acc(adv_preds, targs, k=5, avg=True)\n",
    "\n",
    "        total_adv_acc.update(adv_acc, ims.shape[0])\n",
    "        total_adv_top5.update(adv_top5, ims.shape[0])\n",
    "\n",
    "    return (\n",
    "        total_adv_acc.get_avg(percentage=True),\n",
    "        total_adv_top5.get_avg(percentage=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% |########################################################################|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load_state output <All keys matched successfully>\n",
      "Loading /scratch/ffcv/cifar10/val_32.beton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 10/10 [03:55<00:00, 23.50s/it]\n",
      "Evaluation: 100%|██████████| 10/10 [03:50<00:00, 23.08s/it]t]\n",
      "Evaluation: 100%|██████████| 10/10 [03:50<00:00, 23.01s/it]t]\n",
      "Evaluation: 100%|██████████| 10/10 [03:49<00:00, 22.96s/it]t]\n",
      "Evaluation: 100%|██████████| 10/10 [03:57<00:00, 23.76s/it]t]\n",
      "Evaluation: 100%|██████████| 10/10 [03:51<00:00, 23.19s/it]t]\n",
      "Evaluation: 100%|██████████| 10/10 [03:49<00:00, 22.97s/it]  \n",
      "Evaluation: 100%|██████████| 10/10 [03:45<00:00, 22.55s/it]\n",
      "Evaluation: 100%|██████████| 10/10 [03:47<00:00, 22.80s/it]\n",
      "Evaluation: 100%|██████████| 10/10 [03:51<00:00, 23.18s/it]\n",
      "Evaluation: 100%|██████████| 10/10 [03:40<00:00, 22.03s/it]]\n",
      "Evaluation: 100%|██████████| 10/10 [03:45<00:00, 22.53s/it]]\n",
      "Evaluation: 100%|██████████| 10/10 [03:44<00:00, 22.43s/it]]\n",
      "Evaluation: 100%|██████████| 10/10 [03:45<00:00, 22.55s/it]]\n",
      "Evaluation: 100%|██████████| 10/10 [03:44<00:00, 22.47s/it]]\n",
      "Evaluation: 100%|██████████| 10/10 [03:44<00:00, 22.47s/it]]\n",
      "Evaluation: 100%|██████████| 10/10 [03:44<00:00, 22.43s/it]it]\n",
      "Evaluation: 100%|██████████| 10/10 [03:48<00:00, 22.81s/it]it]\n",
      "Evaluation: 100%|██████████| 10/10 [03:48<00:00, 22.82s/it]it]\n",
      "Evaluation: 100%|██████████| 10/10 [03:52<00:00, 23.23s/it]it]\n",
      "Evaluation: 100%|██████████| 10/10 [03:50<00:00, 23.08s/it]it]\n",
      "Evaluating: 100%|██████████| 21/21 [1:19:59<00:00, 228.53s/it]\n"
     ]
    }
   ],
   "source": [
    "adv_acc = []\n",
    "adv_top5 = []\n",
    "\n",
    "data_loader, model = get_data_and_model(dataset='cifar10', model='mlp', data_path='/scratch/ffcv/')\n",
    "all_eps = np.arange(0,0.26,0.0125)\n",
    "\n",
    "for eps in tqdm(all_eps, desc=\"Evaluating\"):\n",
    "    test_adv_acc, test_adv_top5 = test_adversarial(model, 'cifar10', data_loader, eps, 'fgsm', is_mlp = True)\n",
    "\n",
    "    adv_acc.append(test_adv_acc)\n",
    "    adv_top5.append(test_adv_top5)\n",
    "\n",
    "# Print all the stats\n",
    "# print(\"Adversarial Accuracy        \", \"{:.4f}\".format(test_adv_acc))\n",
    "# print(\"Top 5 Adversarial Accuracy          \", \"{:.4f}\".format(test_adv_top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79.97999999046326, 26.019999980926514, 17.889999980926515, 14.369999964237213, 11.999999961853028, 9.590000011920928, 7.930000001192093, 6.429999980330467, 5.309999993443489, 4.2399999833107, 3.5700000020861626, 3.169999997019768, 2.8200000017881393, 2.5799999967217446, 2.2399999964237214, 1.9400000011920928, 1.8099999986588955, 1.769999996125698, 1.630000001192093, 1.6399999964237213, 1.540000001490116] [94.95999968528747, 46.41999990940094, 34.599999828338625, 30.959999990463256, 27.91000002861023, 24.249999928474427, 20.80999999284744, 17.940000023841858, 15.400000002384186, 13.429999947547913, 11.879999955892563, 10.56000000357628, 9.559999978542328, 8.67999996304512, 7.960000001192093, 7.36999997138977, 7.149999976158142, 6.849999995231628, 6.599999995231628, 6.429999985694885, 6.169999990463257]\n"
     ]
    }
   ],
   "source": [
    "print(adv_acc, adv_top5) # CIFAR100 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94.39, 61.31000010490418, 55.89999980926514, 52.53999994277954, 48.87999988079071, 44.86, 39.48999993801117, 34.859999876022336, 30.559999980926513, 26.619999890327453, 23.53, 21.01999995470047, 19.069999947547913, 17.229999935626985, 16.15999995946884, 14.920000030994416, 13.999999933242798, 13.309999961853027, 12.599999995231629, 11.92999997496605, 11.639999984502792] [99.66, 78.31999968528747, 74.15000004768372, 74.39999980926514, 74.96000002861022, 74.4499997329712, 73.23999975204468, 70.98000008583068, 68.38999971389771, 65.31999968528747, 62.62000004768372, 60.399999675750735, 58.35999976158142, 57.17000003814697, 55.95999984741211, 55.42000011444092, 54.83999989509582, 54.289999895095825, 54.280000104904175, 54.08999990463257, 54.09999988555908]\n"
     ]
    }
   ],
   "source": [
    "print(adv_acc, adv_top5) # CIFAR10 MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 100.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGiCAYAAADNzj2mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4tElEQVR4nO3deXxU1f3/8fdMlsk+ISHJJCFA2MMmIBKQxVqjoNZqxSq/YovWggsuiLZf6bdK/dYWxVYtSqW1rWgrUG1VWrW4REGFEBQQ2dfIPklYMpN1ssz9/REYiQQlZCZ3Jnk9H495DLn3zs1nzgNm3pxz7rkWwzAMAQAABBGr2QUAAAB8FQEFAAAEHQIKAAAIOgQUAAAQdAgoAAAg6BBQAABA0CGgAACAoENAAQAAQYeAAgAAgg4BBQAABJ0WB5QPP/xQV111lTIyMmSxWPT666832W8Yhh566CGlp6crOjpaeXl52rlzZ5Njjh07psmTJyshIUGJiYm65ZZbVFFR0ao3AgAA2o8WB5TKykqdd955mj9/frP7586dq3nz5mnBggUqLCxUbGysxo8fr5qaGt8xkydP1ubNm/Xuu+/qjTfe0Icffqhp06ad+7sAAADtiqU1Nwu0WCx67bXXdM0110hq7D3JyMjQfffdp/vvv1+S5HK5lJaWpoULF2rSpEnaunWr+vfvr08++UTDhw+XJC1btkxXXHGFDhw4oIyMjNa/KwAAENLC/XmyoqIiOZ1O5eXl+bbZ7Xbl5uaqoKBAkyZNUkFBgRITE33hRJLy8vJktVpVWFio733ve6ed1+PxyOPx+H72er06duyYkpOTZbFY/PkWAABAgBiGofLycmVkZMhq/fpBHL8GFKfTKUlKS0trsj0tLc23z+l0KjU1tWkR4eFKSkryHfNVc+bM0cMPP+zPUgEAgEn279+vLl26fO0xfg0ogTJr1izNnDnT97PL5VLXrl21f/9+JSQkmFgZAAA4W263W1lZWYqPj//GY/0aUBwOhySpuLhY6enpvu3FxcUaMmSI75iSkpImr6uvr9exY8d8r/8qm80mm8122vaEhAQCCgAAIeZspmf4dR2U7OxsORwO5efn+7a53W4VFhZq1KhRkqRRo0aprKxMa9eu9R3z/vvvy+v1Kjc315/lAACAENXiHpSKigrt2rXL93NRUZE+++wzJSUlqWvXrpoxY4YeeeQR9e7dW9nZ2XrwwQeVkZHhu9InJydHEyZM0NSpU7VgwQLV1dXpzjvv1KRJk7iCBwAASDqHgPLpp5/q4osv9v18cm7IlClTtHDhQv3sZz9TZWWlpk2bprKyMo0ZM0bLli1TVFSU7zUvvfSS7rzzTl1yySWyWq2aOHGi5s2b54e3AwAA2oNWrYNiFrfbLbvdLpfLxRwUAABCREu+v7kXDwAACDoEFAAAEHQIKAAAIOgQUAAAQNAhoAAAgKBDQAEAAEGHgAIAAIIOAQUAAAQdAgoAAAg6BBQAABB0CCgAACDoEFAAAEDQIaCcYtWuI7rv5Q16YdUXZpcCAECHRkA5RdHRSv1r3QG9v63E7FIAAOjQCCinyElvvPXzlsNukysBAKBjI6Ccop8jXhaLVFru0ZEKj9nlAADQYRFQThETGa7uybGSpK30ogAAYBoCylfkpMdLIqAAAGAmAspX9D8xD2Xr4XKTKwEAoOMioHyFb6LsIXpQAAAwCwHlK04GlN2lFfLUN5hcDQAAHRMB5SvS7VGyR0eo3mtoZ3GF2eUAANAhEVC+wmKxMFEWAACTEVCa0T/dLomJsgAAmIWA0oyTPShbDrtMrgQAgI6JgNKMnFMuNTYMw+RqAADoeAgozeidFqdwq0Wu6joddtWYXQ4AAB0OAaUZtvAw9UqNk8REWQAAzEBAOYMvh3kIKAAAtDUCyhl8OVGWgAIAQFsjoJxBDvfkAQDANASUMzgZUL44Wqmq2nqTqwEAoGMhoJxB5zibUuNtMgxpm5NeFAAA2hIB5WtwZ2MAAMxBQPkaXMkDAIA5CChfg5sGAgBgDgLK1+h/ogdlm7NcXi9L3gMA0FYIKF8ju3OsbOFWVdU2aN+xKrPLAQCgwyCgfI3wMKv6OliwDQCAtkZA+QY5DibKAgDQ1ggo34CJsgAAtD0CyjdgyXsAANoeAeUb5GQ0BpSDZdVyVdWZXA0AAB0DAeUbJERFqEunaElMlAUAoK0QUM4CK8oCANC2CChngYACAEDbIqCchf4nr+RxElAAAGgLBJSz0D/dLkna4axQXYPX5GoAAGj/CChnoUunaMXZwlXb4NWe0kqzywEAoN0joJwFq9Wifg4WbAMAoK0QUM4SE2UBAGg7BJSz1P/Egm2shQIAQOARUM4SPSgAALQdAspZ6psWL6tFOlJRq5LyGrPLAQCgXSOgnKXoyDB17xwriRsHAgAQaASUFmCYBwCAtkFAaYH+BBQAANoEAaUFTgaULYcIKAAABBIBpQVODvHsOVKpmroGk6sBAKD9IqC0QFqCTZ1iItTgNbSzuMLscgAAaLcIKC1gsViYKAsAQBsgoLSQbx4KAQUAgIAhoLRQDgEFAICA83tAaWho0IMPPqjs7GxFR0erZ8+e+tWvfiXDMHzHGIahhx56SOnp6YqOjlZeXp527tzp71IC4tQhnlPfEwAA8B+/B5THHntMzz77rJ555hlt3bpVjz32mObOnaunn37ad8zcuXM1b948LViwQIWFhYqNjdX48eNVUxP8S8j3So1TRJhF5TX1OlhWbXY5AAC0S34PKKtWrdLVV1+tK6+8Ut27d9d1112nyy67TGvWrJHU2Hvy1FNP6Re/+IWuvvpqDR48WC+++KIOHTqk119/3d/l+F1kuFU9U+IkseQ9AACB4veAcuGFFyo/P187duyQJG3YsEEff/yxLr/8cklSUVGRnE6n8vLyfK+x2+3Kzc1VQUFBs+f0eDxyu91NHmbqn8GCbQAABFK4v0/4wAMPyO12q1+/fgoLC1NDQ4N+/etfa/LkyZIkp9MpSUpLS2vyurS0NN++r5ozZ44efvhhf5d6zvqnJ+hVHeRSYwAAAsTvPSgvv/yyXnrpJS1atEjr1q3TCy+8oN/+9rd64YUXzvmcs2bNksvl8j3279/vx4pbzjdR1klAAQAgEPzeg/LTn/5UDzzwgCZNmiRJGjRokPbu3as5c+ZoypQpcjgckqTi4mKlp6f7XldcXKwhQ4Y0e06bzSabzebvUs/ZyYCy92iVKjz1irP5vRkBAOjQ/N6DUlVVJau16WnDwsLk9XolSdnZ2XI4HMrPz/ftd7vdKiws1KhRo/xdTkAkxUYqLaExMG2nFwUAAL/z+3/9r7rqKv36179W165dNWDAAK1fv15PPPGEfvzjH0tqXC5+xowZeuSRR9S7d29lZ2frwQcfVEZGhq655hp/lxMw/dMTVOwu1ZZDbp3fLcnscgAAaFf8HlCefvppPfjgg7rjjjtUUlKijIwM3XrrrXrooYd8x/zsZz9TZWWlpk2bprKyMo0ZM0bLli1TVFSUv8sJmJz0BH2wvVRbuNQYAAC/sxghuByq2+2W3W6Xy+VSQkKCKTX8Z8Mh3bV4vYZkJer16aNNqQEAgFDSku9v7sVzjk5OlN3uLFeDN+QyHgAAQY2Aco6yO8cqKsKq6roG7T1aaXY5AAC0KwSUcxRmtaivgzsbAwAQCASUVuifHi9JrCgLAICfEVBawbeiLFfyAADgVwSUVvgyoNCDAgCAPxFQWqGfo3GI57CrRscra02uBgCA9oOA0grxURHqmhQjiV4UAAD8iYDSSjknJspyJQ8AAP5DQGklJsoCAOB/BJRWYqIsAAD+R0Bppf4nAsrOknLV1ntNrgYAgPaBgNJKXTpFKz4qXHUNhnaXVphdDgAA7QIBpZUsFotyHAzzAADgTwQUP8hhyXsAAPyKgOIHXMkDAIB/EVD8oH/Gl3c1NgzD5GoAAAh9BBQ/6JMWL6tFOlZZq5Jyj9nlAAAQ8ggofhAVEaYeKXGSWFEWAAB/IKD4CQu2AQDgPwQUP/Hdk+cQAQUAgNYioPhJf3pQAADwGwKKn5wMKEVHKlVT12ByNQAAhDYCip+kxNuUHBspryFtd7IeCgAArUFA8ROLxcJEWQAA/ISA4ke+ibIEFAAAWoWA4kcnV5SlBwUAgNYhoPjRySGebYfLWfIeAIBWIKD4Uc+UOEWGWVXuqdeB49VmlwMAQMgioPhRRJhVvVJZ8h4AgNYioPiZ787GrCgLAMA5I6D4GZcaAwDQegQUPzt5qfFWJwEFAIBzRUDxs5NL3u8/Vq3ymjqTqwEAIDQRUPwsMSZS6fYoSdI2lrwHAOCcEFAC4GQvChNlAQA4NwSUAGCiLAAArUNACQACCgAArUNACYCTV/Jsc5arvsFrcjUAAIQeAkoAdEuOVXREmDz1Xn1xtNLscgAACDkElAAIs1rU70QvypbDXMkDAEBLEVAChHkoAACcOwJKgBBQAAA4dwSUAOl/csl7AgoAAC1GQAmQvo7GHpRit0dHKzwmVwMAQGghoARInC1c3ZNjJElbmSgLAECLEFACiHkoAACcGwJKABFQAAA4NwSUADoZULYQUAAAaBECSgCdXPJ+V0mFPPUNJlcDAEDoIKAEUGZitBKiwlXvNbSrpMLscgAACBkElACyWCynzEPhSh4AAM4WASXAmCgLAEDLEVACrP/JibKHCCgAAJwtAkqA9c840YPidMswDJOrAQAgNBBQAqxXapzCrBaVVdXJ6a4xuxwAAEICASXAoiLC1DMlVhLzUAAAOFsElDbAlTwAALQMAaUN5DBRFgCAFiGgtIH+XGoMAECLEFDawMkelKKjlaqqrTe5GgAAgh8BpQ2kxNuUEm+TYUhzl22X18vlxgAAfB0CShuZkddbkrRw1Re6a8l61dRx80AAAM4kIAHl4MGDuvHGG5WcnKzo6GgNGjRIn376qW+/YRh66KGHlJ6erujoaOXl5Wnnzp2BKCVoTM7tpqduGKKIMIve/PywfvTXNXJV1ZldFgAAQcnvAeX48eMaPXq0IiIi9N///ldbtmzR7373O3Xq1Ml3zNy5czVv3jwtWLBAhYWFio2N1fjx41VT074XMrtmaKYW3jxC8bZwrSk6pusWrNKhsmqzywIAIOhYDD+vv/7AAw9o5cqV+uijj5rdbxiGMjIydN999+n++++XJLlcLqWlpWnhwoWaNGnSN/4Ot9stu90ul8ulhIQEf5bfJrYeduum59eo2O1RWoJNC28e4ZtICwBAe9WS72+/96D8+9//1vDhw/X9739fqampGjp0qJ577jnf/qKiIjmdTuXl5fm22e125ebmqqCgoNlzejweud3uJo9QlpOeoFfvGK3eqXEqdnt0/YICrdp1xOyyAAAIGn4PKHv27NGzzz6r3r176+2339btt9+uu+++Wy+88IIkyel0SpLS0tKavC4tLc2376vmzJkju93ue2RlZfm77DaXmRitf952oUZkJ6ncU68pz6/R0s8Oml0WAABBwe8Bxev1atiwYfrNb36joUOHatq0aZo6daoWLFhwzuecNWuWXC6X77F//34/Vmwee0yEXvzxCF05OF11DYbuWfKZFqzYzV2PAQAdnt8DSnp6uvr3799kW05Ojvbt2ydJcjgckqTi4uImxxQXF/v2fZXNZlNCQkKTR3sRFRGmpycN1S1jsiVJj/53mx7+zxY1sFYKAKAD83tAGT16tLZv395k244dO9StWzdJUnZ2thwOh/Lz83373W63CgsLNWrUKH+XExKsVose/E5//eLKHEmNa6VMf2kda6UAADosvweUe++9V6tXr9ZvfvMb7dq1S4sWLdKf/vQnTZ8+XZJksVg0Y8YMPfLII/r3v/+tjRs36kc/+pEyMjJ0zTXX+LuckPKTsT30zA+GKjLMqmWbnbrxz4Uqq6o1uywAANqc3y8zlqQ33nhDs2bN0s6dO5Wdna2ZM2dq6tSpvv2GYWj27Nn605/+pLKyMo0ZM0Z/+MMf1KdPn7M6f6hfZvxNVu85qqkvfqrymnr1TInVwptHKCspxuyyAABolZZ8fwckoARaew8okrSjuFxT/rpGh101Som36fmbLtDATLvZZQEAcM5MXQcF/tEnLV6v3TFa/RzxKi336IY/FuijnaVmlwUAQJsgoAQxhz1KL982Shf2TFZlbYNufv4T/WvtAbPLAgAg4AgoQS4hKkILbx6hq4dkqN5r6L5XNmj+B7tYKwUA0K4RUEJAZLhVT14/RLde1EOS9Pjb2/Xg0k2slQIAaLcIKCHCarVo1uU5evi7A2SxSH9fvU+3/X2tqmtZKwUA0P4QUELMlAu769nJwxQZbtW7W4r1gz+v1rFK1koBALQvBJQQNGFguhb9JFf26Ait31emic+uUtGRSrPLAgDAbwgoIWp49yT96/YLlZkYraIjlRr/5If69Ztb5KqqM7s0AABajYASwnqlxum1Oy7U2N6dVdvg1XMfFWnc4x/ozx/tkaeeuSkAgNDFSrLtgGEYWrGjVHPe2qbtxeWSpKykaP1sfD99Z3C6LBaLyRUCAMBS9x1Wg9fQP9fu1+/e2aGSco8k6bwudv38ihzl9kg2uToAQEdHQOngqmrr9ZePirRgxW5VnrgMOS8nTQ9c3k+9UuNMrg4A0FERUCBJKi336Pf5O7R4zX41eA2FWS2adEGWZuT1UUq8zezyAAAdDAEFTewqqdBjy7bp3S3FkqTYyDDddlFP/WRsD0VHhplcHQCgoyCgoFmFe47qN29t1YYDLklSWoJN913aVxPP76IwKxNpAQCBRUDBGXm9ht7YeFiPv71N+49VS5L6psXrgSv66Vt9UrjiBwAQMAQUfCNPfYP+VrBXT7+/S67qxsXdRvdK1qzLczQw025ydQCA9oiAgrPmqqrTMx/s1Aur9qq2wSuLRfrekEzdN76vMhOjzS4PANCOEFDQYvuPVenxt7fr3xsOSZIiw626ZUy2bv9WTyVERZhcHQCgPSCg4Jx9fqBMv35zqwqLjkmSkmIj9bPxfXX98CxZmUgLAGgFAgpaxTAM5W8t0aPLtmlXSYUk6bysRP3q6gEa3CXR3OIAACGLgAK/qGvw6sWCvXry3R2q8NTLYpH+34iu+ullfdUpNtLs8gAAIaYl39/czRhnFBHWOA/l/fsu0veGZsowpEWF+/Tt3y3XkjX75PWGXLYFAIQIelBw1gr3HNVDSzf77pjMsA8AoCUY4kHAMOwDADhXDPEgYL5u2Gcxwz4AAD+hBwWtwrAPAOBsMcSDNsWwDwDgbDDEgzbFsA8AwN/oQYHfMewDAGgOQzwwHcM+AICvYogHpmPYBwDQGvSgoE2cNuzTxa5HrhmkQV3sJlcGAGgr9KAg6OT2SNYbd4/Rg9/przhbuDYccOnq+R/r0f9uU01dg9nlAQCCDAEFbebUYZ/vDE6X15AWrNitK+d9pLV7j5tdHgAgiBBQ0OZSE6L0zA+G6Y8/PF+d42zaXVqp6xas0iNvbFF1Lb0pAAACCkw0foBD780cp2uHNU6i/fPHRbr89x+qcM9Rs0sDAJiMgAJTJcZE6onrh+ivNw2XIyFKXxyt0g1/Wq3ZSzep0lNvdnkAAJMQUBAUvt0vTe/MHKdJF2RJkl4o2KvxT32olbuOmFwZAMAMBBQEjYSoCD06cbD+dssIZSZG68Dxak3+c6FmvbpR5TV1ZpcHAGhDBBQEnbG9U/T2veN048iukqTFa/bpsic/1PLtJSZXBgBoKwQUBKU4W7geuWaQFk8dqa5JMTrsqtFNz3+i+1/ZIFcVvSkA0N4RUBDURvVM1rIZY3Xz6O6yWKR/rj2gS59cofe2FJtdGgAggAgoCHoxkeGafdUAvXLrKPXoHKuSco9+8uKnumfJeh2vrDW7PABAABBQEDKGd0/SW/eM1a3jeshqkZZ+dkiXPrlC/9142OzSAAB+RkBBSImKCNOsK3L06h2j1Ts1TkcqanX7S+t0x0trdaTCY3Z5AAA/IaAgJA3JStQbd4/RnRf3UpjVorc2OnXpEyu09LODCsEbdAMAvoKAgpBlCw/T/eP7aun00cpJT9Dxqjrds+QzTfvbWuamAECII6Ag5A3MtGvp9NG6N6+PIsIsendLsSY+u0r7jlaZXRoA4BwRUNAuRIZbdU9eby2dPkaZidHac6RS1z67Uhv2l5ldGgDgHBBQ0K70z0jQq3dcqP7pCTpSUatJf1qt97exZgoAhBoCCtqdtIQovXzbKI3t3VnVdQ36yQufalHhPrPLAgC0AAEF7VKcLVx/vekCXXd+F3kN6eevbdTjb2/jCh8ACBEEFLRbEWFWPX7dYN1zSW9J0vwPdmvmyxtUW+81uTIAwDchoKBds1gsuvfSPnps4iCFWS16bf1B3bxwjdw13HAQAIIZAQUdwg0XdNVfpgxXbGSYVu46qusXFOiwq9rssgAAZ0BAQYfxrb6p+seto5QSb9M2Z7m+N3+VtjndZpcFAGgGAQUdysBMu169/UL1So2T012j7z9boJW7jphdFgDgKwgo6HCykmL0r9su1IjsJJV76nXT82v06roDZpcFADgFAQUdkj0mQi/+eISuHJyuugZDM1/eoPkf7OIyZAAIEgQUdFhREWF6etJQTRvXQ5L0+Nvb9b+vb1J9A5chA4DZCCjo0KxWi35+RY5+eVV/WSzSosJ9uvVva1VVW292aQDQoRFQAEk3jc7Ws5PPly3cqvxtJZr0p9UqLfeYXRYAdFgBDyiPPvqoLBaLZsyY4dtWU1Oj6dOnKzk5WXFxcZo4caKKi7mhG8w1YaBDi6aOVKeYCH1+wKVrn12pPaUVZpcFAB1SQAPKJ598oj/+8Y8aPHhwk+333nuv/vOf/+iVV17RihUrdOjQIV177bWBLAU4K+d366R/3X6huibFaP+xak18dpXW7j1mdlkA0OEELKBUVFRo8uTJeu6559SpUyffdpfLpb/85S964okn9O1vf1vnn3++nn/+ea1atUqrV69u9lwej0dut7vJAwiUHilxevWOC3VeVqKOV9XpB88Vatmmw2aXBQAdSsACyvTp03XllVcqLy+vyfa1a9eqrq6uyfZ+/fqpa9euKigoaPZcc+bMkd1u9z2ysrICVTYgSeocZ9PiqbnKy0mVp96r219ap79+XGR2WQDQYQQkoCxZskTr1q3TnDlzTtvndDoVGRmpxMTEJtvT0tLkdDqbPd+sWbPkcrl8j/379weibKCJmMhwLbjxfN04sqsMQ/q/N7bo4f9sVh2XIQNAwIX7+4T79+/XPffco3fffVdRUVF+OafNZpPNZvPLuYCWCA+z6ldXD1RGYrTmLtuu51d+oY0HXHr6B0OVbo82uzwAaLf83oOydu1alZSUaNiwYQoPD1d4eLhWrFihefPmKTw8XGlpaaqtrVVZWVmT1xUXF8vhcPi7HKDVLBaL7vhWLy24cZjibeH6dO9xXTnvY324o9Ts0gCg3fJ7QLnkkku0ceNGffbZZ77H8OHDNXnyZN+fIyIilJ+f73vN9u3btW/fPo0aNcrf5QB+M2Fgut64e4wGZCToWGWtpjy/Rk+8u0MNXpbHBwB/8/sQT3x8vAYOHNhkW2xsrJKTk33bb7nlFs2cOVNJSUlKSEjQXXfdpVGjRmnkyJH+Lgfwq27JsfrX7Rfq/97YokWF+zQvf6c+/eKYfj9pqFLiGYYEAH8xZSXZJ598Ut/5znc0ceJEjRs3Tg6HQ6+++qoZpQAtFhURpt98b5CeumGIYiLDtGr3UV057yMV7jlqdmkA0G5YjBC8favb7ZbdbpfL5VJCQoLZ5aAD21VSrtv/vk47SypktUj3j++r28b1lNVqMbs0AAg6Lfn+5l48QCv0So3X0jtH69qhmfIa0txl23XLC5/oeGWt2aUBQEgjoACtFBMZrt9df54evXaQbOFWfbC9VN95+mOt33fc7NIAIGQRUAA/sFgsmjSiq167Y7S6J8foYFm1rv9jgf76cZFCcBQVAExHQAH8qH9Ggv5z1xhdMcihugZD//fGFt3x0jq5a+rMLg0AQgoBBfCz+KgIzf/BMP3yqv6KCLPov5ucuurpj7XpoMvs0gAgZBBQgACwWCy6aXS2XrntQmUmRmvv0Spd++wqLSrcx5APAJwFAgoQQEOyEvXm3WN0Sb9U1dZ79fPXNmrmyxtU6ak3uzQACGoEFCDAEmMi9dyPhuuBy/spzGrRa+sP6ur5K7WzuNzs0gAgaBFQgDZgtVp020U9tegnuUqNt2lXSYW++8xKvbrugNmlAUBQIqAAbSi3R7LeumesxvTqrOq6Bs18eYNmvfq5auoazC4NAIIKAQVoY53jbHrhxyM0I6+3LBZp8Zr9+t4fVml3aYXZpQFA0CCgACYIs1o0I6+PXvzxCCXHRmrrYbe+M+9jvVS4l6t8AEAEFMBUY3un6M27x2p0r2RV1zXof1/bpKkvfqojFR6zSwMAUxFQAJM57FH6249z9YsrcxQZZtV7W0s04akP9f62YrNLAwDTEFCAIGC1WvSTsT30+vTR6pMWpyMVtfrxwk/1i9c3qrqWCbQAOh4CChBE+mck6N93jtGPR2dLkv6+ep++8/RHLJMPoMMhoABBJioiTA9d1V9/u2WEUuNt2l1aqWvmr9Qflu9Sg5cJtAA6BgIKEKTG9k7R2zPGacIAh+q9huYu267/99xqHTheZXZpABBwBBQgiHWKjdSzNw7T3OsGKzYyTGuKjuny33+kpZ8dNLs0AAgoAgoQ5CwWi64fnqW37hmroV0TVV5Tr3uWfKa7F6+Xq7rO7PIAICAIKECI6JYcq1duHaV78/oozGrRvzcc0uVPfaiC3UfNLg0A/I6AAoSQ8DCr7snrrVduG6VuyTE65KrRD/68WnP+u1W19V6zywMAvyGgACFoWNdOeuvusbpheJYMQ/rjij26Zv5K7SopN7s0APALAgoQomJt4XrsusFacOP56hQToS2H3bpy3sd6seAL7ucDIOQRUIAQN2GgQ8tmjNPY3p3lqffqoaWbdfPCT1RSXmN2aQBwzggoQDuQlhClF24eoV9e1V+R4VYt316qCU99pHc2O80uDQDOCQEFaCesVotuGp2tN+4ao5z0BB2rrNW0v63VA//6XO4aLkcGEFoIKEA70yctXq9Pv1DTxvWQxSIt+WS/Ln1ihd7dwt2RAYQOAgrQDtnCw/TzK3K0eOpIdU+OUbHbo6kvfqo7F63TkQqP2eUBwDcioADt2MgeyVo2Y5xuvaiHwqwWvfH5YeU9sUL/WnuAK30ABDUCCtDORUWEadblOVo6fbT6pyeorKpO972yQVOe/4QbDwIIWgQUoIMYmGnX0jtH66fj+yoy3KoPd5Tqsic/1MKVRWrw0psCILgQUIAOJCLMqukX99J/7xmrEd2TVFXboF/+Z4u+v2CVdhazCi2A4EFAATqgnilxWjJtpB65ZqDibOFat69MV877WL9/byf39AEQFAgoQAdltVp048hueufecfp2v1TVNnj15Hs7dNXTH+uz/WVmlweggyOgAB1cRmK0/jJluH4/aYiSYiO1vbhc1/5hpX71xhZV1dabXR6ADoqAAkAWi0VXD8nUezMv0veGZsprSH/5uEjjn/pQK3cdMbs8AB0QAQWAT1JspJ68YYiev/kCZdijtP9YtSb/uVA/fWWDXFUslw+g7RBQAJzm4r6pemfmRfrRqG6yWKRX1h5Q3pMr9N+Nh80uDUAHQUAB0Kw4W7j+7+qBeuXWUeqZEqvSco9uf2mdbvvbWpW4a8wuD0A7R0AB8LWGd0/Sm3eP1Z0X91K41aJlm53Ke2KF/vHJPpbLBxAwFiMEP2HcbrfsdrtcLpcSEhLMLgfoMLYedut//vW5Pj/gkiQNyrTr3kt76+K+qbJYLCZXByDYteT7m4ACoEXqG7x6fuUXevK9HaqqbZAknZeVqHvzeuuiPikEFQBnREABEHBHKzz604d79GLBXlXXNQaVYV0TNfPSvhrdK5mgAuA0BBQAbaa03KM/rtitv63eK8+JZfIv6N5J917aRxf27GxydQCCCQEFQJsrcdfo2RW79VLhPt/9fEb2SNK9eX2U2yPZ5OoABAMCCgDTOF01+sPyXVqyZr9qGxqDyuheyZp5aR+d3y3J5OoAmImAAsB0h8qqNf+DXXr50/2qa2j8mBnXJ0X35vXW0K6dTK4OgBkIKACCxoHjVZr/wS698ukB1XsbP24u7puiey/to8FdEs0tDkCbIqAACDr7jlbp6fd36tX1B9VwIqjk5aRqRl4fDcy0m1wdgLZAQAEQtL44Uql57+/U6+sP6kRO0fgBaZqR10c56fx7BtozAgqAoLe7tEJP5+/U0g2HdPJT6IpBDt1zSR/1dcSbWxyAgCCgAAgZO4vL9fv8nXpz42EZhmSxSFcMTNePRnXTiOwkFnwD2hECCoCQs91Zrt/n79BbG52+bX3S4nTjyG763tBMxUdFmFgdAH8goAAIWducbr2w6gu9vv6Qbwn9mMgwXTM0UzfmdlP/DP7NA6GKgAIg5Llr6vTq2gP6e+E+7Sqp8G0f1jVRPxzVTZcPTFdURJiJFQJoKQIKgHbDMAyt3nNMfy/cq7c3OX1rqXSKidD1F2Rp8ohu6pocY3KVAM4GAQVAu1RSXqN/rNmvxWv26ZCrRlLjpNpxvVP0w5HddHG/VIVZmVQLBCsCCoB2rb7Bqw+2l+rvq/dqxY5S3/bMxGj9vxFZuuGCrkqJt5lYIYDmEFAAdBh7j1ZqUeE+vfzpfh2vqpMkRYRZNH6AQzeO7KZcLlUGggYBBUCHU1PXoLc2HtbfV+/Vun1lvu29U09cqjwsUwlcqgyYioACoEPbfMilv6/ep6WfHVRV7ZeXKl89JFMTh2VqWNdOsjJXBWhzBBQAUOOlyq+tO6i/r96rnadcqtw5zqbLBqRpwgCHRvZIVmS41cQqgY6jJd/ffv9XOWfOHF1wwQWKj49XamqqrrnmGm3fvr3JMTU1NZo+fbqSk5MVFxeniRMnqri42N+lAOjgEqIiNOXC7nrn3nH6x7SRunZopuKjwnWkwqNFhfv0o7+u0fBH3tXMf3ymtzc7VX2itwWA+fzegzJhwgRNmjRJF1xwgerr6/Xzn/9cmzZt0pYtWxQbGytJuv322/Xmm29q4cKFstvtuvPOO2W1WrVy5cqz+h30oAA4V7X1Xq3ec1TLNjv1zuZiHanw+PZFRVj1rT6pmjDQoYv7pcoezZwVwJ+CaointLRUqampWrFihcaNGyeXy6WUlBQtWrRI1113nSRp27ZtysnJUUFBgUaOHHnaOTwejzyeLz9E3G63srKyCCgAWqXBa2j9vuNatsmpZZudOnC82rcvIsyiC3t21vgBDl3aP43LlgE/aElACQ90MS6XS5KUlJQkSVq7dq3q6uqUl5fnO6Zfv37q2rXrGQPKnDlz9PDDDwe6VAAdTJjVouHdkzS8e5L+98ocbT7k1tubnVq2yamdJRVasaNUK3aU6n9f36gLuiVp/ECHxg9IU5dOrFwLBFpAe1C8Xq+++93vqqysTB9//LEkadGiRbr55pub9IhI0ogRI3TxxRfrscceO+089KAAaGu7Syv09man3t7k1IYDrib7BmXaNeFEWOmVGm9ShUDoCZoelOnTp2vTpk2+cHKubDabbDa6VwG0nZ4pcbrjW710x7d66WBZtd450bPyyRfHtPGgSxsPuvT429vVMyX2RFhxaGCGncuXAT8JWEC588479cYbb+jDDz9Uly5dfNsdDodqa2tVVlamxMRE3/bi4mI5HI5AlQMA5ywzMVo3j87WzaOzdbTCo/e2FmvZJqc+3nVEu0srNf+D3Zr/wW6lJdj07X5pystJ1ehenbnbMtAKfh/iMQxDd911l1577TUtX75cvXv3brL/5CTZxYsXa+LEiZKk7du3q1+/fmecg/JVXMUDIBi4a+r0wbYSvb3ZqeXbS32LwkmNVwSN6ZWivJxUfTsnVanxUSZWCgQHU6/iueOOO7Ro0SItXbpUffv29W232+2Kjo6W1HiZ8VtvvaWFCxcqISFBd911lyRp1apVZ/U7CCgAgo2nvkGr9xzTe1uKlb+12He35ZPO62LXJTlpystJU056PPcHQodkakA50z+6559/XjfddJOkxoXa7rvvPi1evFgej0fjx4/XH/7wh7Me4iGgAAhmhmFo6+Fy5W8t1nvbSrRhf1mT/Rn2qMaw0j9NI3skyRbOUBA6hqBaByUQCCgAQkmJu0bvbyvRe1tL9PGuUtXUeX37YiPDNLZ3ii7JSdW3+6UqOY4LAtB+EVAAIEjV1DVo5a4jem9rid7fVqxi95dLKFgs0tCsROX1bxwK6p0ax1AQ2hUCCgCEAMMwtOmgW+9tLdZ7W4u1+ZC7yf6spGhd0i9NI7KT1CctXt2TYxQexo0NEboIKAAQgg67qpW/tUT5W4u1cvdR1dZ7m+yPDLeqd2qc+jri1c8Rr76OBPVzxCs13kZPC0ICAQUAQlxVbb0+2nlEy7eXasshl3YUV6i6rvm7LSfGRKhv2pehpa8jTn3S4hUfxc0OEVwIKADQzni9hvYfr9I2Z7m2n3hsc7pVdKRS3jN8imcmRp8ILfEnel0S1CMlVhEME8EkBBQA6CBq6hq0q6SiMbQUl2ubs1w7nOVyumuaPT4izKKeKY09LP3S4zU4M1GDMu2yx9DbgsAjoABAB1dWVdsktGw/EVzKPfXNHt8tOUaDMu0a3MWuQZmJGpiZwBAR/I6AAgA4jWEYOlhWfWJ4qFxbDru16aBLe49WNXt8j5RYDc60a1CXRA3uYteAjATFRAb0HrNo5wgoAICzVlZVq00H3fr8YJk2HnDp8wMuHSyrPu04q0XqlRqnQZmNgWVQF7v6pydwU0ScNQIKAKBVjlZ49PlBly+wbDxY1mRRuZPCrBb1SYs/0dPSOETU1xHP8v1oFgEFAOB3xe6axsBy0KWNB8r0+QGXjlbWnnZcRJhFPTrHqUdKrLI7x6pHSuOfe3SOVWJMpAmVI1gQUAAAAWcYhg67anw9LI3PLpVV1Z3xNUmxkerR+fTg0jU5hl6XDoCAAgAwhWEYOnC8WrtKKrTnSKX2lFZoT2mlio5UnvHSZ6lxfkuXTjEnAkucslNi1bNzrLJTYuVIiGKl3HaCgAIACDqVnnoVHan0BZeiI5XaU9r458ra5lfJlaSYyDBln+x16RyrjMRopSdGK8MepfTEaMXZuLIoVBBQAAAhwzAMlZZ7tPtET8ue0sbel6Ijldp3rEoNZ1oq94T4qHBl2KOVnhildPuXweXkc7o9iiuNggQBBQDQLtTWe7X/eNWJYaIKFR2p0mFXtQ6X1eiQq1rlNc0vPPdVSbGRSrefCDCJTZ/T7VFy2KO4BUAbaMn3N/1iAICgFRluVc+UOPVMiZOUdtr+Ck+9nK5qHSqr0eFTng+7anSorPG5qrZBxyprdayyVpsPuZv9PRaLlBJnU0ZitDITTw0xX/6cFBvJXJg2REABAISsOFu4eqXGq1dqfLP7DcOQu7peh1zVTQPMiR6Yw64aHXbVqLbeq5Jyj0rKPfpsf1mz57KFW5VxIqw0DilFKzMx6sS2aGXYoxUdyVCSvxBQAADtlsVikT0mQvaYCOWkNz+kYBiGjlbW+kLLobKTjxodLGsMNiXlHnnqvSo6MTfmTDrFRPgCS+aJ+S8ZJ57TE6OVGm9jKOksEVAAAB2axWJR5zibOsfZNKiLvdljauu9KnY3BpaTQ0cHy5qGmQpPvY5X1el4Vd03DiWdnPeSbo8+8RwlR0JjmElNsLEmjAgoAAB8o8hwq7KSYpSVFHPGY9w1db7AcrDsxByYsmodLKuW010jp6tGdQ2GbyhpwwHXGc/VOS5SDnuUHAnRp4SZppN62/uVSQQUAAD8ICEqQgmOCPVzND+U5PUaOlbVOJR02NUYWg67GoPLYVf1iecaeeq9OlJRqyMVjTdxPJNOMRFKio1UnC1cMZHhirWF+Z5jI8MVYwtXbGTYl8+R4Y3HntwfGaZYW+PxkWHWoJsATEABAKANWK3fPJRkGIbKqup06JTA4nt2n5jUW1aj6roG33CSP4RbLb7AEhMZpjhbuMYPdOiOb/Xyy/nPqSbTfjMAAGjCYrGoU2ykOsVGakDGmUOMu6Zeh13VOl5Zp6raelXWNqjK0/hc6alXZW29qjwNTZ4rPfWqqv1yW4WnXp56rySp3tt4Tvcp68oM7pLYFm/5jAgoAACEEIvFInt0hOzREa0+V32DV1V1DU1CTKWnQVW19XLYo/xQ7bkjoAAA0EGFh1mVEGZVQlTrw46/cTE2AAAIOvSgnMowpLoqs6sAACA4RMQ0Lt5iAgLKqeqqpN9kmF0FAADB4eeHpMhYU341QzwAACDo0INyqoiYxrQIAAAavxdNQkA5lcViWlcWAAD4EkM8AAAg6BBQAABA0CGgAACAoENAAQAAQYeAAgAAgg4BBQAABB0CCgAACDoEFAAAEHQIKAAAIOgQUAAAQNAhoAAAgKBDQAEAAEGHgAIAAIIOAQUAAAQdAgoAAAg6BBQAABB0CCgAACDoEFAAAEDQIaAAAICgQ0ABAABBh4ACAACCDgEFAAAEHQIKAAAIOgQUAAAQdAgoAAAg6BBQAABA0CGgAACAoENAAQAAQYeAAgAAgg4BBQAABB0CCgAACDqmBpT58+ere/fuioqKUm5urtasWWNmOQAAIEiYFlD+8Y9/aObMmZo9e7bWrVun8847T+PHj1dJSYlZJQEAgCBhMQzDMOMX5+bm6oILLtAzzzwjSfJ6vcrKytJdd92lBx54oMmxHo9HHo/H97PL5VLXrl21f/9+JSQktGndAADg3LjdbmVlZamsrEx2u/1rjw1vo5qaqK2t1dq1azVr1izfNqvVqry8PBUUFJx2/Jw5c/Twww+ftj0rKyugdQIAAP8rLy8PzoBy5MgRNTQ0KC0trcn2tLQ0bdu27bTjZ82apZkzZ/p+9nq9OnbsmJKTk2WxWPxa28l0R+9MYNHObYN2bhu0c9ugndtOoNraMAyVl5crIyPjG481JaC0lM1mk81ma7ItMTExoL8zISGBfwBtgHZuG7Rz26Cd2wbt3HYC0dbf1HNykimTZDt37qywsDAVFxc32V5cXCyHw2FGSQAAIIiYElAiIyN1/vnnKz8/37fN6/UqPz9fo0aNMqMkAAAQREwb4pk5c6amTJmi4cOHa8SIEXrqqadUWVmpm2++2aySJDUOJ82ePfu0ISX4F+3cNmjntkE7tw3aue0EQ1ubdpmxJD3zzDN6/PHH5XQ6NWTIEM2bN0+5ublmlQMAAIKEqQEFAACgOdyLBwAABB0CCgAACDoEFAAAEHQIKAAAIOi0+4Ayf/58de/eXVFRUcrNzdWaNWu+9vhXXnlF/fr1U1RUlAYNGqS33nqryX7DMPTQQw8pPT1d0dHRysvL086dOwP5FkKCv9v5pptuksViafKYMGFCIN9CyGhJW2/evFkTJ05U9+7dZbFY9NRTT7X6nB2Fv9v5l7/85Wl/p/v16xfAdxAaWtLOzz33nMaOHatOnTqpU6dOysvLO+14PqOb5+92bpPPaKMdW7JkiREZGWn89a9/NTZv3mxMnTrVSExMNIqLi5s9fuXKlUZYWJgxd+5cY8uWLcYvfvELIyIiwti4caPvmEcffdSw2+3G66+/bmzYsMH47ne/a2RnZxvV1dVt9baCTiDaecqUKcaECROMw4cP+x7Hjh1rq7cUtFra1mvWrDHuv/9+Y/HixYbD4TCefPLJVp+zIwhEO8+ePdsYMGBAk7/TpaWlAX4nwa2l7fyDH/zAmD9/vrF+/Xpj69atxk033WTY7XbjwIEDvmP4jD5dINq5LT6j23VAGTFihDF9+nTfzw0NDUZGRoYxZ86cZo+//vrrjSuvvLLJttzcXOPWW281DMMwvF6v4XA4jMcff9y3v6yszLDZbMbixYsD8A5Cg7/b2TAa//JfffXVAak3lLW0rU/VrVu3Zr84W3PO9ioQ7Tx79mzjvPPO82OVoa+1f/fq6+uN+Ph444UXXjAMg8/oM/F3OxtG23xGt9shntraWq1du1Z5eXm+bVarVXl5eSooKGj2NQUFBU2Ol6Tx48f7ji8qKpLT6WxyjN1uV25u7hnP2d4Fop1PWr58uVJTU9W3b1/dfvvtOnr0qP/fQAg5l7Y245yhLpBtsnPnTmVkZKhHjx6aPHmy9u3b19pyQ5Y/2rmqqkp1dXVKSkqSxGd0cwLRzicF+jO63QaUI0eOqKGhQWlpaU22p6Wlyel0Nvsap9P5tceffG7JOdu7QLSzJE2YMEEvvvii8vPz9dhjj2nFihW6/PLL1dDQ4P83ESLOpa3NOGeoC1Sb5ObmauHChVq2bJmeffZZFRUVaezYsSovL29tySHJH+38P//zP8rIyPB9+fIZfbpAtLPUNp/Rpt2LB/g6kyZN8v150KBBGjx4sHr27Knly5frkksuMbEy4Nxcfvnlvj8PHjxYubm56tatm15++WXdcsstJlYWmh599FEtWbJEy5cvV1RUlNnltFtnaue2+Ixutz0onTt3VlhYmIqLi5tsLy4ulsPhaPY1Dofja48/+dySc7Z3gWjn5vTo0UOdO3fWrl27Wl90iDqXtjbjnKGurdokMTFRffr06bB/p1vTzr/97W/16KOP6p133tHgwYN92/mMPl0g2rk5gfiMbrcBJTIyUueff77y8/N927xer/Lz8zVq1KhmXzNq1Kgmx0vSu+++6zs+OztbDoejyTFut1uFhYVnPGd7F4h2bs6BAwd09OhRpaen+6fwEHQubW3GOUNdW7VJRUWFdu/e3WH/Tp9rO8+dO1e/+tWvtGzZMg0fPrzJPj6jTxeIdm5OQD6jAzoF12RLliwxbDabsXDhQmPLli3GtGnTjMTERMPpdBqGYRg//OEPjQceeMB3/MqVK43w8HDjt7/9rbF161Zj9uzZzV5mnJiYaCxdutT4/PPPjauvvppL2PzczuXl5cb9999vFBQUGEVFRcZ7771nDBs2zOjdu7dRU1NjynsMFi1ta4/HY6xfv95Yv369kZ6ebtx///3G+vXrjZ07d571OTuiQLTzfffdZyxfvtwoKioyVq5caeTl5RmdO3c2SkpK2vz9BYuWtvOjjz5qREZGGv/85z+bXN5aXl7e5Bg+o5vydzu31Wd0uw4ohmEYTz/9tNG1a1cjMjLSGDFihLF69WrfvosuusiYMmVKk+Nffvllo0+fPkZkZKQxYMAA480332yy3+v1Gg8++KCRlpZm2Gw245JLLjG2b9/eFm8lqPmznauqqozLLrvMSElJMSIiIoxu3boZU6dO7dBfmKdqSVsXFRUZkk57XHTRRWd9zo7K3+18ww03GOnp6UZkZKSRmZlp3HDDDcauXbva8B0Fp5a0c7du3Zpt59mzZ/uO4TO6ef5s57b6jLYYhmH4rz8GAACg9drtHBQAABC6CCgAACDoEFAAAEDQIaAAAICgQ0ABAABBh4ACAACCDgEFAAAEHQIKAAAIOgQUAAAQdAgoAAAg6BBQAABA0Pn/tQaU6jPh4gYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(all_eps, adv_acc)\n",
    "#plt.plot(all_eps, adv_acc_cnn)\n",
    "plt.plot(all_eps, len(all_eps)*[10])\n",
    "plt.ylim(0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "avd_acc = np.array(adv_acc)\n",
    "adv_top5 = np.array(adv_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('adv_acc_mlp_cifar10', adv_acc)\n",
    "np.save('adv_top5_mlp_cifar10', adv_top5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marcel's part\n",
    "Run cells 1, 2, 5 & 6 before this and change data_path below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n",
      "Loading /scratch/ffcv/cifar10/val_32.beton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/10 [01:15<?, ?it/s]\n",
      "Evaluating:   0%|          | 0/21 [01:15<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m all_eps \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0.26\u001b[39m,\u001b[38;5;241m0.0125\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m eps \u001b[38;5;129;01min\u001b[39;00m tqdm(all_eps, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluating\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m---> 11\u001b[0m     test_adv_acc, test_adv_top5 \u001b[38;5;241m=\u001b[39m \u001b[43mtest_adversarial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpgd\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_mlp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mis_mlp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m     adv_acc\u001b[38;5;241m.\u001b[39mappend(test_adv_acc)\n\u001b[1;32m     14\u001b[0m     adv_top5\u001b[38;5;241m.\u001b[39mappend(test_adv_top5)\n",
      "Cell \u001b[0;32mIn[25], line 12\u001b[0m, in \u001b[0;36mtest_adversarial\u001b[0;34m(model, dataset, loader, eps, mode, is_mlp)\u001b[0m\n\u001b[1;32m     10\u001b[0m     adv_ims \u001b[38;5;241m=\u001b[39m fgsm_untargeted(model, dataset, ims, targs, eps)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpgd\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 12\u001b[0m     adv_ims \u001b[38;5;241m=\u001b[39m \u001b[43mpgd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m adv_preds \u001b[38;5;241m=\u001b[39m model(adv_ims)\n\u001b[1;32m     16\u001b[0m adv_acc, adv_top5 \u001b[38;5;241m=\u001b[39m topk_acc(adv_preds, targs, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, avg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[24], line 57\u001b[0m, in \u001b[0;36mpgd\u001b[0;34m(model, dataset, x_batch, label, eps, k, eps_step)\u001b[0m\n\u001b[1;32m     55\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     56\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss()(model(x_adv), label)\n\u001b[0;32m---> 57\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m perturbation \u001b[38;5;241m=\u001b[39m eps_step \u001b[38;5;241m*\u001b[39m x_adv\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39msign()\n\u001b[1;32m     60\u001b[0m x_adv \u001b[38;5;241m=\u001b[39m denormalize(x_adv, mean, std)\n",
      "File \u001b[0;32m~/miniconda3/envs/ffcv/lib/python3.9/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ffcv/lib/python3.9/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for model in ['mlp', 'cnn']:\n",
    "    for dataset in ['cifar10', 'cifar100']:\n",
    "        is_mlp = model == 'mlp'\n",
    "\n",
    "        adv_acc = []\n",
    "        adv_top5 = []\n",
    "        data_loader, model = get_data_and_model(dataset=dataset, model=model, data_path='/scratch/ffcv/')\n",
    "        all_eps = np.arange(0,0.26,0.0125)\n",
    "\n",
    "        for eps in tqdm(all_eps, desc=\"Evaluating\"):\n",
    "            test_adv_acc, test_adv_top5 = test_adversarial(model, dataset, data_loader, eps, 'pgd', is_mlp = is_mlp)\n",
    "\n",
    "            adv_acc.append(test_adv_acc)\n",
    "            adv_top5.append(test_adv_top5)\n",
    "\n",
    "        acc_fname = 'pgd_acc_' + model + '_' + dataset\n",
    "        top5_fname = 'pgd_top5_' + model + '_' + dataset\n",
    "        \n",
    "        np.save(acc_fname, np.array(adv_acc))\n",
    "        np.save(top5_fname, np.array(adv_top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
