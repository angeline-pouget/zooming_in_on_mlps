{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Fall 2023 Course Project - Zooming in on MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import timm\n",
    "import detectors\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from ffcv.fields import BytesField, IntField, RGBImageField\n",
    "from ffcv.writer import DatasetWriter\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "from data_utils.data_stats import *\n",
    "from data_utils.dataloader import get_loader\n",
    "from data_utils.dataset_to_beton import get_dataset\n",
    "from models.networks import get_model\n",
    "from utils.metrics import topk_acc, real_acc, AverageMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching data loader and model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_and_model(dataset, model, data_path='/scratch/ffcv/'):\n",
    "    \"\"\"\n",
    "    This function retrieves the data, model and feature extractor (if needed) based on the provided information.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (str): The name of the dataset to retrieve (can be cifar10, cifar100 or imagenet).\n",
    "    model (str): The name of the model to retrieve (can be mlp, cnn or vit; only mlp is supported for dataset imagenet).\n",
    "    data_path (str): The path to the data.\n",
    "\n",
    "    Returns (as a tuple):\n",
    "    data_loader (DataLoader): The retrieved data loader.\n",
    "    model (Model): The retrieved model.\n",
    "\n",
    "    Raises:\n",
    "    AssertionError: If the dataset or model is not supported.\n",
    "    \"\"\"\n",
    "\n",
    "    assert dataset in ('cifar10', 'cifar100', 'imagenet'), f'dataset {dataset} is currently not supported by this function'\n",
    "    assert model in ('mlp', 'cnn', 'vit'), f'model {model} is currently not supported by this function'\n",
    "\n",
    "    num_classes = CLASS_DICT[dataset]\n",
    "    eval_batch_size = 1024\n",
    "\n",
    "    if dataset == 'imagenet':\n",
    "        data_resolution = 64\n",
    "        assert model == 'mlp', f'imagenet dataset is only supported by mlp model'\n",
    "    else:\n",
    "        data_resolution = 32\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if device == 'cuda':\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "    if model == 'mlp':\n",
    "        crop_resolution = 64\n",
    "        architecture = 'B_12-Wi_1024'\n",
    "        checkpoint = 'in21k_' + dataset\n",
    "\n",
    "        model = get_model(architecture=architecture, resolution=crop_resolution, num_classes=num_classes, checkpoint=checkpoint)\n",
    "\n",
    "    if model == 'cnn':\n",
    "        crop_resolution = 32\n",
    "        architecture = 'resnet18_' + dataset\n",
    "\n",
    "        model = timm.create_model(architecture, pretrained=True)\n",
    "\n",
    "    if model == 'vit':\n",
    "        crop_resolution = 32\n",
    "\n",
    "        if dataset == 'cifar10':\n",
    "            architecture = 'vit_small_patch16_224_cifar10_v4.pth'\n",
    "            model = torch.load(architecture)\n",
    "\n",
    "        elif dataset == 'cifar100':\n",
    "            architecture = 'vit_small_patch16_224_cifar100_v3.pth'\n",
    "            model = torch.load(architecture)\n",
    "\n",
    "    data_loader = get_loader(\n",
    "        dataset,\n",
    "        bs=eval_batch_size,\n",
    "        mode=\"test\",\n",
    "        augment=False,\n",
    "        dev=device,\n",
    "        mixup=0.0,\n",
    "        data_path=data_path,\n",
    "        data_resolution=data_resolution,\n",
    "        crop_resolution=crop_resolution,\n",
    "    )\n",
    "\n",
    "    return data_loader, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating baseline model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a test function that evaluates test accuracy\n",
    "@torch.no_grad()\n",
    "def test(model, loader, is_mlp = False):\n",
    "    model.eval()\n",
    "    total_acc, total_top5 = AverageMeter(), AverageMeter()\n",
    "\n",
    "    for ims, targs in tqdm(loader, desc=\"Evaluation\"):\n",
    "        if is_mlp:\n",
    "            ims = torch.reshape(ims, (ims.shape[0], -1))\n",
    "        \n",
    "        preds = model(ims)    \n",
    "        acc, top5 = topk_acc(preds, targs, k=5, avg=True)\n",
    "        \n",
    "        total_acc.update(acc, ims.shape[0])\n",
    "        total_top5.update(top5, ims.shape[0])\n",
    "\n",
    "    return (\n",
    "        total_acc.get_avg(percentage=True),\n",
    "        total_top5.get_avg(percentage=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n",
      "Loading /scratch/ffcv/cifar10/val_32.beton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 10/10 [01:06<00:00,  6.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy         94.3900\n",
      "Top 5 Test Accuracy           99.6600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_loader, model = get_data_and_model(dataset='cifar10', model='mlp', data_path='/scratch/ffcv/')\n",
    "test_acc, test_top5 = test(model, data_loader, True)\n",
    "\n",
    "# Print all the stats\n",
    "print(\"Test Accuracy        \", \"{:.4f}\".format(test_acc))\n",
    "print(\"Top 5 Test Accuracy          \", \"{:.4f}\".format(test_top5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate adversarial accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor, mean, std):\n",
    "    \"\"\"\n",
    "    Denormalize a tensor.\n",
    "\n",
    "    Parameters:\n",
    "    tensor (torch.Tensor): The tensor to denormalize.\n",
    "    mean (float or sequence): The mean used for normalization.\n",
    "    std (float or sequence): The standard deviation used for normalization.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The denormalized tensor.\n",
    "    \"\"\"\n",
    "    return tensor*std[1]+mean[1]\n",
    "\n",
    "def normalize(tensor, mean, std):\n",
    "    \"\"\"\n",
    "    Normalize a tensor.\n",
    "\n",
    "    Parameters:\n",
    "    tensor (torch.Tensor): The tensor to normalize.\n",
    "    mean (float or sequence): The mean used for normalization.\n",
    "    std (float or sequence): The standard deviation used for normalization.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The normalized tensor.\n",
    "    \"\"\"\n",
    "    return (tensor-mean[1])/std[1]\n",
    "\n",
    "def pgd(model, dataset, x_batch, label, eps, k, eps_step):\n",
    "    \"\"\"\n",
    "    Performs the Projected Gradient Descent (PGD) for adversarial attacks.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model to attack.\n",
    "    dataset (str): The name of the dataset used (can be cifar10, cifar100 or imagenet).\n",
    "    x_batch (torch.Tensor): The input tensor.\n",
    "    label (torch.Tensor): The true labels for the input tensor.\n",
    "    eps (float): The maximum perturbation for PGD.\n",
    "    k (int): The number of steps for PGD.\n",
    "    eps_step (float): The step size for each iteration.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The adversarially perturbed input tensor.\n",
    "    \"\"\"   \n",
    "    mean, std = MEAN_DICT[dataset]/255, STD_DICT[dataset]/255\n",
    "\n",
    "    x = x_batch.clone().detach_()\n",
    "    x = denormalize(x, mean, std)\n",
    "    x_adv = x + eps * (2*torch.rand_like(x) - 1)\n",
    "    x_adv.clamp_(min=0., max=1.)\n",
    "    \n",
    "    for _ in range(k):\n",
    "        x_adv = normalize(x_adv, mean, std).detach_()\n",
    "        x_adv.requires_grad_()\n",
    "        model.zero_grad()\n",
    "        loss = torch.nn.CrossEntropyLoss()(model(x_adv), label)\n",
    "        loss.backward()\n",
    "        perturbation = eps_step * x_adv.grad.sign()\n",
    "\n",
    "        x_adv = denormalize(x_adv, mean, std)\n",
    "        x_adv = x + (x_adv + perturbation - x).clamp_(min=-eps, max=eps)\n",
    "        x_adv.clamp_(min=0, max=1)\n",
    "\n",
    "    return normalize(x_adv.detach(), mean, std)\n",
    "\n",
    "def fgsm_untargeted(model, dataset, x_batch, label, eps):\n",
    "    \"\"\"\n",
    "    Performs the Fast Gradient Sign Method (FGSM) for untargeted adversarial attacks.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model to attack.\n",
    "    dataset (str): The name of the dataset used (can be cifar10, cifar100 or imagenet).\n",
    "    x_batch (torch.Tensor): The input tensor.\n",
    "    label (torch.Tensor): The true labels for the input tensor.\n",
    "    eps (float): The step size for the FGSM attack.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The adversarially perturbed input tensor.\n",
    "    \"\"\"\n",
    "    mean, std = MEAN_DICT[dataset]/255, STD_DICT[dataset]/255\n",
    "\n",
    "    x = x_batch.clone().detach_()\n",
    "    x.requires_grad_()\n",
    "    model.zero_grad()\n",
    "    loss = torch.nn.CrossEntropyLoss()(model(x), label)\n",
    "    loss.backward()\n",
    "    perturbation = eps * x.grad.sign()\n",
    "\n",
    "    out = denormalize(x, mean, std) + perturbation\n",
    "    out = out.clamp_(min=0, max=1)\n",
    "        \n",
    "    return normalize(out, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_adversarial(model, dataset, loader, eps, mode, is_mlp = False, k = None, eps_step = None):\n",
    "    model.eval()\n",
    "    total_adv_acc, total_adv_top5 = AverageMeter(), AverageMeter()\n",
    "\n",
    "    for ims, targs in tqdm(loader, desc=\"Evaluation\"):\n",
    "        if is_mlp:\n",
    "            ims = torch.reshape(ims, (ims.shape[0], -1))\n",
    "        targs = targs\n",
    "        if mode ==\"fgsm\":\n",
    "            adv_ims = fgsm_untargeted(model, dataset, ims, targs, eps)\n",
    "        if mode == \"pgd\":\n",
    "            adv_ims = pgd(model, dataset, ims, targs, 5, eps, eps_step)\n",
    "\n",
    "        adv_preds = model(adv_ims)\n",
    "   \n",
    "        adv_acc, adv_top5 = topk_acc(adv_preds, targs, k=5, avg=True)\n",
    "\n",
    "        total_adv_acc.update(adv_acc, ims.shape[0])\n",
    "        total_adv_top5.update(adv_top5, ims.shape[0])\n",
    "\n",
    "    return (\n",
    "        total_adv_acc.get_avg(percentage=True),\n",
    "        total_adv_top5.get_avg(percentage=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n",
      "Loading /scratch/ffcv/cifar10/val_32.beton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <finalize object at 0x7fc5185e09c0; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/apouget/miniconda3/envs/ffcv/lib/python3.9/weakref.py\", line 591, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"/home/apouget/miniconda3/envs/ffcv/lib/python3.9/site-packages/numba/core/dispatcher.py\", line 312, in finalizer\n",
      "    for cres in overloads.values():\n",
      "KeyError: (Array(uint8, 1, 'C', True, aligned=True), Array(uint8, 1, 'C', True, aligned=True), uint32, uint32, uint32, uint32, Literal[int](0), Literal[int](0), Literal[int](1), Literal[int](1), Literal[bool](False), Literal[bool](False))\n"
     ]
    }
   ],
   "source": [
    "adv_acc = []\n",
    "adv_top5 = []\n",
    "\n",
    "for eps in tqdm([0, 0.001, 0.01, 0.05, 0.1, 0.15, 0.2]):\n",
    "    data_loader, model = get_data_and_model(dataset='cifar10', model='mlp', data_path='/scratch/ffcv/')\n",
    "    test_adv_acc, test_adv_top5 = test_adversarial(model, 'cifar10', data_loader, eps, 'fgsm', is_mlp = True)\n",
    "\n",
    "    adv_acc.append(test_adv_acc)\n",
    "    adv_top5.append(test_adv_top5)\n",
    "\n",
    "# Print all the stats\n",
    "# print(\"Adversarial Accuracy        \", \"{:.4f}\".format(test_adv_acc))\n",
    "# print(\"Top 5 Adversarial Accuracy          \", \"{:.4f}\".format(test_adv_top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
