{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\merci\\miniconda3\\envs\\ffcv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from ffcv.fields import BytesField, IntField, RGBImageField\n",
    "from ffcv.writer import DatasetWriter\n",
    "\n",
    "from data_utils.data_stats import *\n",
    "from data_utils.dataloader import get_loader\n",
    "from utils.metrics import topk_acc, real_acc, AverageMeter\n",
    "from models.networks import get_model\n",
    "from data_utils.dataset_to_beton import get_dataset\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "import ast\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'imagenet'                 # One of cifar10, cifar100, stl10, imagenet or imagenet21\n",
    "architecture = 'B_12-Wi_1024'\n",
    "data_resolution = 64                # Resolution of data as it is stored\n",
    "crop_resolution = 64                # Resolution of fine-tuned model (64 for all models we provide)\n",
    "num_classes = CLASS_DICT[dataset]\n",
    "data_path = './beton/'\n",
    "eval_batch_size = 1024\n",
    "checkpoint = 'in21k_imagenet'  #'in21k_cifar100'        # This means you want the network pre-trained on ImageNet21k and finetuned on CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Couldn't find any class folder in C:/mlp/scaling_mlps/beton/imagenetOriginal/val.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\mlp\\scaling_mlps\\explore.ipynb Cell 3\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/mlp/scaling_mlps/explore.ipynb#W2sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     writer\u001b[39m.\u001b[39mfrom_indexed_dataset(dataset, chunksize\u001b[39m=\u001b[39m\u001b[39m100\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/mlp/scaling_mlps/explore.ipynb#W2sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mC:/mlp/scaling_mlps/beton/imagenetOriginal/val\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/mlp/scaling_mlps/explore.ipynb#W2sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m create_beton(dataset, \u001b[39m'\u001b[39;49m\u001b[39mtest\u001b[39;49m\u001b[39m'\u001b[39;49m, path, data_resolution)\n",
      "\u001b[1;32mc:\\mlp\\scaling_mlps\\explore.ipynb Cell 3\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/mlp/scaling_mlps/explore.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_beton\u001b[39m(dataset, mode, data_path, res):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/mlp/scaling_mlps/explore.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     dataset \u001b[39m=\u001b[39m get_dataset(dataset, mode, data_path)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/mlp/scaling_mlps/explore.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     write_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/mlp/scaling_mlps/explore.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         write_path, dataset, mode, \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mmode\u001b[39m}\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m{\u001b[39;00mres\u001b[39m}\u001b[39;00m\u001b[39m.beton\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/mlp/scaling_mlps/explore.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     )\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/mlp/scaling_mlps/explore.ipynb#W2sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     os\u001b[39m.\u001b[39mmakedirs(os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mdirname(write_path), exist_ok\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\mlp\\scaling_mlps\\data_utils\\dataset_to_beton.py:11\u001b[0m, in \u001b[0;36mget_dataset\u001b[1;34m(dataset_name, mode, data_path)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_dataset\u001b[39m(dataset_name, mode, data_path):\n\u001b[0;32m     10\u001b[0m     \u001b[39mif\u001b[39;00m data_path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m         \u001b[39mreturn\u001b[39;00m torchvision\u001b[39m.\u001b[39;49mdatasets\u001b[39m.\u001b[39;49mImageFolder(root\u001b[39m=\u001b[39;49mdata_path, transform\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m     13\u001b[0m     \u001b[39mif\u001b[39;00m dataset_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mcifar10\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m     14\u001b[0m         \u001b[39mreturn\u001b[39;00m torchvision\u001b[39m.\u001b[39mdatasets\u001b[39m.\u001b[39mCIFAR10(\n\u001b[0;32m     15\u001b[0m             root\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m/tmp\u001b[39m\u001b[39m\"\u001b[39m, train\u001b[39m=\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m, download\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m     16\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\merci\\miniconda3\\envs\\ffcv\\lib\\site-packages\\torchvision\\datasets\\folder.py:309\u001b[0m, in \u001b[0;36mImageFolder.__init__\u001b[1;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    302\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    303\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    307\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    308\u001b[0m ):\n\u001b[1;32m--> 309\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[0;32m    310\u001b[0m         root,\n\u001b[0;32m    311\u001b[0m         loader,\n\u001b[0;32m    312\u001b[0m         IMG_EXTENSIONS \u001b[39mif\u001b[39;49;00m is_valid_file \u001b[39mis\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    313\u001b[0m         transform\u001b[39m=\u001b[39;49mtransform,\n\u001b[0;32m    314\u001b[0m         target_transform\u001b[39m=\u001b[39;49mtarget_transform,\n\u001b[0;32m    315\u001b[0m         is_valid_file\u001b[39m=\u001b[39;49mis_valid_file,\n\u001b[0;32m    316\u001b[0m     )\n\u001b[0;32m    317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimgs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msamples\n",
      "File \u001b[1;32mc:\\Users\\merci\\miniconda3\\envs\\ffcv\\lib\\site-packages\\torchvision\\datasets\\folder.py:144\u001b[0m, in \u001b[0;36mDatasetFolder.__init__\u001b[1;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[0;32m    135\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    136\u001b[0m     root: \u001b[39mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m     is_valid_file: Optional[Callable[[\u001b[39mstr\u001b[39m], \u001b[39mbool\u001b[39m]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    142\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    143\u001b[0m     \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(root, transform\u001b[39m=\u001b[39mtransform, target_transform\u001b[39m=\u001b[39mtarget_transform)\n\u001b[1;32m--> 144\u001b[0m     classes, class_to_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfind_classes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mroot)\n\u001b[0;32m    145\u001b[0m     samples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmake_dataset(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot, class_to_idx, extensions, is_valid_file)\n\u001b[0;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloader \u001b[39m=\u001b[39m loader\n",
      "File \u001b[1;32mc:\\Users\\merci\\miniconda3\\envs\\ffcv\\lib\\site-packages\\torchvision\\datasets\\folder.py:218\u001b[0m, in \u001b[0;36mDatasetFolder.find_classes\u001b[1;34m(self, directory)\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfind_classes\u001b[39m(\u001b[39mself\u001b[39m, directory: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[\u001b[39mstr\u001b[39m], Dict[\u001b[39mstr\u001b[39m, \u001b[39mint\u001b[39m]]:\n\u001b[0;32m    192\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Find the class folders in a dataset structured as follows::\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \n\u001b[0;32m    194\u001b[0m \u001b[39m        directory/\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39m        (Tuple[List[str], Dict[str, int]]): List of all classes and dictionary mapping each class to an index.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 218\u001b[0m     \u001b[39mreturn\u001b[39;00m find_classes(directory)\n",
      "File \u001b[1;32mc:\\Users\\merci\\miniconda3\\envs\\ffcv\\lib\\site-packages\\torchvision\\datasets\\folder.py:42\u001b[0m, in \u001b[0;36mfind_classes\u001b[1;34m(directory)\u001b[0m\n\u001b[0;32m     40\u001b[0m classes \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(entry\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m entry \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39mscandir(directory) \u001b[39mif\u001b[39;00m entry\u001b[39m.\u001b[39mis_dir())\n\u001b[0;32m     41\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m classes:\n\u001b[1;32m---> 42\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCouldn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt find any class folder in \u001b[39m\u001b[39m{\u001b[39;00mdirectory\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     44\u001b[0m class_to_idx \u001b[39m=\u001b[39m {cls_name: i \u001b[39mfor\u001b[39;00m i, cls_name \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(classes)}\n\u001b[0;32m     45\u001b[0m \u001b[39mreturn\u001b[39;00m classes, class_to_idx\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Couldn't find any class folder in C:/mlp/scaling_mlps/beton/imagenetOriginal/val."
     ]
    }
   ],
   "source": [
    "# If you did not yet, produce .beton file for CIFAR10 (check README for how to do that for ImageNet)\n",
    "def create_beton(dataset, mode, data_path, res):\n",
    "    dataset = get_dataset(dataset, mode, data_path)\n",
    "\n",
    "    write_path = os.path.join(\n",
    "        write_path, dataset, mode, f\"{mode}_{res}.beton\"\n",
    "    )\n",
    "\n",
    "    os.makedirs(os.path.dirname(write_path), exist_ok=True)\n",
    "\n",
    "    writer = DatasetWriter(\n",
    "        write_path,\n",
    "        {\n",
    "            \"image\": RGBImageField(write_mode=\"smart\", max_resolution=res),\n",
    "            \"label\": IntField(),\n",
    "        },\n",
    "        num_workers=0,\n",
    "    )\n",
    "\n",
    "    writer.from_indexed_dataset(dataset, chunksize=100)\n",
    "\n",
    "path = \"C:/mlp/scaling_mlps/beton/imagenetOriginal/val\"\n",
    "create_beton(dataset, 'test', path, data_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BottleneckMLP(\n",
       "  (linear_in): Linear(in_features=12288, out_features=1024, bias=True)\n",
       "  (linear_out): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x BottleneckBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorms): ModuleList(\n",
       "    (0-11): 12 x LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model and specify the pre-trained weights\n",
    "model = get_model(architecture=architecture, resolution=crop_resolution, num_classes=CLASS_DICT[dataset],\n",
    "                  checkpoint=checkpoint)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C:\\mlp\\scaling_mlps\\beton\\imagenet\\ffcv\\val\\val_64.beton\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the test loader\n",
    "from torchvision.transforms import ToTensor\n",
    "data_path = \"C:\\\\mlp\\\\scaling_mlps\\\\beton\"\n",
    "loader = get_loader(\n",
    "    dataset,\n",
    "    bs=eval_batch_size,\n",
    "    mode=\"test\",\n",
    "    augment=False,\n",
    "    dev=device,\n",
    "    mixup=0.0,\n",
    "    data_path=data_path,\n",
    "    data_resolution=data_resolution,\n",
    "    crop_resolution=crop_resolution,\n",
    ")\n",
    "\n",
    "len(loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "#create custom dataset for Imagenet A\n",
    "#loads ImagenetA as loader\n",
    "\n",
    "mean = MEAN_DICT[\"imagenet\"]\n",
    "std = STD_DICT[\"imagenet\"]\n",
    "transform =transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean, std),\n",
    "            transforms.Resize((data_resolution, data_resolution))\n",
    "        ])\n",
    "\n",
    "\n",
    "dataset = ImageFolder(root = 'C:/mlp/scaling_mlps/beton/imageneta/indexed/imagenet-a', transform=transform)\n",
    "\n",
    "with open('wordnetToLabel.txt', 'r') as file:\n",
    "    data = file.read()\n",
    "\n",
    "wordnetToLabel = ast.literal_eval(data) \n",
    "\n",
    "debug = dataset[0][0]\n",
    "print(debug.shape)\n",
    "\n",
    "dataset.class_to_idx = wordnetToLabel\n",
    "loader = DataLoader(dataset,batch_size=eval_batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create imagenet dataset downloaded from the website\n",
    "#loads imagenet as loader\n",
    "\n",
    "mean = MEAN_DICT[\"imagenet\"]\n",
    "std = STD_DICT[\"imagenet\"]\n",
    "\n",
    "class Imnet(Dataset):\n",
    "\n",
    "    def __init__(self, imgs, labels):\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            #transforms.ToTensor(),\n",
    "            #transforms.Resize((data_resolution, data_resolution)),\n",
    "\n",
    "\n",
    "            \n",
    "            transforms.Normalize(mean, std),\n",
    "            transforms.Resize((data_resolution, data_resolution))\n",
    "            \n",
    "        ])\n",
    "        imgs = np.reshape(imgs,(imgs.shape[0],3,data_resolution,data_resolution))\n",
    "        \n",
    "        self.imgs = torch.from_numpy(imgs.astype(np.float32))\n",
    "        self.labels = torch.tensor(labels, dtype=torch.int)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.imgs.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        im = self.transform(self.imgs[idx])\n",
    "        sample = [ im.to(\"cuda\"), self.labels[idx].to(\"cuda\")]\n",
    "        return sample\n",
    "    \n",
    "\n",
    "\n",
    "#try to get original imagenetdataset to work\n",
    "path = \"C:/mlp/scaling_mlps/beton/imagenetOriginal/val/val_data\"\n",
    "with open(path, 'rb') as f:\n",
    "    dict = pickle.load(f)\n",
    "\n",
    "debug = dict[\"labels\"]\n",
    "\n",
    "ImDataset = Imnet(dict[\"data\"],dict[\"labels\"])\n",
    "\n",
    "debug = ImDataset[0]\n",
    "\n",
    "loader = DataLoader(ImDataset,batch_size=eval_batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a test function that evaluates test accuracy\n",
    "@torch.no_grad()\n",
    "def test(model, loader):\n",
    "    debug = True\n",
    "\n",
    "    model.eval()\n",
    "    total_acc, total_top5 = AverageMeter(), AverageMeter()\n",
    "\n",
    "    for ims, targs in tqdm(loader, desc=\"Evaluation\"):\n",
    "\n",
    "        #added to(\"cuda\") to add data to gpu\n",
    "        ims = torch.reshape(ims, (ims.shape[0], -1)).cuda()\n",
    "        preds = model(ims).cuda()\n",
    "        \n",
    "   \n",
    "      \n",
    "        targs = targs.to(\"cuda\")\n",
    "        if dataset != 'imagenet_real':\n",
    "            acc, top5 = topk_acc(preds, targs, k=5, avg=True)\n",
    "        else:\n",
    "            acc = real_acc(preds, targs, k=5, avg=True)\n",
    "            top5 = 0\n",
    "\n",
    "        total_acc.update(acc, ims.shape[0])\n",
    "        total_top5.update(top5, ims.shape[0])\n",
    "\n",
    "\n",
    "    return (\n",
    "        total_acc.get_avg(percentage=True),\n",
    "        total_top5.get_avg(percentage=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/8 [00:00<?, ?it/s]c:\\Users\\merci\\miniconda3\\envs\\ffcv\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "Evaluation: 100%|██████████| 8/8 [00:36<00:00,  4.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy         0.1467\n",
      "Top 5 Test Accuracy           0.1733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc, test_top5 = test(model, loader)\n",
    "\n",
    "# Print all the stats\n",
    "print(\"Test Accuracy        \", \"{:.4f}\".format(test_acc))\n",
    "print(\"Top 5 Test Accuracy          \", \"{:.4f}\".format(test_top5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
