{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\merci\\miniconda3\\envs\\ffcv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from ffcv.fields import BytesField, IntField, RGBImageField\n",
    "from ffcv.writer import DatasetWriter\n",
    "\n",
    "from data_utils.data_stats import *\n",
    "from data_utils.dataloader import get_loader\n",
    "from utils.metrics import topk_acc, real_acc, AverageMeter\n",
    "from models.networks import get_model\n",
    "from data_utils.dataset_to_beton import get_dataset\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "\n",
    "import ast\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'imagenet'                 # One of cifar10, cifar100, stl10, imagenet or imagenet21\n",
    "architecture = 'B_12-Wi_1024'\n",
    "data_resolution = 64                # Resolution of data as it is stored\n",
    "crop_resolution = 64                # Resolution of fine-tuned model (64 for all models we provide)\n",
    "num_classes = CLASS_DICT[dataset]\n",
    "data_path = './beton/'\n",
    "eval_batch_size = 1024\n",
    "checkpoint = 'in21k_imagenet'  #'in21k_cifar100'        # This means you want the network pre-trained on ImageNet21k and finetuned on CIFAR10\n",
    "\n",
    "DEVICE = \"cuda:0\"\n",
    "mode = \"pgd\" #pgd or fgsm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BottleneckMLP(\n",
       "  (linear_in): Linear(in_features=12288, out_features=1024, bias=True)\n",
       "  (linear_out): Linear(in_features=1024, out_features=1000, bias=True)\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x BottleneckBlock(\n",
       "      (block): Sequential(\n",
       "        (0): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (layernorms): ModuleList(\n",
       "    (0-11): 12 x LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define the model and specify the pre-trained weights\n",
    "model = get_model(architecture=architecture, resolution=crop_resolution, num_classes=CLASS_DICT[dataset],\n",
    "                  checkpoint=checkpoint)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C:\\mlp\\scaling_mlps\\beton\\imagenet\\ffcv\\val\\val_64.beton\n"
     ]
    }
   ],
   "source": [
    "# Get the test loader\n",
    "from torchvision.transforms import ToTensor\n",
    "data_path = \"C:\\\\mlp\\\\scaling_mlps\\\\beton\"\n",
    "loader = get_loader(\n",
    "    dataset,\n",
    "    bs=eval_batch_size,\n",
    "    mode=\"test\",\n",
    "    augment=False,\n",
    "    dev=device,\n",
    "    mixup=0.0,\n",
    "    data_path=data_path,\n",
    "    data_resolution=data_resolution,\n",
    "    crop_resolution=crop_resolution,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd(model, x_batch, target, k, eps, eps_step):\n",
    "    loss_fn = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "    # Initialize random input around x_batch within an eps sized box\n",
    "    x_adv = x_batch + eps * (2*torch.rand_like(x_batch) - 1)\n",
    "    # clamp values back down to the [0,1] range\n",
    "    x_adv.clamp_(min=0., max=1.)\n",
    "    \n",
    "    for _ in range(k):\n",
    "        x_adv.detach_().requires_grad_()\n",
    "\n",
    "        # Calculate the loss and calculate the gradients.\n",
    "        model.zero_grad()\n",
    "        out = model(x_adv)\n",
    "        loss_fn(out, target).backward()\n",
    "    \n",
    "        # Calculate the step and add the step and project back to the eps\n",
    "        # sized box around x_batch\n",
    "        step = eps_step * x_adv.grad.sign()\n",
    "        x_adv = x_batch + (x_adv + step - x_batch).clamp_(min=-eps, max=eps)\n",
    "\n",
    "        # clamp back to image domain; in contrast to the previous exercise we clamp at each step (so this is part of the projection)\n",
    "        # both implementations are valid; this tents to work slightly better\n",
    "        x_adv.clamp_(min=0, max=1)\n",
    "\n",
    "    return x_adv.detach()\n",
    "\n",
    "\n",
    "def fgsm_(model, x, target, eps, targeted=True, clip_min=None, clip_max=None):\n",
    "    \"\"\"Internal process for all FGSM and PGD attacks.\"\"\"    \n",
    "    # create a copy of the input, remove all previous associations to the compute graph...\n",
    "    input_ = x.clone().detach_().to(DEVICE)\n",
    "    # ... and make sure we are differentiating toward that variable\n",
    "    input_.requires_grad_()\n",
    "\n",
    "    # run the model and obtain the loss\n",
    "    logits = model(input_).to(DEVICE)\n",
    "    #target = torch.LongTensor([target]).to(DEVICE)\n",
    "    model.zero_grad()\n",
    "    loss = torch.nn.CrossEntropyLoss()(logits, target).to(DEVICE)\n",
    "    loss.backward()\n",
    "    \n",
    "    #perform either targeted or untargeted attack\n",
    "    if targeted:\n",
    "        out = input_ - eps * input_.grad.sign()\n",
    "    else:\n",
    "        out = input_ + eps * input_.grad.sign()\n",
    "    \n",
    "    #if desired clip the ouput back to the image domain\n",
    "    if (clip_min is not None) or (clip_max is not None):\n",
    "        out.clamp_(min=clip_min, max=clip_max)\n",
    "    return out\n",
    "\n",
    "def fgsm_targeted(model, x, target, eps, **kwargs):\n",
    "    return fgsm_(model, x, target, eps, targeted=True, **kwargs)\n",
    "\n",
    "def fgsm_untargeted(model, x, label, eps, **kwargs):\n",
    "    return fgsm_(model, x, label, eps, targeted=False, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define FGGSM\n",
    "#@torch.no_grad()\n",
    "def test_adversarial(model, loader, eps, mode, epsStep = None):\n",
    "    model.eval()\n",
    "    total_acc, total_top5 = AverageMeter(), AverageMeter()\n",
    "    total_accFGGSM, total_top5FGGSM = AverageMeter(), AverageMeter()\n",
    "    for ims, targs in tqdm(loader, desc=\"Evaluation\"):\n",
    "\n",
    "        ims = torch.reshape(ims, (ims.shape[0], -1)).cuda()\n",
    "        targs = targs.to(DEVICE)\n",
    "\n",
    "        if mode ==\"fgsm\":\n",
    "            imsFGSM = fgsm_(model, ims, targs, eps, targeted=True, clip_min=None, clip_max=None)\n",
    "\n",
    "        if mode == \"pgd\":\n",
    "            imsFGSM = pgd(model,ims,targs,1,eps,epsStep)\n",
    "\n",
    "        preds = model(ims).cuda()\n",
    "        \n",
    "        predsFSM = model(imsFGSM).cuda()\n",
    "   \n",
    "        if dataset != 'imagenet_real':\n",
    "            acc, top5 = topk_acc(preds, targs, k=5, avg=True)\n",
    "            accFGGSM, top5FGGSM = topk_acc(predsFSM, targs, k=5, avg=True)\n",
    "\n",
    "        else:\n",
    "            acc = real_acc(preds, targs, k=5, avg=True)\n",
    "            top5 = 0\n",
    "\n",
    "        total_acc.update(acc, ims.shape[0])\n",
    "        total_top5.update(top5, ims.shape[0])\n",
    "\n",
    "        total_accFGGSM.update(accFGGSM, ims.shape[0])\n",
    "        total_top5FGGSM.update(top5FGGSM, ims.shape[0])\n",
    "\n",
    "    return (\n",
    "        total_acc.get_avg(percentage=True),\n",
    "        total_top5.get_avg(percentage=True),\n",
    "        total_accFGGSM.get_avg(percentage=True),\n",
    "        total_top5FGGSM.get_avg(percentage=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 100%|██████████| 49/49 [00:23<00:00,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy         43.0300\n",
      "Top 5 Test Accuracy           66.6800\n",
      "Test Accuracy FG        8.9960\n",
      "Top 5 Test Accuracy  FG         20.5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc, test_top5, total_accFGGSM, total_top5FGGSM = test_adversarial(model, loader,.005, mode = mode, epsStep = 0.1)\n",
    "\n",
    "# Print all the stats\n",
    "print(\"Test Accuracy        \", \"{:.4f}\".format(test_acc))\n",
    "print(\"Top 5 Test Accuracy          \", \"{:.4f}\".format(test_top5))\n",
    "print(\"Test Accuracy FG       \", \"{:.4f}\".format(total_accFGGSM))\n",
    "print(\"Top 5 Test Accuracy  FG        \", \"{:.4f}\".format(total_top5FGGSM))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ffcv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
