{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Fall 2023 Course Project - Zooming in on MLPs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\merci\\miniconda3\\envs\\ffcv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import timm\n",
    "import detectors\n",
    "\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from ffcv.fields import BytesField, IntField, RGBImageField\n",
    "from ffcv.writer import DatasetWriter\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, ViTFeatureExtractor, ViTForImageClassification\n",
    "\n",
    "from data_utils.data_stats import *\n",
    "from data_utils.dataloader import get_loader\n",
    "from data_utils.dataset_to_beton import get_dataset\n",
    "from models.networks import get_model\n",
    "from utils.metrics import topk_acc, real_acc, AverageMeter\n",
    "\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching data loader and model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_and_model(dataset, model, data_path='/scratch/ffcv/'):\n",
    "    \"\"\"\n",
    "    This function retrieves the data, model and feature extractor (if needed) based on the provided information.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (str): The name of the dataset to retrieve (can be cifar10, cifar100 or imagenet).\n",
    "    model (str): The name of the model to retrieve (can be mlp, cnn or vit; only mlp is supported for dataset imagenet).\n",
    "    data_path (str): The path to the data.\n",
    "\n",
    "    Returns (as a tuple):\n",
    "    data_loader (DataLoader): The retrieved data loader.\n",
    "    model (Model): The retrieved model.\n",
    "\n",
    "    Raises:\n",
    "    AssertionError: If the dataset or model is not supported.\n",
    "    \"\"\"\n",
    "\n",
    "    assert dataset in ('cifar10', 'cifar100', 'imagenet'), f'dataset {dataset} is currently not supported by this function'\n",
    "    assert model in ('mlp', 'cnn', 'vit'), f'model {model} is currently not supported by this function'\n",
    "\n",
    "    num_classes = CLASS_DICT[dataset]\n",
    "    eval_batch_size = 100\n",
    "\n",
    "    if dataset == 'imagenet':\n",
    "        data_resolution = 64\n",
    "        assert model == 'mlp', f'imagenet dataset is only supported by mlp model'\n",
    "    else:\n",
    "        data_resolution = 32\n",
    "\n",
    "    crop_resolution = data_resolution\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if device == 'cuda':\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "    if model == 'mlp':\n",
    "        architecture = 'B_12-Wi_1024'\n",
    "        checkpoint = 'in21k_' + dataset\n",
    "        model = get_model(architecture=architecture, resolution=64, num_classes=num_classes, checkpoint=checkpoint)\n",
    "\n",
    "    if model == 'cnn':\n",
    "        architecture = 'resnet18_' + dataset\n",
    "        model = timm.create_model(architecture, pretrained=True)\n",
    "\n",
    "    if model == 'vit':\n",
    "        architecture = 'vit_small_patch16_224_' + dataset + '_v7.pth'\n",
    "        model = torch.load(architecture)\n",
    "\n",
    "    data_loader = get_loader(\n",
    "        dataset,\n",
    "        bs=eval_batch_size,\n",
    "        mode=\"test\",\n",
    "        augment=False,\n",
    "        dev=device,\n",
    "        mixup=0.0,\n",
    "        data_path=data_path,\n",
    "        data_resolution=data_resolution,\n",
    "        crop_resolution=crop_resolution,\n",
    "    )\n",
    "    model.cuda()\n",
    "    return data_loader, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(torch.nn.Module): \n",
    "    def __init__(self, shape=224): \n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = shape \n",
    "        \n",
    "    def forward(self, x): \n",
    "        shape = self.shape\n",
    "        x = transforms.functional.resize(x, size=(shape, shape))\n",
    "        \n",
    "        #if shape == 64, its an mlp\n",
    "        if shape == 64:\n",
    "            #x = torch.reshape(x, shape=(-1,))\n",
    "            x = torch.reshape(x, shape=(x.shape[0],-1))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating baseline model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a test function that evaluates test accuracy\n",
    "@torch.no_grad()\n",
    "def test(model, loader, is_mlp = False, is_vit = False):\n",
    "    model.eval()\n",
    "    total_acc, total_top5 = AverageMeter(), AverageMeter()\n",
    "\n",
    "    for ims, targs in tqdm(loader, desc=\"Evaluation\"):\n",
    "        if is_mlp:\n",
    "            model = torch.nn.Sequential(Reshape(64), model)\n",
    "        if is_vit:\n",
    "            model = torch.nn.Sequential(Reshape(224), model)\n",
    "        \n",
    "        preds = model(ims)    \n",
    "        acc, top5 = topk_acc(preds, targs, k=5, avg=True)\n",
    "        \n",
    "        total_acc.update(acc, ims.shape[0])\n",
    "        total_top5.update(top5, ims.shape[0])\n",
    "\n",
    "    return (\n",
    "        total_acc.get_avg(percentage=True),\n",
    "        total_top5.get_avg(percentage=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader, model = get_data_and_model(dataset='cifar10', model='mlp', data_path='/scratch/ffcv/')\n",
    "test_acc, test_top5 = test(model, data_loader, is_mlp=True)\n",
    "\n",
    "# Print all the stats\n",
    "print(\"Test Accuracy        \", \"{:.4f}\".format(test_acc))\n",
    "print(\"Top 5 Test Accuracy          \", \"{:.4f}\".format(test_top5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate adversarial accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor, mean, std):\n",
    "    \"\"\"\n",
    "    Denormalize a tensor.\n",
    "\n",
    "    Parameters:\n",
    "    tensor (torch.Tensor): The tensor to denormalize.\n",
    "    mean (float or sequence): The mean used for normalization.\n",
    "    std (float or sequence): The standard deviation used for normalization.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The denormalized tensor.\n",
    "    \"\"\"\n",
    "    return tensor*std[1]+mean[1]\n",
    "\n",
    "def normalize(tensor, mean, std):\n",
    "    \"\"\"\n",
    "    Normalize a tensor.\n",
    "\n",
    "    Parameters:\n",
    "    tensor (torch.Tensor): The tensor to normalize.\n",
    "    mean (float or sequence): The mean used for normalization.\n",
    "    std (float or sequence): The standard deviation used for normalization.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The normalized tensor.\n",
    "    \"\"\"\n",
    "    return (tensor-mean[1])/std[1]\n",
    "\n",
    "def pgd(model, dataset, x_batch, label, eps, k, eps_step):\n",
    "    \"\"\"\n",
    "    Performs the Projected Gradient Descent (PGD) for adversarial attacks.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model to attack.\n",
    "    dataset (str): The name of the dataset used (can be cifar10, cifar100 or imagenet).\n",
    "    x_batch (torch.Tensor): The input tensor.\n",
    "    label (torch.Tensor): The true labels for the input tensor.\n",
    "    eps (float): The maximum perturbation for PGD.\n",
    "    k (int): The number of steps for PGD.\n",
    "    eps_step (float): The step size for each iteration.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The adversarially perturbed input tensor.\n",
    "    \"\"\"   \n",
    "    mean, std = MEAN_DICT[dataset]/255, STD_DICT[dataset]/255\n",
    "\n",
    "    x = x_batch.clone().detach_()\n",
    "    x = denormalize(x, mean, std)\n",
    "    x_adv = x + eps * (2*torch.rand_like(x) - 1)\n",
    "    x_adv.clamp_(min=0., max=1.)\n",
    "    \n",
    "    for _ in range(int(k)):\n",
    "        x_adv = normalize(x_adv, mean, std).detach_()\n",
    "        x_adv.requires_grad_()\n",
    "        model.zero_grad()\n",
    "        loss = torch.nn.CrossEntropyLoss()(model(x_adv), label)\n",
    "        loss.backward()\n",
    "        perturbation = eps_step * x_adv.grad.sign()\n",
    "\n",
    "        x_adv = denormalize(x_adv, mean, std)\n",
    "        x_adv = x + (x_adv + perturbation - x).clamp_(min=-eps, max=eps)\n",
    "        x_adv.clamp_(min=0, max=1)\n",
    "\n",
    "\n",
    "    return normalize(x_adv.detach(), mean, std)\n",
    "\n",
    "def fgsm_untargeted(model, dataset, x_batch, label, eps):\n",
    "    \"\"\"\n",
    "    Performs the Fast Gradient Sign Method (FGSM) for untargeted adversarial attacks.\n",
    "\n",
    "    Parameters:\n",
    "    model (torch.nn.Module): The model to attack.\n",
    "    dataset (str): The name of the dataset used (can be cifar10, cifar100 or imagenet).\n",
    "    x_batch (torch.Tensor): The input tensor.\n",
    "    label (torch.Tensor): The true labels for the input tensor.\n",
    "    eps (float): The step size for the FGSM attack.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The adversarially perturbed input tensor.\n",
    "    \"\"\"\n",
    "    mean, std = MEAN_DICT[dataset]/255, STD_DICT[dataset]/255\n",
    "\n",
    "    x = x_batch.clone().detach_()\n",
    "    x.requires_grad_()\n",
    "    model.zero_grad()\n",
    "    loss = torch.nn.CrossEntropyLoss()(model(x), label)\n",
    "    loss.backward()\n",
    "    perturbation = eps * x.grad.sign()\n",
    "\n",
    "    out = denormalize(x, mean, std) + perturbation\n",
    "    out = out.clamp_(min=0, max=1)\n",
    "        \n",
    "    return normalize(out, mean, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_adversarial(model, dataset, loader, eps, mode, is_mlp = False, is_vit = False, modelname = 'MLP', datasetname = 'cifar10'):\n",
    "    model.eval()\n",
    "    total_adv_acc, total_adv_top5 = AverageMeter(), AverageMeter()\n",
    "    batchnumber = 0\n",
    "    if is_mlp:\n",
    "        model = torch.nn.Sequential(Reshape(64), model)\n",
    "    if is_vit:\n",
    "        model = torch.nn.Sequential(Reshape(224), model)\n",
    "    for ims, targs in tqdm(loader, desc=\"Evaluation\"):\n",
    "\n",
    "            \n",
    "        if mode ==\"fgsm\":\n",
    "            adv_ims = fgsm_untargeted(model, dataset, ims, targs, eps)\n",
    "            path = './adv_examples/' + modelname + '/' + datasetname + '/' + mode + '/' + str(eps) + 'Batch' + str(batchnumber)\n",
    "            batchnumber += 1\n",
    "            torch.save(adv_ims, path)\n",
    "        if mode == \"pgd\":\n",
    "            adv_ims = pgd(model, dataset, ims, targs, eps=eps, k=5, eps_step=eps/2)\n",
    "            path = './adv_examples/' + modelname + '/' + datasetname + '/' + mode + '/' + str(eps) + 'Batch' + str(batchnumber)\n",
    "            batchnumber += 1\n",
    "            torch.save(adv_ims, path)\n",
    "        adv_preds = model(adv_ims)\n",
    "        adv_acc, adv_top5 = topk_acc(adv_preds, targs, k=5, avg=True)\n",
    "        total_adv_acc.update(adv_acc, ims.shape[0])\n",
    "        total_adv_top5.update(adv_top5, ims.shape[0])\n",
    "\n",
    "    return (\n",
    "        total_adv_acc.get_avg(percentage=True),\n",
    "        total_adv_top5.get_avg(percentage=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now starting: pgd on vit with cifar100\n",
      "Loading ./beton/cifar100\\ffcv\\test\\test_32.beton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating:   0%|          | 0/12 [00:00<?, ?it/s]c:\\Users\\merci\\miniconda3\\envs\\ffcv\\lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "Evaluation: 100%|██████████| 100/100 [03:45<00:00,  2.26s/it]\n",
      "Evaluation: 100%|██████████| 100/100 [03:48<00:00,  2.29s/it]\n",
      "Evaluation: 100%|██████████| 100/100 [03:47<00:00,  2.28s/it]\n",
      "Evaluation: 100%|██████████| 100/100 [03:47<00:00,  2.28s/it]\n",
      "Evaluation: 100%|██████████| 100/100 [03:47<00:00,  2.28s/it]\n",
      "Evaluation: 100%|██████████| 100/100 [03:47<00:00,  2.28s/it]\n",
      "Evaluation: 100%|██████████| 100/100 [03:47<00:00,  2.28s/it]\n",
      "Evaluation: 100%|██████████| 100/100 [03:47<00:00,  2.28s/it]\n",
      "Evaluation: 100%|██████████| 100/100 [03:47<00:00,  2.28s/it]\n",
      "Evaluation: 100%|██████████| 100/100 [03:48<00:00,  2.28s/it]\n",
      "Evaluation: 100%|██████████| 100/100 [03:48<00:00,  2.28s/it]\n",
      "Evaluation: 100%|██████████| 100/100 [03:48<00:00,  2.28s/it]\n",
      "Evaluating: 100%|██████████| 12/12 [45:34<00:00, 227.84s/it]\n"
     ]
    }
   ],
   "source": [
    "#USE BATCH SIZE 100\n",
    "\n",
    "#already done: MLP(everything),cnn everytthing, vittt fgp,pgd on cif10 pgd on cifar100..\n",
    "\n",
    "eps_range = 0.025\n",
    "steps = 12\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "for modelname in ['vit']:\n",
    "    is_mlp = modelname == 'mlp'\n",
    "    is_vit = modelname == 'vit'\n",
    "    for datasetname in ['cifar100']:\n",
    "        for methodname in [ 'pgd']:\n",
    "            adv_acc = []\n",
    "            adv_top5 = []\n",
    "            print('Now starting: ' + methodname +' on ' + modelname + ' with ' + datasetname)\n",
    "            data_loader, model = get_data_and_model(dataset=datasetname, model=modelname, data_path='./beton/')\n",
    "            #all_eps = np.arange(0,0.26,0.0125)\n",
    "            all_eps = np.arange(0,eps_range,eps_range / steps)\n",
    "            for eps in tqdm(all_eps, desc=\"Evaluating\"):\n",
    "                test_adv_acc, test_adv_top5 = test_adversarial(model, datasetname, data_loader, eps, methodname, is_vit = is_vit, is_mlp= is_mlp, modelname= modelname, datasetname= datasetname)\n",
    "                adv_acc.append(test_adv_acc)\n",
    "                adv_top5.append(test_adv_top5)\n",
    "\n",
    "            name = methodname + '_' + modelname + '_' + datasetname + '_zoomedin_'\n",
    "            np.save('accuracy_' + name, adv_acc)\n",
    "            np.save('top5_' + name, adv_top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot adversarial accuracies\n",
    "\n",
    "\n",
    "#all_eps = np.arange(0,0.26,0.0125)\n",
    "eps_range = 0.025\n",
    "steps = 12\n",
    "all_eps = np.arange(0,eps_range,eps_range / steps)\n",
    "for modelname in ['cnn', 'vit', 'mlp']:\n",
    "    for datasetname in ['cifar10','cifar100']:\n",
    "        for mode in ['pgd']:\n",
    "            name = mode + '_' + modelname + '_' + datasetname + '_zoomedin_'\n",
    "            accuracy = np.load('accuracy_' +name+ '.npy')\n",
    "            accuracytop5 = np.load('top5_' +name+ '.npy')\n",
    "            \n",
    "        \n",
    "\n",
    "            #plot accuracies\n",
    "            plt.plot(all_eps, accuracy)\n",
    "            plt.title('accuracy_' +name)\n",
    "            plt.savefig('./plots/'+ 'accuracy_'+ name  +  '.jpg')\n",
    "            plt.clf()\n",
    "\n",
    "            #plot top5 accuracies\n",
    "            plt.plot(all_eps, accuracy)\n",
    "            plt.title('top5_' +name)\n",
    "            plt.savefig('./plots/' +'top5_'+ name + '.jpg')\n",
    "            plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot adversarial examples\n",
    "\n",
    "for modelname in [ 'mlp']:\n",
    "    for datasetname in ['cifar10','cifar100']:\n",
    "        data_loader, model = get_data_and_model(dataset=datasetname, model=modelname, data_path='./beton/')\n",
    "        for mode in ['fgsm','pgd']:\n",
    "            for eps in tqdm(all_eps, desc=\"Evaluating\"):\n",
    "                batchnumber = 0\n",
    "                for x,y in data_loader:\n",
    "                   \n",
    "                    \n",
    "                    #get adversarial batch\n",
    "                    path = './adv_examples/' + modelname + '/' + datasetname + '/' + mode + '/' + str(eps) + 'Batch' + str(batchnumber)\n",
    "                    batchnumber += 1\n",
    "                    adv_batch = torch.load(path)\n",
    "                    adv_im = adv_batch[0].cpu().permute(1, 2, 0).detach().numpy()\n",
    "                    im = x[0].cpu().permute(1, 2, 0).detach().numpy()\n",
    "\n",
    "                    fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "                    #plot standart image and adv \n",
    "                    axes[0].imshow(im)\n",
    "                    axes[0].set_title(modelname +  datasetname +  mode +  str(eps) + 'Batch' + str(batchnumber))\n",
    "                    plt.subplot(1, 2, 1)\n",
    "                    axes[1].imshow(adv_im)\n",
    "                    axes[1].set_title('aversarial' + modelname +  datasetname +  mode +  str(eps) + 'Batch' + str(batchnumber)) \n",
    "                    plt.tight_layout()\n",
    "                    plt.clf()\n",
    "                    break             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy_advexamples(model, datamodel, datasetname, eps, mode, loader):\n",
    "    #testmodel: Model to be tested\n",
    "    #datamodel: Model with which the adv examples were generated\n",
    "    #datasetname: from which dataset to take the adv examples\n",
    "    #eps & mode: params for adversarial generation\n",
    "\n",
    "    \n",
    "\n",
    "    total_adv_acc, total_adv_top5 = AverageMeter(), AverageMeter()\n",
    "    batchnumber = 0\n",
    "\n",
    "\n",
    "    for ims, targs in tqdm(loader, desc=\"Evaluation\"):\n",
    "\n",
    "        if mode ==\"fgsm\":\n",
    "            path = './adv_examples/' + datamodel + '/' + datasetname + '/' + mode + '/' + str(eps) + 'Batch' + str(batchnumber)\n",
    "            adv_ims = torch.load(path)\n",
    "            batchnumber += 1\n",
    "            \n",
    "        if mode == \"pgd\":\n",
    "            path = './adv_examples/' + datamodel + '/' + datasetname + '/' + mode + '/' + str(eps) + 'Batch' + str(batchnumber)\n",
    "            adv_ims = torch.load(path)\n",
    "            batchnumber += 1\n",
    "            \n",
    "        adv_preds = model(adv_ims)\n",
    "        adv_acc, adv_top5 = topk_acc(adv_preds, targs, k=5, avg=True)\n",
    "        total_adv_acc.update(adv_acc, ims.shape[0])\n",
    "        total_adv_top5.update(adv_top5, ims.shape[0])\n",
    "\n",
    "    return (\n",
    "        total_adv_acc.get_avg(percentage=True),\n",
    "        total_adv_top5.get_avg(percentage=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./beton/cifar10\\ffcv\\val\\val_32.beton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/100 [00:00<?, ?it/s]Exception ignored in: <finalize object at 0x223e4331920; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\merci\\miniconda3\\envs\\ffcv\\lib\\weakref.py\", line 591, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"c:\\Users\\merci\\miniconda3\\envs\\ffcv\\lib\\site-packages\\numba\\core\\dispatcher.py\", line 312, in finalizer\n",
      "    for cres in overloads.values():\n",
      "KeyError: (Array(uint8, 1, 'C', True, aligned=True), Array(uint8, 1, 'C', True, aligned=True), uint32, uint32, uint32, uint32, Literal[int](0), Literal[int](0), Literal[int](1), Literal[int](1), Literal[bool](False), Literal[bool](False))\n",
      "Evaluation: 100%|██████████| 100/100 [00:34<00:00,  2.88it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:32<00:00,  3.06it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.62it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.69it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.69it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.66it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:26<00:00,  3.71it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.63it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.63it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.64it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.63it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.67it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.64it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.65it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.63it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.69it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.59it/s]\n",
      "Evaluation: 100%|██████████| 100/100 [00:27<00:00,  3.68it/s]\n"
     ]
    }
   ],
   "source": [
    "#Get adversarial transversability examples\n",
    "top_acc = []\n",
    "top5_acc = []\n",
    "top_comparison = []\n",
    "for testmodel in ['cnn']:\n",
    "    for datasetname in ['cifar10']:\n",
    "        loader, model = get_data_and_model(dataset=datasetname, model=testmodel, data_path='./beton/')\n",
    "        if testmodel == 'mlp':\n",
    "            model = torch.nn.Sequential(Reshape(64), model)\n",
    "        if testmodel == 'vit':\n",
    "            model = torch.nn.Sequential(Reshape(224), model)\n",
    "        model.cuda()\n",
    "        model.eval()\n",
    "        for datamodel in ['mlp']:\n",
    "            for eps in np.arange(0,0.26,0.0125):\n",
    "                for mode in ['fgsm']:\n",
    "                    total_adv_acc, total_adv_top5 = test_accuracy_advexamples(model, datamodel, datasetname,eps, mode, loader)\n",
    "                    #total_adv_acc_comparison, total_adv_top5_comparison = test_accuracy_advexamples(model, testmodel, datasetname,eps, mode, loader)\n",
    "\n",
    "                    top_acc.append(total_adv_acc)\n",
    "                    top5_acc.append(total_adv_top5)\n",
    "                    #top_comparison.append(total_adv_acc_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[93.78999847173691, 88.03999811410904, 80.89999812841415, 73.23999810218811, 65.96999871730804, 58.54999881982803, 51.52999863028526, 44.42999878525734, 38.14999911189079, 32.68999923765659, 28.43999920785427, 24.729999244213104, 21.479999467730522, 19.02999947220087, 17.009999625384808, 15.629999622702599, 14.679999627172947, 13.759999677538872, 13.489999629557133, 12.92999967560172, 12.559999715536833]\n",
      "[93.78999847173691, 23.439999356865883, 21.039999529719353, 22.97999933362007, 25.189999282360077, 26.78999924659729, 27.349999263882637, 26.539999306201935, 25.6199993789196, 24.049999356269836, 22.019999355077744, 20.229999475181103, 17.90999949723482, 16.21999954432249, 14.859999641776085, 13.909999668598175, 13.09999967738986, 12.459999728947878, 12.14999964274466, 12.13999966904521, 12.019999668002129]\n"
     ]
    }
   ],
   "source": [
    "print(top_acc)\n",
    "print(top_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marcel's part\n",
    "Run cells 1, 2, 5 & 6 before this and change data_path below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for modelname in ['vit', 'cnn']:\n",
    "    for datasetname in ['cifar10', 'cifar100']:\n",
    "        is_mlp = modelname == 'mlp'\n",
    "\n",
    "        adv_acc = []\n",
    "        adv_top5 = []\n",
    "        data_loader, model = get_data_and_model(dataset=datasetname, model=modelname, data_path='./beton/')\n",
    "        all_eps = np.arange(0,0.26,0.0125)\n",
    "\n",
    "        for eps in tqdm(all_eps, desc=\"Evaluating\"):\n",
    "            test_adv_acc, test_adv_top5 = test_adversarial(model, datasetname, data_loader, eps, 'pgd', is_mlp = is_mlp, modelname= modelname, datasetname= datasetname)\n",
    "\n",
    "            adv_acc.append(test_adv_acc)\n",
    "            adv_top5.append(test_adv_top5)\n",
    "\n",
    "        acc_fname = 'pgd_acc_' + model + '_' + datasetname\n",
    "        top5_fname = 'pgd_top5_' + model + '_' + datasetname\n",
    "        \n",
    "        np.save(acc_fname, np.array(adv_acc))\n",
    "        np.save(top5_fname, np.array(adv_top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
