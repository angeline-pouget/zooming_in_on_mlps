{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Robustness of MLP, ViT and CNN on CIFAR-10 and CIFAR-100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import torch\n",
    "import timm\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as T\n",
    "\n",
    "from data_utils.data_stats import *\n",
    "from data_utils.dataloader import get_loader\n",
    "from models.networks import get_model\n",
    "from utils.metrics import topk_acc, AverageMeter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching data loader and model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_and_model(dataset, model, data_path='/scratch/ffcv/', split='test', batch_size=100):\n",
    "    \"\"\"\n",
    "    This function retrieves the data, model and feature extractor (if needed) based on the provided information.\n",
    "\n",
    "    Parameters:\n",
    "    dataset (str): The name of the dataset to retrieve (can be cifar10, cifar100 or imagenet).\n",
    "    model (str): The name of the model to retrieve (can be mlp, cnn or vit; only mlp is supported for dataset imagenet).\n",
    "    data_path (str): The path to the data.\n",
    "\n",
    "    Returns (as a tuple):\n",
    "    data_loader (DataLoader): The retrieved data loader.\n",
    "    model (Model): The retrieved model.\n",
    "\n",
    "    Raises:\n",
    "    AssertionError: If the dataset or model is not supported.\n",
    "    \"\"\"\n",
    "\n",
    "    assert dataset in ('cifar10', 'cifar100', 'imagenet'), f'dataset {dataset} is currently not supported by this function'\n",
    "    assert model in ('mlp', 'cnn', 'vit'), f'model {model} is currently not supported by this function'\n",
    "\n",
    "    num_classes = CLASS_DICT[dataset]\n",
    "    eval_batch_size = batch_size\n",
    " \n",
    "    if dataset == 'imagenet':\n",
    "        data_resolution = 64\n",
    "        assert model == 'mlp', f'imagenet dataset is only supported by mlp model'\n",
    "    else:\n",
    "        data_resolution = 32\n",
    "\n",
    "    crop_resolution = data_resolution\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    if device == 'cuda':\n",
    "        torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "    if model == 'mlp':\n",
    "        architecture = 'B_12-Wi_1024'\n",
    "        checkpoint = 'in21k_' + dataset\n",
    "        model = get_model(architecture=architecture, resolution=64, num_classes=num_classes, checkpoint=checkpoint)\n",
    "\n",
    "    if model == 'cnn':\n",
    "        architecture = 'resnet18_' + dataset\n",
    "        model = timm.create_model(architecture, pretrained=True)\n",
    "\n",
    "    if model == 'vit':\n",
    "        architecture = 'vit_small_patch16_224_' + dataset + '_v7.pth'\n",
    "        model = torch.load(architecture)\n",
    "\n",
    "    data_loader = get_loader(\n",
    "        dataset,\n",
    "        bs=eval_batch_size,\n",
    "        mode=split,\n",
    "        augment=split == 'train',\n",
    "        dev=device,\n",
    "        mixup=0.0,\n",
    "        data_path=data_path,\n",
    "        data_resolution=data_resolution,\n",
    "        crop_resolution=crop_resolution,\n",
    "    )\n",
    "\n",
    "    return data_loader, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape(torch.nn.Module): \n",
    "    def __init__(self, shape=224): \n",
    "        super(Reshape, self).__init__()\n",
    "        self.shape = shape \n",
    "        \n",
    "    def forward(self, x): \n",
    "        shape = self.shape\n",
    "        x = transforms.functional.resize(x, size=(shape, shape))\n",
    "        if shape == 64:\n",
    "            bs = x.shape[0]\n",
    "            x = torch.reshape(x, shape=(bs,-1,))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating baseline model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n",
      "Loading /scratch/data/ffcv/cifar100/train_32.beton\n",
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n",
      "Loading /scratch/data/ffcv/cifar10/train_32.beton\n"
     ]
    }
   ],
   "source": [
    "dataset_name = 'cifar100'\n",
    "model_name = 'mlp'\n",
    "\n",
    "train_data_loader, _ = get_data_and_model(dataset=dataset_name, model=model_name, data_path='/scratch/data/ffcv/', split='train', batch_size=30000)\n",
    "_, model = get_data_and_model(dataset='cifar10', model=model_name, data_path='/scratch/data/ffcv/', split='train', batch_size=30000)\n",
    "\n",
    "model = nn.Sequential(Reshape(64), model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]/home/apouget/miniconda3/envs/ffcv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "100%|██████████| 5/5 [01:52<00:00, 22.59s/it]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters())\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Train weights for the linear layer for 5 epochs, resizing the input images\n",
    "num_epochs = 5\n",
    "\n",
    "for _ in tqdm(range(num_epochs)):\n",
    "    for ims, targs in train_data_loader:\n",
    "        idx = (targs==0) | (targs==1) | (targs==2) | (targs==3) | (targs==4) | (targs==5) | (targs==6) | (targs==7) | (targs==8) | (targs==9)\n",
    "        ims, targs = ims[idx], targs[idx]\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(ims)\n",
    "        loss = loss_function(outputs, targs)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a test function that evaluates test accuracy\n",
    "@torch.no_grad()\n",
    "def test(model, loader):\n",
    "    total_acc, total_top5 = AverageMeter(), AverageMeter()\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    for ims, targs in tqdm(loader, desc=\"Evaluation\"):\n",
    "        idx = (targs==0) | (targs==1) | (targs==2) | (targs==3) | (targs==4) | (targs==5) | (targs==6) | (targs==7) | (targs==8) | (targs==9)\n",
    "        ims, targs = ims[idx], targs[idx]\n",
    "        preds = model(ims)\n",
    "        acc, top5 = topk_acc(preds, targs, k=5, avg=True)\n",
    "        total_acc.update(acc, ims.shape[0])\n",
    "        total_top5.update(top5, ims.shape[0])\n",
    "\n",
    "    return (\n",
    "        total_acc.get_avg(percentage=True),\n",
    "        total_top5.get_avg(percentage=True),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights already downloaded\n",
      "Load_state output <All keys matched successfully>\n",
      "Loading /scratch/data/ffcv/cifar100/test_32.beton\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation:   0%|          | 0/100 [00:00<?, ?it/s]Exception ignored in: <finalize object at 0x7fd044f6ffc0; dead>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/apouget/miniconda3/envs/ffcv/lib/python3.9/weakref.py\", line 591, in __call__\n",
      "    return info.func(*info.args, **(info.kwargs or {}))\n",
      "  File \"/home/apouget/miniconda3/envs/ffcv/lib/python3.9/site-packages/numba/core/dispatcher.py\", line 312, in finalizer\n",
      "    for cres in overloads.values():\n",
      "KeyError: (Array(uint8, 1, 'C', True, aligned=True), Array(uint8, 1, 'C', True, aligned=True), uint32, uint32, uint32, uint32, Literal[int](0), Literal[int](0), Literal[int](1), Literal[int](1), Literal[bool](False), Literal[bool](False))\n",
      "/home/apouget/miniconda3/envs/ffcv/lib/python3.9/site-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "Evaluation:  44%|████▍     | 44/100 [00:06<00:06,  8.55it/s]"
     ]
    }
   ],
   "source": [
    "test_data_loader, _ = get_data_and_model(dataset=dataset_name, model=model_name, data_path='/scratch/data/ffcv/', split='test')\n",
    "test_acc, test_top5 = test(model, test_data_loader)\n",
    "\n",
    "# Print all the stats\n",
    "print(\"Test Accuracy        \", \"{:.4f}\".format(test_acc))\n",
    "print(\"Top 5 Test Accuracy          \", \"{:.4f}\".format(test_top5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
